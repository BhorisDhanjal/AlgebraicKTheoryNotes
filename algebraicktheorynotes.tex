\documentclass[12pt]{report}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{fontawesome5}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[toc,page]{appendix}
\usepackage[nottoc]{tocbibind}
\numberwithin{equation}{section}
\graphicspath{ {./Images/} }
\usepackage[raggedright]{titlesec}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{float}
\usepackage[autostyle]{csquotes}\usepackage{quiver}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}
\usepackage{hyperref}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Hom}{{\mathrm{Hom}}}
\newcommand{\image}{{\mathrm{Im}}}
\newcommand{\kernel}{{\mathrm{Ker}}}
\newcommand{\coker}{{\mathrm{coker}}}
% \newtheorem{dummy}{Dummy}[section]
\newcounter{dummy} \numberwithin{dummy}{section}
\newtheorem{theorem}[dummy]{Theorem}
\newtheorem{definition}[dummy]{Definition}
\newtheorem{corollary}[dummy]{Corollary}
\newtheorem{lemma}[dummy]{Lemma}
\newtheorem{proposition}[dummy]{Proposition}
\newtheorem{example}[dummy]{Example}
%opening

\makeatletter
\newcommand\frontmatter{%
	\cleardoublepage
	%\@mainmatterfalse
	\pagenumbering{roman}}

\newcommand\mainmatter{%
	\cleardoublepage
	% \@mainmattertrue
	\pagenumbering{arabic}}
\makeatother

\title{Algebraic K theory}

\author{Bhoris Dhanjal} 

\date{November, 2024} 
\newcommand{\reporttitle}{{Classical Algebraic\\[0.5em] K-Theory $(K_0, K_1)$}}


\begin{document}
	\input{titlepage}

	\frontmatter
	
	\begin{center}
		

		{\LARGE {\textsc{Certificate}}}\\[2.5cm]
	\end{center}
	\normalsize This is to certify the Semester III Research Project titled 'Classical Algebraic K-Theory $(K_0,K_1)$' in partial fulfilment of the requirements for the degree of M.Sc. Mathematics  submitted by Mr. Bhoris Dhanjal is approved for submission.
	

	
	\vfill
	
	
	% Bottom of the page
	\begin{flushright}
		Dr. Anuradha Garge\\
		(Project Guide)\\[1.5cm]
		Prof. B. S. Desale\\
		(Head of Department)\\
	\end{flushright}
	
	\begin{flushleft}
		Date:
	\end{flushleft}
	\clearpage
	
	\begin{center}
	
	
	{\LARGE {\textsc{Acknowledgements}}}\\[1cm]
\end{center}
I would like to express my deepest gratitude to my guide, Dr. Anuradha Garge, for her invaluable guidance, encouragement, and support throughout this research project. Her insights and expertise were instrumental in shaping this work.

I am also thankful to my family and friends for their unwavering support and encouragement, which have been a constant source of strength during this journey.
	\clearpage
	\begin{center}
		
		
		{\LARGE {\textsc{Abstract}}}\\[1cm]
	\end{center}
This project explores key results in classical algebraic \( K \)-theory, focusing on the Grothendieck groups \( K_0 \), Whitehead groups \( K_1 \), and its various applications. Topics include the Quillenâ€“Suslin theorem, and Suslin's work on unimodular vectors linear groups.
\clearpage
	\tableofcontents
	\mainmatter
	

	\chapter{Projective modules}
	
	
%	We begin with some basic prerequisites of abelian categories and homological algebra, which provide a foundational framework. These concepts will be used extensively and implicitly throughout both the projects, forming an assumed background for the discussions. So for completeness sake we will begin by examining it in detail.
	We begin with with basic prerequisites in homological algebra. Introducing the concept of a projective module.
	
	Unless otherwise specified, all rings considered are assumed to be commutative with unity.
%	\section{Abelian Categories}
%	Abelian categories are essential to the understanding of homological algebra. It is motivated by the fact that it allows for using homological methods in a wide variety of applications and helps unify various (co)homology theories. They were first introduced by Grothendieck in his seminal Tohuku paper \cite{grothendieck1957quelques}.
%	
%	There is a chain of conditions regarding `abelian'-ness of categories which is roughly understood as follows.
%	\[ \textbf{Abelian} \subseteq \textbf{Pre-Abelian} \subseteq \textbf{Additive} \subseteq \textbf{Ab-Enriched}\]
%	
%	Ab-Enriched categories (sometimes referred to as pre-additive categories) are categories such that for $A,B \in \mathcal{C}$ the external hom set $\Hom(A,B)$ has the structure of an abelian group, furthermore it has a well defined notion of composition (which is bilinear due to the monoidal product in Ab), $\Hom(A,B)\otimes \Hom(B,C) =\Hom(A,C)$. 
%	
%	We have chosen to omit the precise definitions of the coherence conditions for monoidal and monoidally enriched categories to make this section easier to read. Since we refrain from explicitly using them for computations anywhere, the basic background described above will suffice. For a more detailed overview of the definitions for monoidal and monoidally enriched categories refer to \cite{lane1998categories} for a classical treatment or \cite{riehl2017category} for an excellent modern exposition. 
%	\begin{example}
%		A ring is a single object $\mathrm{Ab}$-Enriched category (In the same sense how a group is realized as a single object category with all arrows invertible).
%	\end{example}
%	We cover a few basic results.
%	
%	\begin{proposition}
%		In Ab-Enriched categories intial and terminal objects coincide (it is often called the zero object)
%	\end{proposition}
%	\begin{proof}
%		Let $\mathcal{C}$ be an Ab-Enriched category. Note that the Hom-sets between objects have `zero morphisms', i.e. arrows in the Hom-set which behave like the additive identity in the Ab group induced by it. In particular for $0_{A,B}\in \Hom(A,B)$ we have the property that if $f:B \to C$ then $f\circ 0_{A,B}=0_{A,C}$ and $g: A \to D$ then $0_{A,B}\circ g=0_{D,B}$.
%		
%		Now suppose $0 \in \mathcal{C}$ is initial so there is a unique morphism $0\to 0$ so in its Hom-set its both the additive inverse and the identity. So for any $f:X \to 0$ we can say that by the zero morphism property $f=0$ so also $0$ is terminal.
%	\end{proof}
%	\begin{proposition}
%		In Ab-Enriched categories finite coproducts coincide with finite products (i.e. biproducts) \footnote{This also holds over categories enriched over commutative monoids.}
%	\end{proposition}
%	\begin{proof}	
%		Let $\mathcal{C}$ be an Ab-enriched category and $A,B\in \mathcal{C}$ consider the product $A\times B$, which is determined by the following UMP,
%		\[\begin{tikzcd}
%			& X \\
%			A & A\times B & B
%			\arrow["{p_1}"', from=2-2, to=2-1]
%			\arrow["{p_2}", from=2-2, to=2-3]
%			\arrow["u", dashed, from=1-2, to=2-2]
%			\arrow["{x_1}"', from=1-2, to=2-1]
%			\arrow["{x_2}", from=1-2, to=2-3]
%		\end{tikzcd}\]
%		Consider $A$ and $B$ in place of $X $ in the diagram. By the UMP we have $q_1: A \to A\times B, q_2: B \to A\times B$
%		\[\begin{tikzcd}
%			A && B \\
%			& {A\times B} \\
%			A && B
%			\arrow["{p_1}"', from=2-2, to=3-1]
%			\arrow["{p_2}", from=2-2, to=3-3]
%			\arrow["{q_2}"', from=1-3, to=2-2]
%			\arrow["{q_1}"', from=1-1, to=2-2]
%			\arrow["{1_A}"', from=1-1, to=3-1]
%			\arrow["{1_B}", from=1-3, to=3-3]
%		\end{tikzcd}\]
%		So $p_1q_1=1_A$ and $p_2q_2=1_B$ also $p_1q_2=p_2q_1=0$.
%		
%		Now note that $q_1p_1+q_2p_2=1_{A\times B}$ as $p_1(q_1p_1+q_2p_2)=p_1$ and $p_2(q_1p_1+q_2p_2)=p_2$. Claim this $q_1,q_2$ determine a coproduct $A +B$.
%		
%		We wish to show the following UMP holds for some arbitrary $C \in \mathcal{C}$
%		\[\begin{tikzcd}
%			A & C & B \\
%			& {A\times B} \\
%			A && B
%			\arrow["{q_1}"', from=1-1, to=2-2]
%			\arrow["{q_2}", from=1-3, to=2-2]
%			\arrow["{p_1}"', from=2-2, to=3-1]
%			\arrow["{p_2}", from=2-2, to=3-3]
%			\arrow["{1_B}"', from=1-3, to=3-3]
%			\arrow["{1_A}"', from=1-1, to=3-1]
%			\arrow["{r_1}", from=1-1, to=1-2]
%			\arrow["{r_2}"', from=1-3, to=1-2]
%			\arrow["{f}"',dashed, from=2-2, to=1-2]
%		\end{tikzcd}\]
%		Define $f: A\times B \to C$ as $f=r_1p_1+r_2p_2$. Now $fq_1=r_1$ and $fq_2=r_2$ if we show uniqueness of $f$ we are done.
%		
%		Say $f'$ then $(f-f')1_{A \times B}=(f-f')(q_1p_1+q_2p_2)=0$. So $f=f'$.
%		
%		
%	\end{proof}
%	
%	
%	\begin{definition}[Additive category]
%		An Ab-Enriched category which has all finite (co)products (i.e. biproducts since they coincide).
%	\end{definition}
%	
%	\begin{example}
%		The category of vector bundles over a topology $X$ is a additive category (but not an abelian category). We will see this in more detail in the following section.
%	\end{example}
%	Functors between additive categories are called \textit{additive functors}. And can be realized as functors which preserve additivity of homomorphisms between modules, $F(f+g)=F(f)+F(g).$
%	
%	Before proceeding further it is important to think about kernels and cokernels in the categorical sense.
%	\begin{definition}[Kernel]
%		A kernel of a morphism $f:A \to B$ is the pullback along the unique morphism from $0 \to B$, i.e. it is $p: \ker f \to A$. Provided initials and pullbacks exist.
%		
%		\[\begin{tikzcd}
%			{\ker f} && 0 \\
%			\\
%			A && B
%			\arrow["f", from=3-1, to=3-3]
%			\arrow[from=1-3, to=3-3]
%			\arrow[from=1-1, to=1-3]
%			\arrow["p"',from=1-1, to=3-1]
%			\arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=1-1, to=3-3]
%		\end{tikzcd}\]
%	\end{definition}
%	The intuition behind this definition is that alternatively it is seen as an equalizer of a function $f:A \to B$ and the unique zero morphism $0_{A,B}$. The kernel object is the part of the domain that is 'going to zero'. \footnote{A minor point to note is that in the case of Ab-Enrichments the `zero' in the Hom-sets isn't a terminal, its Hom-set specific. When you assume a Ab-Enriched category has a initial 0 however this matches up with our intuition.}
%	
%	A cokernel is simply its dual.
%	
%	\begin{definition}[Pre-abelian categories]
%		An additive category with all morphism having kernels and cokernels.
%	\end{definition}
%	The above definition is equivalent to saying a pre-abelian category is a Ab-Enriched category with all finite limits and colimits. This is a consequence to the fact that categories have finite limits iff it has finite products and equalizers \cite[Proposition~5.21]{Awodey}. And we know equalizers exist because equalizers of two morphisms is just the kernel of $f-g$.
%	
%	
%	
%	
%	\begin{definition}[Abelian category]
%		Pre-abelian categories for which each monomorphism is a kernel and each epimorphism is a cokernel.
%	\end{definition}
%	Equivalently a category is abelian if its pre-abelian and $\bar{f}$ is an isomorphism in the canonical decomposition of $f:A\to B$ as $$A \twoheadrightarrow \coker \ker f \xrightarrow{\bar{f}} \ker \coker f  \hookrightarrow B.$$
%	\begin{example}\label{expreabnotab}
%		
%		\begin{enumerate}Some non examples are:
%			\item The category of hausdorff topological abelian groups is pre-abelian but not abelian. Since not every morphism which is a mono+epi is necessarily a isomorphism. 
%			
%			Consider a Hausdorff abelian topological group $G$ with a non discrete topology and consider $G'$ it's discretization. The inclusion map $G' \to G$ is a mono+epi but not isomorphic. 
%			\item The category of torsion free abelian groups ($\mathrm{TFAb}$) is pre-abelian but not abelian as the mono $f: \Z \xrightarrow{z\mapsto 2z} \Z $ is not a kernel of some morphism. Say it were and there exists $ A \in \mathrm{TFAb}$ such that $f$ is the kernel to $ g: \Z \to A$, i.e.
%			\[\begin{tikzcd}
%				Z & 0 \\
%				Z & A
%				\arrow[from=1-1, to=1-2]
%				\arrow["{f(z)=2z}"', from=1-1, to=2-1]
%				\arrow["\lrcorner"{anchor=center, pos=0.125}, draw=none, from=1-1, to=2-2]
%				\arrow[from=1-2, to=2-2]
%				\arrow["g", from=2-1, to=2-2]
%			\end{tikzcd}\]
%			 this implies $1_\Z$ factors through $f$ i.e. $1_\Z =f\circ h$ for some unique $h:\Z \to \Z $ which implies $h(1)=1/2$ which is absurd.
%		\end{enumerate}
%		
%	\end{example}
%	\begin{example}Some examples of abelian categories:
%		\begin{enumerate}
%			\item The category of modules.
%			\item Category of representations of a group
%			\item Category of sheaves of abelian groups on some topological space.
%			
%			%		\begin{definition}[Presheaf]
%				%			For a category $\mathcal C$ a presheaf is any functor $F: \mathcal{C}^{\mathrm{op}}\to \mathbf{Sets}$.
%				%		\end{definition}
%			%		In particular in the case for a topological space $X$ a presheaf of groups (or any algebraic object) on $X$ (in particular the set of the lattice of open sets of $X$ ordered by inclusion) is a some contravariant functor $F$ which sends open sets $U \subseteq X$ to some $F(U)$, it respects inclusions (i.e. there for open sets $V \subseteq V $ is a natural transformation $\rho_{UV}: F(U)\to F(V)$ in the form of a restriction). Furthermore, function composition, unitals and empty sets going to empty sets hold (to make it a category). Note that all these notions of presheaves are really just a special case of the categorical definition where the sheaf of groups is really just a group object in the categorical presheaf.
%			%		\begin{definition}[Sheaf of sets on a topology]\label{def:scheaf}
%				%			A sheaf of a topology $X$ is a presheaf which satisfies two additional properties, for open sets $U \in X$ and open covers ${U_i}$ of $U$
%				%			\begin{enumerate}
%					%				\item (Locality) A section, i.e. an element $s \in F(U)$ goes to zero restricted at $U_i$ for all $i$ implies $s=0$.
%					%				\item (Gluing) If there is a collection of sections $s_i \in F(U_i)$ such that $s_i|_{U_i \cap U_j}=s_j|_{U_i \cap U_j}$ for all $i,j$ then there is some $s \in F(U)$ such that $s|_{U_i}=s_i$ for all $i$.
%					%			\end{enumerate}
%				%			
%				%			These two conditions can be written is short as just saying we require $F(U)$ to be the equalizer for the following diagram
%				%			\[\begin{tikzcd}
%					%				{\prod_{i \in I} F(U_i)} && {\prod_{i,j}F(U_i \cap U_j)}
%					%				\arrow[shift right=2, from=1-1, to=1-3]
%					%				\arrow[shift left=2, from=1-1, to=1-3]
%					%			\end{tikzcd}\]
%				%		\end{definition}
%			%		
%			%		The category of sheaves of abelian groups on a topological space form a abelian category. Additivity is natural due to the functorial nature of $F$. A quick proof is due to `sheafification', i.e. the left adjoint to the inclusion functor from sheaves into presheaves. Presheves of abelian groups can be understood to have all the required properties to be an Abelian category due the functorial representation. Now due to the following result \cite[Sec. 6.17]{stacks1} we can extend this notion to the sheaves via sheafification.
%		\end{enumerate}
%	\end{example}
%	
%	With this definition in mind we will now define a few important constructions we will use often. These are not restricted to abelian categories but we will use them very often in the case of abelian categories, so it is good to see it in action directly with the notion of an abelian category at hand.
%	\begin{definition}[Subobject]
%		A subobject for some $X \in \mathcal{C}$ is a monomorphisms into $X$. 
%	\end{definition}
%	
%	
%	With slight abuse of notation we refer to $Y \leq X$ as a subobject of $X$ where $Y$ is just a representative of the codomain of a isomorphism class of monomorphisms into $X$. In particular for$X, Z \rightrightarrows X$ monics $Z, X$ belong to the same subobject class if the morphisms are isomorphic, i.e. there exists an isomorphism between $Y \to Z$ making the triangle commute. 
%	
%	This is clearer when seen through the lens of a slice category. Note that arrows between subobjects of the same $X$ are arrows in the slice category of $X$. So collection of subobjects form a category with a preorder (with inclusion). The reasoning behind such an definition for subobjects is motivated by the fact that we think of generalized elements in $\mathcal{C} $ as being not $X \in \mathrm{Ob}(\mathcal{C}) $ but rather $\Hom_\mathcal{C}(-,X)$.
%	
%	\begin{definition}[Quotients in abelian categories]
%		For $Y \leq X$ in an abelian category we can define $X/Y $ as the cokernel of the monomorphism $Y \to X$. 
%	\end{definition}
%	
%	\begin{definition}[Extension/short exact sequences in abelian categories]
%		For $ A, B \in \mathcal{A}$ an extension by $A$ of $B$ refers to some $E \in \mathcal{A}$ such that $0 \to A \to E \to B \to 0$ is a short exact sequence.
%	\end{definition}
%	
%
%
%	
%	A deep result on abelian categories is the Freyd-Mitchel embedding theorem which helps characterize all small abelian categories in terms of modules.
%	
%	\begin{theorem}[Freyd-Mitchell]
%		Every small abelian category can be faithfully embedded as a full subcategory via an exact functor into $R-$Mod for some ring $R$.
%	\end{theorem}
%	The proof for the theorem is very extensive and as such is omitted. The canonical reference is Freyd's own book \cite{freyd1964abelian}. A proof sketch summarising Freyd's proof is given in an excellent MathOverflow post by the user Theo Buehler \cite{47762}.
%	
	\section{Chain complexes and exact sequences}
%	In this section we define and prove the essential homological algebra results that we require. For further details refer to \cite{eisenbud2013commutative, weibel_1994}. 
	
%	All of the results below stated for modules over rings apply for abelian categories. The proofs performed via diagram chases are well defined under the Freyd-Mitchel embedding on the full subcategory of the given diagram only.
	
	\begin{definition}[Chain complex]
		A {chain complex} $(A_\bullet, \varphi_\bullet)$ is a collection of modules over a commutative ring and homomorphisms $\varphi_i: A_i \to A_{i-1}$ such that $\varphi_i \varphi_{i+1}=0$.
		\[\begin{tikzcd}
			\cdots & {A_{i+1}} & {A_i} & {A_{i-1}} & \cdots
			\arrow["{\varphi_{i+1}}", from=1-2, to=1-3]
			\arrow["{\varphi_i}", from=1-3, to=1-4]
			\arrow["{\varphi_{i-1}}", from=1-4, to=1-5]
			\arrow["{\varphi_{i+2}}", from=1-1, to=1-2]
		\end{tikzcd}\]
	\end{definition}
	\begin{definition}[Chain (Co)Homology]
		The {homology} of the complex at $F_i$ is denoted as its $i^{\mathrm{th}}$ homology defined as follows,
		\[ H_iA := \ker \varphi_i/ \mathrm{im} \varphi_{i+1}. \]
		Reversing the arrows gives us the analogous definitions for cochain complexes and cohomology.
	\end{definition}
	
	
	The homomorphisms are often called {`boundary operators'} or {`differentials'}. This nomenclature is motivated by de Rahm cohomology. Furthermore elements of $\ker \varphi_i$ are called `{cycles}' and elements of $\mathrm{im} \varphi_{i+1}$ are called {boundaries}, this echoes the aphorism `cycles modulo boundaries' often encountered in singular homology.
	\begin{definition}[Exact sequence]
		A chain complex is said to be {exact} if all its homologies are zero. In particular it is exact at one object if its homology there is zero.
	\end{definition}
	 An exact sequence of the form \[ 0 \to A \to B \to C \to 0 \]
	is referred to as short exact sequence. Note that due to the exactness conditions $A \to B $ is injective and $B \to C$ is surjective.
	\begin{proposition}[Splitting lemma]
		For a short exact sequence $$0 \to A \xrightarrow{f} B \xrightarrow{g} C \to 0$$ the following are equivalent:
		\begin{enumerate}
			\item The sequence splits, i.e. $B \cong A \oplus C.$
			\item Left split: There is a morphism $h:B \to A $, such that $hf=1_A$.
			\item Right split: There is a module morphism $i: C \to B $ such that $gi=1_C$.
		\end{enumerate}
	\end{proposition}
%	\begin{proof}
%		Begin by showing $1$ and $2$ are equivalent then $1$ and $3$.
%		
%		
%	\end{proof}
	
%	\begin{definition}[Chain homotopy]\label{chainhomotopy}
%		If $\alpha, \beta $ are maps between differential modules $(A, \varphi), (B, \psi )$ then $\alpha $ is homotopically equivalent to $\beta $ if there is a map $h: A \to B $ such that $\alpha - \beta = \psi h+ h \varphi$. If grading is relevant the picture formed is as such, we require a family of maps $h_i: A_i \to B_{i+1}$ \footnote{i.e. It has degree $1$, sometimes the subscript is dropped and just treated as $h$}
%		\[\begin{tikzcd}
%			\cdots && {A_i} && {A_{i-1}} && \cdots \\
%			\\
%			\cdots && {B_i} && {B_{i-1}} && \cdots
%			\arrow["{\varphi_i}", from=1-3, to=1-5]
%			\arrow["{\psi_i}"', from=3-3, to=3-5]
%			\arrow["{h_{i-1}}"', from=1-5, to=3-3]
%			\arrow["{\beta_i}"', shift right, from=1-3, to=3-3]
%			\arrow[from=3-3, to=3-1]
%			\arrow["{h_i}"', from=1-3, to=3-1]
%			\arrow["{\alpha_{i-1}}", shift left, from=1-5, to=3-5]
%			\arrow[from=1-1, to=1-3]
%			\arrow["{h_{i-2}}"', from=1-7, to=3-5]
%			\arrow[from=1-5, to=1-7]
%			\arrow["{\alpha_i}", shift left, from=1-3, to=3-3]
%			\arrow["{\beta_{i-1}}"', shift right, from=1-5, to=3-5]
%			\arrow[from=3-5, to=3-7]
%		\end{tikzcd}\]
%		The intution behind this particular choice of definition is that the map $\alpha - \beta $ maps all cycles to boundaries which have zero homology. So really $\alpha- \beta$ is null homotopic, as such this relation is an equivalence relation.
%	\end{definition}
%	\begin{definition}[Quasi-isomorphism]
%		A chain map is called a quasi isomorphism if the induced map on the homologies constituents an isomorphism.
%	\end{definition}
%	The reason for `quasi' is that the relation is reflexive and transitive but not symmetric. 
%	\begin{definition}[Homotopy category of chain complexes]
%		For a given category of chain complexes $\mathrm{Ch}(\mathcal{A})$ we can define $\mathcal{K}(\mathcal{A})$ to be the homotopy category of chain complexes with objects as objects of $\mathrm{Ch}(\mathcal{A})$ and arrows as chain homotopic maps as in Definition\ref{chainhomotopy}.
%	\end{definition}
	
	\section{Projective modules}	
	The category of finitely generated projective modules is the main object of study in algebraic K-theory. This is largely motivated by a theorem due to Swan's which we will prove in the next project.
	
	Recall the definition of a free module.
	\begin{definition}[Free module of rank $n$]
	A module over a ring $A$ is said to be free with rank $n$ if it is isomorphism to a module of the form $A^n$.
	\end{definition}In particular this means that there exists a linearly independent spanning set of the module with $n$ elements.
	
	Note homomorphisms from free modules to other modules are determined by the image of their generators.
%	, i.e. free objects are left adjoints to forgetful functors. \footnote{This holds in free monoids $\mathrm{Hom}_\mathbf{Mon}(F(X), M) \cong \mathrm{Hom}_\mathbf{Sets} (X, U(M))$ where $F(X)$ denotes the free monoid generated by elements from the set $X$ and $U(M)$ is the underlying set of a monoid $M$, refer to \cite[p. ~208]{Awodey} }
	\begin{definition}[Projective module]
		A module $P$ is said to be {projective} if it satisfies the following lifting property, every morphism from $P$ to $N$ factors through an epimorphism into $N$. Note that the lift need not be unique.
		\[\begin{tikzcd}
			&& M \\
			\\
			P && N
			\arrow[two heads, from=1-3, to=3-3]
			\arrow[from=3-1, to=3-3]
			\arrow[dashed, from=3-1, to=1-3]
		\end{tikzcd}\]
	\end{definition}
	
	
	
	
	\begin{proposition}[Equivalent definitions of projectivity]\label{projtfae}
		The following are equivalent,
		\begin{enumerate}
			\item $P$ is projective.
			\item For all epimorphisms between $M\twoheadrightarrow N$, the induced map $\Hom(P,g):\mathrm{Hom}(P,M) \to \mathrm{Hom}(P,N)$ sending $f \mapsto g \circ f$ for $g:M \to N$ and $f:P \to M$ is an epimorphism.
			\item For some epimorphism from a free module $F$ to $P$, $\mathrm{Hom}(P,F) \to \mathrm{Hom}(P,P)$ is an epimorphism.
			\item There exists $Q$ s.t. $P \oplus Q$ is free.
			\item Short exact sequences of the form $0 \to A \to B \to P \to 0$ split, i.e. isomorphic to another short exact where middle term is $A \oplus P$. \footnote{In general any epimorphisms into projective objects split (i.e. have an inverse).}
		\end{enumerate}
	\end{proposition}
	
	\begin{proof}
		$1 \iff 2$ is restatement of definitions.
		
		$2 \implies 3$ is also just substitution.
		
		$3 \implies 4$ consider a map in the preimage of identity in $\Hom(P,P)$ which is a splitting (inverse) of the epimorphism $F$ into $P$,
		\[\begin{tikzcd}
			& P \\
			\\
			F && P
			\arrow["g", shift left=3, two heads, from=3-1, to=3-3]
			\arrow[""{name=0, anchor=center, inner sep=0}, "f"', from=1-2, to=3-1]
			\arrow[""{name=1, anchor=center, inner sep=0}, "{\mathrm{Id}_P=g \circ f}", dashed, two heads, from=1-2, to=3-3]
			\arrow[shorten <=6pt, shorten >=6pt, Rightarrow, from=0, to=1]
		\end{tikzcd}\]
		Now we have a short exact sequence $0 \to \ker g \to F \to P \to 0$, and also $f\circ g $ is idempotent so it naturally admits a decomposition $F = \image(f \circ g) \oplus \kernel (f \circ g)$\footnote{For some idempotent $e$, $1-e$ is also an idempotent and images under these two mappings decompose any module, furthermore image of $1-e$ is just kernel of $e$}=$\image (g) \oplus \kernel (g)$ the first by the 1st isomorphism theorem and the second by $f $ being a mono.
		
		$4 \implies 2$ simply as $\Hom (P \oplus Q,-) = \Hom(P,-) \oplus \Hom(Q,-)$
		
		$1 \iff 5$ To show that $0\to A \to B \xrightarrow{\varphi} P$ splits we need to show that there exists a $\psi: P \to B$ such that $\varphi \circ \psi = 1_P$. This is just obtained by the definition of $P$ being projective.
		\[\begin{tikzcd}
			&& M \\
			\\
			P && P
			\arrow["\varphi", from=1-3, to=3-3]
			\arrow["\psi", dashed, from=3-1, to=1-3]
			\arrow["{=}", from=3-1, to=3-3]
		\end{tikzcd}\]
		
	\end{proof}
	\begin{lemma}[Free modules are projective]
	\end{lemma}
	\begin{proof}
		Consider the preimages of images of basis of $P$ in $N$, that lie in $M$. Then map basis elements from $P$ into these preimages.
	\end{proof}
	\begin{example}[Projective modules are not always free]
		Let $R,S $ be two non-trivial commutative rings with unity, consider $R \oplus S$ as a (free) module over itself. Consider $R \oplus \{0\}$ as a submodule of $R \oplus S$, it is projective as it is a direct summand of $R \oplus S$. However, it cannot be free as $(R \oplus \{0\})^n \not \cong R\oplus S $ for any $n$.
	\end{example}
	
	\begin{theorem}\label{a2}Projective finitely generated modules over local rings are free.
	\end{theorem}
	\begin{proof}
		Pick a minimal set of generators and see its residue classes in $M/\mathfrak{m}M$ as the basis of it as a vector space over $R/\mathfrak{m}$.
		
		Now as for some free module $F, F=\varphi(M)\oplus K$ for some $K$ and some homomorphism $\varphi: M \to F$, (by definition of projective module), 	we get \[ M/\mathfrak{m}M \cong 	F/\mathfrak{m}F = (R/\mathfrak{m})^n\cong R^n\otimes R/\mathfrak{m} \cong F \otimes R/\mathfrak{m} \cong (\varphi(M)\oplus K) \otimes R/\mathfrak{m}\]
		
		Finally we get $M/\mathfrak{m}M \cong M/\mathfrak{m}M \oplus K/\mathfrak{m}K\implies K=\mathfrak{m}K \implies K=0$ by Nakayamas lemma.
	\end{proof}
	This holds for not necessarily finitely generated modules too refer to \cite[Theorem~2.5]{matsumura_1987}	.
	
	Using the convention of \cite{lam1999lectures} we define the rank of a projective module as such.
	\begin{definition}[Rank of a finitely generated projective module]\label{def:rankproj}
		For any finitely generated projective module $P$ over commutative ring $A$ the localization $P_\mathfrak{p} =P \otimes_A A_\mathfrak{p}$ is also a finitely generated $A_\mathfrak{p}$ module, but $P_\mathfrak{p}$ being local is free by Theorem \ref{a2}. So the local rank of $P$ is defined as the rank of the free $P_\mathfrak{p} $ module.
		
		This induces a map $\phi: \mathrm{Spec}(A) \to \Z $ sending each $\mathfrak{p}$ to the local rank of $P$. If $\phi $ is constant and the rank of $P$ is the same for all localizations then we refer to that as the rank of $P$.
	\end{definition}
	
	%	\begin{proposition} If $M$ is a finitely presented module over a Noetherian ring $R$ (prime ideals fin gen) then TFAE
		%		
		%		
		%		\begin{enumerate}
			%			\item $M$ is projective.
			%			\item $M$ localized at maximal ideals is free.
			%			\item A finite set of elements $\{x_i\}^n$ in $R$ generate $R$ such that $M[x_i^{-1}]$ is free over $R[x_i^{-1}]$.
			%		\end{enumerate}		
		%	\end{proposition}
	%	This proceeds just from the previous result.
	%	\begin{lemma}\label{suboffgisfgnoet}
		%		$A$ is Noetherian iff all submodules of finitely generated $A$ modules are finitely generated.
		%	\end{lemma}
	\begin{proposition}\label{submodoffreemodisfreepid}
		For a principal ideal domain $A$ a submodule $M$ of a free module of finite rank say $A^n $ is free, and the submodule has rank $\leq n$.
	\end{proposition}
	\begin{proof}
		We prove this by induction on $n$. When $n=0$ there is nothing to prove. For $n=1$ due to the fact that $A$ is a principal ideal domain the submodules of $A$ (ideals) are one generated i.e. they are rank 1 free modules of $A$.
		
		Proceed via induction. Now consider the case when $n=k$. 
		
		Let $M \subset A^k$ be non zero. Consider the componentwise projection maps $p_i: A^{k} \to A$ for each $i$. Then $\pi_i(M) \neq \{0\}$ for some $i$. Therefore $p_i(M)$ is a non-zero ideal in $A$, i.e. free with rank 1. Also, $\ker p_i \cap M$ is a submodule of $\ker p_i$ which is itself free of rank $n-1$. Therefore rank of $\ker p_i \cap M$ is $\leq n - 1$. Let $a$ be a generator for $p_i(M)$ consider some preimage of it as $a_p$.
		
		Now $M = \ker p_i \cap M \oplus \langle a_p \rangle$. If $\{a_1, a_2, \cdots a_m\}$ is a basis of $\ker p_i \cap M$, then $\{a_1, a_2, \cdots a_m, a_p \}$ is a basis of $M$. Hence rank of $M$ equals $m + 1 \leq n$. 
		
	\end{proof}
	
	\begin{proposition}\label{projfgpidfree}
		Projective finitely generated modules over principal ideal domains are free.
	\end{proposition}
	\begin{proof}
		Every finitely generated projective module $P$ is a direct summand of a free module $F$ meaning it is a submodule of $F$ and by Proposition \ref{submodoffreemodisfreepid} it is free.
	\end{proof}
	
	\begin{definition}[Stably isomorphic]\label{stabiso}
		Two $A-$modules $M,N$ are said to be stably isomorphic if there exists $r$ such that $M \oplus A^r \cong M \oplus A^r$.
	\end{definition}
	\begin{definition}[Stably free module]\label{stabfree}
		An $A$ module $M$ is stably free if there exists a finitely generated free module $F$ such that $M \oplus F$ is free, i.e. if $M$ is stably isomorphic to a finitely generated free $A$ module.
	\end{definition}
	
	%		Note If $R$ is local and $M$ is fin-gen projective module then $M$ is free, this is a consequence of Nakayama. As $M \oplus Q = R$ so if $R$ has maximal ideal $\mathfrak{m}$ then $M/\mathfrak{m}M$ is a vector space	over the field $R/\mathfrak{m}R$ and its basis lifts to minimal set of generators of $M$, consider $N=M/\sum R m_i$ and so $ N/ IN=M/(IM+\sum_i R m_i)=M/M=0\implies N=IN$ then apply typical Nakayama to get $N=0
	%		\implies M= \sum_i R m_i$, for $I$ an ideal inside the Jacobson radical of $R$
	%		
	%		So now to prove $1 \iff 2 $ consider a finitely presented module localized over 
	%		
	%		If $M,N$ finitely presented over $R$ and their localizations are isomorphic then theres some element of $f\in R-P$ such that $M[f^{-1}] \cong N[f^{-1}]$
	
%	
%	\section{Long exact sequence of homologies}
%	
%	Consider $(A,\varphi),(B,\psi),(C,\chi)$ to be chain complexes we can define a short exact sequence of complexes as \[ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 \]
%	For $\alpha, \beta $ maps of complexes as discussed above, and $\beta \alpha=0$, if for all $i$ the underlying sequence of modules is exact\[ 0 \to A_i \xrightarrow{\alpha_i } B_i \xrightarrow{\beta_i } C_i \to 0\]
%	
%	These maps also induce maps on the homologies $\alpha_i: H_i A \to H_i B, \beta_i: H_i B \to H_i C$. Furthermore there is a natural map \[ 	\delta_i : H_i C \to H_{i-1}A	 \] which is called the \textbf{connecting homomorphism}
%	
%	Before seeing how to construct this $\delta $ it is useful to have a complete picture of the data in front of us. This can be seen below,
%	\[\begin{tikzcd}
%		& \vdots & \vdots & \vdots \\
%		0 & {A_i} & {B_i} & {C_i} & 0 \\
%		0 & {A_{i-1}} & {B_{i-1}} & {C_{i-1}} & 0 \\
%		0 & {A_{i-2}} & {B_{i-2}} & {C_{i-2}} & 0 \\
%		& \vdots & \vdots & \vdots
%		\arrow[from=2-1, to=2-2]
%		\arrow["{\alpha_i}", from=2-2, to=2-3]
%		\arrow["{\beta_i}", from=2-3, to=2-4]
%		\arrow[from=2-4, to=2-5]
%		\arrow[from=3-1, to=3-2]
%		\arrow[from=4-1, to=4-2]
%		\arrow["{\alpha_{i-1}}", from=3-2, to=3-3]
%		\arrow["{\beta_{i-1}}", from=3-3, to=3-4]
%		\arrow[from=3-4, to=3-5]
%		\arrow["{\alpha_{i-2}}", from=4-2, to=4-3]
%		\arrow["{\beta_{i-2}}", from=4-3, to=4-4]
%		\arrow[from=4-4, to=4-5]
%		\arrow["{\varphi_i}"', from=2-2, to=3-2]
%		\arrow["{\varphi_{i-1}}"', from=3-2, to=4-2]
%		\arrow[from=4-2, to=5-2]
%		\arrow[from=1-2, to=2-2]
%		\arrow[from=1-3, to=2-3]
%		\arrow[from=1-4, to=2-4]
%		\arrow["{\psi_i}"', from=2-3, to=3-3]
%		\arrow["{\chi_i}"', from=2-4, to=3-4]
%		\arrow["{\psi_{i-1}}"', from=3-3, to=4-3]
%		\arrow["{\chi_{i-1}}"', from=3-4, to=4-4]
%		\arrow[from=4-3, to=5-3]
%		\arrow[from=4-4, to=5-4]
%	\end{tikzcd}\]
%	We construct via a diagram chase. Suppose $h \in H_i C= \ker \chi_i / \image \chi_{i+1} $ pick a cycle $x\in \ker \chi_i$. As $\beta_i $ is surjective we know there exists $y \in B_i$ s.t. $\beta_i(y)=x $. Now also by the fact that $x\in \ker \chi_i$ and that we have maps between chain complexes so the squares commute. We have that $\beta_{i-1}(\psi_{i}(y))=\chi_i(\beta_i(y))=\chi_i(x)=0$.
%	
%	Now there is some $z \in A_{i-1}$ such that $\alpha_{i-1}(z)=\psi_i(y)$ (this is due to exactness of $i-1$ sequence hence the quotient isomorphism and the above condition).
%	
%	As $\alpha_{i-2}$ is a monomorphism $\alpha_{i-2} \varphi_{i-1}(z)=\psi_{i-1}\alpha_{i-1}(z)=\psi_{i-1}\psi_{i}(y)=0$ so $z\in \ker \alpha_{i-1}$. Just define $\delta_i(h) $ to be the image of $z$ in $H_{i-1}A$.
%	
%	The above definition is well defined as it is independent of the choice of lift $x$. Pick any other lift say $x'$ now $\beta_i(x-x')=x-x=0$. So it has a preimage in $A_i$ and can be given as an embedding from $A_i \to B_i$ so $x-x' \in A_i$. $\phi_i(x-x')=\psi_i x - \psi_i x'$ which implies their images in $H_{i-1}A$ are homotopic.
%	
%	The fact that $\delta_i $ is a group homomorphism is simply via linearity.
%	
%	\begin{proposition}[Induced long exact sequence of homology]
%		For a given short exact sequence 
%		\[ 0 \to A \xrightarrow{\alpha } B \xrightarrow{\beta } C \to 0\]
%		of chain complexes $(A, \varphi), (B, \psi), (C, \chi)$, then the connecting homomorphism $\delta_i: H_iC \to H_{i-1}A$ induces the following long exact sequence of homologies
%		\[\begin{tikzcd}
%			& \cdots & {H_iC} \\
%			{H_{i-1}A} & {H_{i-1}B} & {H_{i-1}C} \\
%			{H_{i-2}A} & \cdots
%			\arrow[from=1-2, to=1-3]
%			\arrow[from=2-1, to=2-2]
%			\arrow[from=2-2, to=2-3]
%			\arrow["{\delta_i}"{description}, from=1-3, to=2-1]
%			\arrow["{\delta_{i-1}}"{description}, from=2-3, to=3-1]
%			\arrow[from=3-1, to=3-2]
%		\end{tikzcd}\]
%		
%		Furthermore if the chain complexes are differential modules the following triangle commutes,
%		\[\begin{tikzcd}
%			HA && HB \\
%			& HC
%			\arrow["\alpha", from=1-1, to=1-3]
%			\arrow["\beta", from=1-3, to=2-2]
%			\arrow["\delta", from=2-2, to=1-1]
%		\end{tikzcd}\]
%		
%	\end{proposition}
%	
%	\begin{lemma}[Snake lemma]
%		\[\begin{tikzcd}
%			& A & B & C & 0 \\
%			0 & {A'} & {B'} & {C'}
%			\arrow[from=1-2, to=1-3]
%			\arrow[from=1-3, to=1-4]
%			\arrow[from=1-4, to=1-5]
%			\arrow[from=2-1, to=2-2]
%			\arrow[from=2-2, to=2-3]
%			\arrow[from=2-3, to=2-4]
%			\arrow["\alpha", from=1-2, to=2-2]
%			\arrow["\beta", from=1-3, to=2-3]
%			\arrow["\gamma", from=1-4, to=2-4]
%		\end{tikzcd}\]
%		The above commutative diagram induces a exact sequence \[ \ker \alpha \to \ker \beta \to \ker \gamma \to \mathrm{coker}\alpha \to \mathrm{coker}\beta \to \mathrm{coker}\gamma \]
%	\end{lemma}
%	\begin{proof}
%		The map $\ker \gamma \to \mathrm{coker} \alpha $ is given by the connecting homomorphism.
%	\end{proof}
%	
%	\begin{lemma}[5-lemma]
%		If we have a commutative diagram as such,
%		\[\begin{tikzcd}
%			A & B & C & D & E \\
%			{A'} & {B'} & {C'} & {D'} & {E'}
%			\arrow[from=1-1, to=1-2]
%			\arrow["\alpha"', from=1-1, to=2-1]
%			\arrow[from=1-2, to=1-3]
%			\arrow["\beta"', from=1-2, to=2-2]
%			\arrow[from=1-3, to=1-4]
%			\arrow["\gamma"', from=1-3, to=2-3]
%			\arrow[from=1-4, to=1-5]
%			\arrow["\delta"', from=1-4, to=2-4]
%			\arrow["\epsilon"', from=1-5, to=2-5]
%			\arrow[from=2-1, to=2-2]
%			\arrow[from=2-2, to=2-3]
%			\arrow[from=2-3, to=2-4]
%			\arrow[from=2-4, to=2-5]
%		\end{tikzcd}\]
%		and if $\beta, \delta $ are isomorphisms with $\alpha $ epimorphism and $\epsilon $ a monomorphism implies that $\gamma $ is an isomorphism.
%	\end{lemma}
%	
	\section{Resolutions}
	
	\begin{definition}\label{defresolution}[Left resolution]
		Given a module $M$ its {left resolution} is given by the data of a exact sequence $(A_\bullet, \varphi_\bullet)$ into $M$ as such,
		\[ 	\dots \to A_1	\to A_0 \xrightarrow{\epsilon} M \to 0 \]
		where $\epsilon $ is called the {augmentation map}, if the exact sequence is free its a free resolution and such for projective. 
	\end{definition}
	
%	
	If we have a cochain complex instead it forms a {right resolution} and if its elements are injective we call them injective resolutions.
	
	We cover a result about stably free modules. We will revisit this in greater detail in further sections.
		\begin{lemma}\label{stabfreefinfreeres}
		A projective module is stably free iff if has a finite free resolution.
	\end{lemma}
	\begin{proof}
		Say $M \in A-$Mod and is projective. Then $M$ is stably free implies $M \oplus A^n \cong A^m$ for some $n,m$. So $M$ has a finite free resolution given by
		\[ 0 \to A^n \to A^m \to M \to 0 \]
		Conversely if $M$ is a projective module with a finite free resolution.
		\[ 0 \to F_n \to \cdots \to F_0 \to M \to 0 \] for $F_i$ free modules over $A$.
		
		We proceed via induction on $n$. If $n=0$ then we are done as simply $M$ is free.
		Let $M_1$ denote the kernel of $F_0 \to M$. Since $M$ is projective, $F_0 = M \oplus M_1$. Now $M_1$ is projective and has a free resolution of length $< n$.
		
		Thus, by the induction hypothesis, $M_1 \oplus F$ is free for some finite free module $F$, i.e. $M_1$ is stably free.
		
		Consequently $F_0 \oplus F$ is trivially finitely free and so $F_0\oplus F \cong (M\oplus M_1) \oplus F \cong M \oplus (M_1 \oplus F)$ is finite free, i.e. $M$ is stably free.
	\end{proof}
	
%	\begin{theorem}\label{finitefreeresolutionninelemma}
%		Given a short exact sequence $0 \to A \to B \to C\to 0$. If any two of these modules have a finite free resolution then so does the third.
%	\end{theorem}
%	
%	\begin{proposition}[Horseshoe lemma]
%		If there is a short exact sequence of modules,
%		\[ 0 \to M \to N \to P \to 0 \]
%		and both $M,P$ have a projective resolutions $A, C$ 
%		\[\begin{tikzcd}
%			&&& 0 \\
%			\cdots & {A_1} & {A_0} & M & 0 \\
%			&&& N \\
%			\cdots & {C_1} & {C_0} & P & 0 \\
%			&&& 0
%			\arrow[from=2-4, to=2-5]
%			\arrow[from=1-4, to=2-4]
%			\arrow[from=2-4, to=3-4]
%			\arrow[from=3-4, to=4-4]
%			\arrow[from=4-4, to=4-5]
%			\arrow[from=4-4, to=5-4]
%			\arrow[ from=4-3, to=4-4]
%			\arrow[ from=2-3, to=2-4]
%			\arrow[from=2-1, to=2-2]
%			\arrow[from=2-2, to=2-3]
%			\arrow[from=4-1, to=4-2]
%			\arrow[from=4-2, to=4-3]
%		\end{tikzcd}\]
%		as below then $N$ also has a projective resolution $B$ which forms a short exact sequence. Also the sequence splits due to $C_i$ being projective so $B_i=A_i \oplus C_i$.
%	\end{proposition}
%	\begin{proof}
%		First note $\epsilon_P: C_0 \to P$ lifts due to projectivity to $C_0 \to N$ also $A_0\to N$ via composition so simply define $B_0 = A_0 \oplus C_0$. This is an epimorphism evidently via diagram chase. Also is projective as direct sum of projectives is projective. Now consider direct sum of kernel of $A_0 \to M, B_0 \to N, C_0 \to P$ and construct the direct sum again to get $F_1$.	Now we get a $3\times 3$. Exactness is due to the Snake lemma
%	\end{proof}

	
%	\section{Puppe/Homotopy cofiber sequence}
%	The discussion in this section follows \cite{weibel_1994}.
	
	%	\textbf{TO DO: KOSZKUL COMPLEX AND HILBERT SYZYGY}
	%	We previously saw the definition of a bilinear map when discussing tensor products. Now consider $n$- linear maps for some map between $R$-Modules $M,P$. Repeated application of the tensor product still provides us with universal such module, $M^n \to \otimes_{i=1}^n M$.
	%	
	%	Also a map is called $n$-alternating if it vanishes when two of the arguments are the same. This also implies that sign changes when the arguments are interchanged. Also for a permutation the sign change changes to the sign of the permutation. Now when we require a notion of a universal $n$-linear alternating map we arrive to the definition of a wedge product.
	%	
	%	In particular for a specific $n$. There is a universal alternating $n$-linear map sending $M \to \Lambda^n M$. If $M$ is finitely generated by $r$ elements then $\Lambda M^n$ is a free module of rank $\binom{r}{n}$.
	%	
	%	\begin{definition}[Tensor algebra]
		%		For a $R$-Module $M$ and $T^n M = \otimes^n M$ the tensor algebra is defined to be \[ T(M)=\oplus_{n=0}^\infty T^n M \]
		%	\end{definition}
	%	
	%	
	%	
	%	\begin{definition}[Exterior algebra and wedge product]
		%		For an $R$-Module $M$. Consider the Tensor algebra $T(M)=\oplus_n \otimes^n M	$. Consider the ideal $I$ spanned by elements $v \otimes v$ for $v \in T(M)$.
		%		
		%		The quotient of $T(V)/I := \Lambda(M) $ is called the exterior algebra and its product the wedge product.	It is universal with respect to multilinear alternating maps.
		%		
		%		For $v \Lambda^nM, w \in \Lambda^m M$ multiplication is defined as such,
		%		\[ v \Lambda w = (-1)^{nm} w \Lambda v\]
		%	\end{definition}
	%	
	%	
	%	\begin{definition}[Koszkul complex]
		%		For a $R$-module $M$ there is an associated chain complex of $n^\textbf{th}$ exterior algebras
		%		\[ \Lambda^n M \to \Lambda^{n-1} M \to \dots \to \Lambda^0 M \cong M \]
		%	\end{definition}
	%	
	%	
	%	\begin{definition}[Regular sequence]
		%		A sequence of elements $r_1,\dots,r_n$ is said to be a regular sequence in $R$ if $r_1$ is not a zero divisor of $R$, $r_2$ is not a zero divisor of $R/\langle r_1\rangle $, and so on
		%	\end{definition}
	%	\begin{proposition}
		%		For a finite regular sequence $\{r_i\}_{i=1}^n$ of a ring $R$ the Koszkul complex forms the canonical free resolution of $R/\langle r_1,\dots,r_n\rangle$ of the form
		%		\[ 0 \to R^{\binom{n}{n}} \to \dots \to R^{\binom{n}{1}} \to R \to R/\langle r_1,\dots, r_n \rangle \to 0\]
		%	\end{proposition}
	%	\begin{proof}
		%		TO DO
		%	\end{proof}
	

%		\section{Vector bundles}
%	 In this section, we introduce the foundational concepts required to prove Swan's theorem, which demonstrates a key connection between projective modules and vector bundles over certain topological spaces. The purpose of proving Swan's theorem is to highlight why projective modules play a central role in algebraic $K$-theory, serving as essentially algebraic counterparts to vector bundles.
%	
%	All results presented hold for both real and complex vector bundles. For simplicity, we use $k$ to denote the underlying field. 
%	
%	More detailed exposition can be found in \cite{milnor1974characteristic, karoubi2008k}.
%	
%	\begin{definition}[Vector bundle]
%		A $n$ dimensional vector bundle over $k$ is a triple $(E,p, X)$. Which consists of a continuous map $p:E \to X$ from the total space $E$ to the base space $X$. Such that for all $x \in X$, $E_x=p^{-1}(x)$ the fibre of $x$ has a $k$ vector space structure. Along with the following property of local trivialization
%		\begin{enumerate}
%			\item For any $x \in X$ there exists a open open $U \subset X$ along with a homeomorphism \[ h: X \times k^n	\to p^{-1}(U) \] such that for all $c \in U$ the map through $h$ defines an isomorphism between $E_c$ and $k^n$.
%		\end{enumerate}
%	\end{definition}
%	\begin{example}[Trivial vector bundle]
%		A trivial vector bundle is one in which the total space $E=X \times k^n$ with $p$ just the trivial projection mapping.
%	\end{example}
%	The local trivialization condition can now be understood as saying there exists an open neighbourhood for each point $x \in X$ such that $E|_U$ is a trivial vector bundle
%	\begin{definition}[Quasi-vector bundle]
%		A fibre bundle defined as above without the property of local trivialisation is called a quasi-vector bundle.
%	\end{definition}
%	\begin{definition}[Rank of vector bundle]
%		If each $E_x$ has the same dimension $n$ then $n$ is referred to as the rank of the vector bundle.
%	\end{definition}
%	
%	\begin{example}[Tangent bundle on $S^2$]
%		Let $S^2$ be the unit sphere in $\R^3$ associate to each point $x \in S^2$ the plane tangent to $S^2$ at $x$, label this $T_xS^2$ (this is the tangent space at point $x$) then the disjoint union of all the tangent spaces form a vector bundle $T S^2 = \sqcup_{x \in S^2} T_x S^2.$ 
%	\end{example}
%	We don't use the concept of a tangent bundle proper so we refrain from defining it in its entirety.
%	\begin{definition}[Vector bundle morphisms]
%		Two vector bundles $(E_1,p, X)$ and $(E_2,p_2, X) $ are considered isomorphic if there exists a continuous map between their total spaces $g$ such that the below diagram commutes
%		\[\begin{tikzcd}
%			{E_1} && {E_2} \\
%			& X
%			\arrow["{p_1}"', from=1-1, to=2-2]
%			\arrow["{p_2}", from=1-3, to=2-2]
%			\arrow["g", from=1-1, to=1-3]
%		\end{tikzcd}\]
%		
%		and $g$ induces a vector space homomorphism for each fibre.
%	\end{definition}
%	If $g$ is a homeomorphism and fibrewise isomorphism then it is a vector bundle isomorphism.
%	
%	\begin{definition}[Category of vector bundles]
%		For a fixed base space $B$ the collection of vector bundles over $X$ with arrows as vector bundle homomorphisms forms a category which we denote as $\mathrm{VB}(X)$.
%	\end{definition}
%	\begin{definition}[Whitney sums]
%		For $(E_1,p_1, X), (E_2,p_2,X)$ their Whitney sum denoted as $E_1 \oplus E_2$ consists of total space as $E_1 \oplus E_2$ with fibrewise direct sums of vector spaces.
%	\end{definition}
%	A Whitney sum is a biproduct of vector bundles in $\mathrm{VB}(X)$. Which makes the category of vector bundles into an additive category, but not abelian. Since the kernel of a morphism of vector bundles need not be a vector bundle. 
%	
%	Along with a Whitney sum there also exists the expected notion of a tensor product of vector bundles this in turn allows us to view $\mathrm{VB}(X)$ as a symmetric monoidal category in the natural way.
%	
%	In the particular case when $E_1=X \times k^n, E_2=X \times k^m$ are both trivial vector bundles over $X$. We can describe the vector bundle morphisms between them explicitly. This is a result we will use very often in the process of proving Swans theorem. 
%	
%	We have associated to the vector bundle morphism $g: E_1 \to E_2$ a natural linear map $g_x: k^n \to k^m$. Consider $\widetilde{g}: X \to \Hom_k(k^n, k^m)$ defined as $\widetilde{g}(x)=g_x.$
%	\begin{theorem}[Characterization of trivial bundle morphisms]\label{thtrivialbundlemorphisms}
%		The map $\tilde{g}: X \to \text{Hom}_k(k^n, k^m)$ is continuous\footnote{Relative to the natural topology on $\text{Hom}_k(k^n, k^m)$. The unique topological vector space topology making any $k^t \cong L(k^n,k^m)$ into a homeomorphism}, and for ${h}: X \to \text{Hom}_k(k^n, k^m)$ continuous, let $\tilde{h}: E \to E'$ be the map which induces $\tilde{h}(x)$ on each fiber. Then $\tilde{h}$ is a morphism of vector bundles.
%	\end{theorem}
%	\begin{proof}
%		Let $\{e_1, \dots, e_n\}$ be a choice of basis for $k^n$ and $\{e'_1, \dots, e'_m\}$ for $k^m$.  
%		
%		Now ${g}_x \in \text{Hom}_k(k^n, k^m)$ is naturally representable by a $m\times n$ matrix $(a_{ij}(x))$.
%		
%		The function $x \mapsto a_{ij}(x)$ is obtained by composing the continuous maps:
%		\[ X \xrightarrow{\beta_j} X \times k^n \xrightarrow{g} X \times k^m \xrightarrow{\gamma} k^m \xrightarrow{p_i} k \]
%		where $\beta_j(x) = (x, e_j)$, $\gamma(x, v) = v$, and $p_i$ is the $i$-th projection onto $k$. Since each $a_{ij}(x)$ is continuous $\tilde{g}$ is continuous.
%		
%		Now consider ${h}: X \to \text{Hom}_k(k^n, k^m)$, continuous. By composing a sequence of continuous maps we obtain the required morphism of vector bundles.
%		\[ X \times k^n \xrightarrow{\delta} X \times \text{Hom}_k(k^n, k^m) \times k^n \xrightarrow{\epsilon} X \times k^m \]
%		where $\delta(x, v) = (x, {h}(x), v)$ and $\epsilon(x, u, v) = (x, u(v))$.
%	\end{proof}
%
%	\begin{proposition}[Sufficient condition for vector bundle isomorphism]\label{propsciso}
%	Let $E$ and $F$ be two vector bundles over $X$, and let $g: E \to F$ be a morphism of vector bundles such that $g_x: E_x \to F_x$ is bijective for each point $x \in X$. Then $g$ is an isomorphism of vector bundles.
%	\end{proposition}
%	
%	\begin{proof}
%		Let $h: F\to E$ be the map defined by $h(v) = g_x^{-1}(v)$ for $v \in F_x$. We need to prove $h$ is continuous and so indeed a map in $\mathrm{VB}(X)$. The other conditions for isomorphisms are clearly met. If we prove continuity locally for every neighbourhood then we have the required continuity globally.
%		
%		 Consider a neighbourhood $U$ of $x$ and the local trivialization isomorphisms $\beta: E|_U \to U \times M$ and $\gamma: F|_U \to U \times N$. Let $g_1 = \gamma g_U \beta^{-1}$. 
%		 
%		 Then $h_U = \beta^{-1} h_1^{-1} \gamma$, where $h_1$ is defined as $\widetilde{h_1}(x) = (\widetilde{g_1}(x))^{-1}$ (as in the above result Theorem \ref{thtrivialbundlemorphisms}), $h_1$ is continuous.  Therefore, $h$ is continuous on a neighbourhood of each point of $F$, implying $h$ is continuous on all of $F$.
%	\end{proof}
%	
%	\section{Sections of a vector bundle}
%	
%	\begin{definition}[Sections of a vector bundle]
%		For a vector bundle $(E,p,X)$ a section refers to a continuous map	$s: X \to E$ such that $p \circ s= 1_X$, where $1_X$ denotes the identity map on $X$.
%		
%		These sections equivalently are a homomorphism of vector bundles from the trivial line bundle $(X \times \R, \pi_X, X) \to (E,p,X)$
%	\end{definition}
%	We assume all sections to be continuous without necessarily specifying it.
%	
%	\begin{definition}[Linear independence of sections]\label{deflinindsections}
%		A sequence $s_1, \cdots, s_n$ of sections on a vector bundle $E$ is said to linearly independent if they are linearly independent for each point $x$.
%		
%		Furthermore the morphism $f: X \times k^n \to E$ given by $(x,c_1, \cdots, c_n) \mapsto \sum_{i=1}^n c_i s_i(x)$ induces an isomorphism of fibres if $E$ has rank $n$ due to Proposition \ref{propsciso}.
%		
%	\end{definition}
%	
%	\begin{example}[Zero section]
%		The map $s:X \to E $ sending every point $x$ to the $0$ vector in $E_x$.	
%	\end{example}
%	\begin{definition}[Vector space of sections]
%		For a vector bundle $p:E \to X $ the set of continuous sections of $E$ is denoted as $\Gamma (X ,E)$. It is a vector space with vector addition defined as $(s+t)(x)=s(x)+t(x)$ and scalar multiplication as $\lambda s (x) = (\lambda s)(x)$ for $\lambda \in k$.	
%	\end{definition}
%	
%	\begin{proposition}[Section functor]\label{sectionfunctor}
%		 $\Gamma(X,E)$ can be realized as a $C(X)$ module where $C(X)$ denotes the ring of continuous functions from $X$ to $k$. With scalar multiplication defined as $(c \cdot s)(x)=c(x) s(x)$ for $s\in \Gamma(X,E), c \in C(X)$.
%		 
%		 For a trivial vector bundle $E=X \times k^n$ we have $\Gamma(X,E)$ corresponds to a free module $ C(X)^n$. If $E$ is a arbitrary vector bundle which is a direct summand of a trivial vector bundle then $\Gamma(X,E) $ corresponds to a projective $C(X)$ module.
%		 
%		 In particular If $E \oplus E' \cong X \times k^n$ we have $\Gamma(X, E) \oplus \Gamma(X,E') \cong \Gamma(X, E \oplus E') \cong C(X)^n$, i.e. $\Gamma: \mathrm{VB}(X) \to \mathrm{Proj}(C(X))$ is an additive functor.
%	\end{proposition}
%	
%	In fact this `stably trivial' property of a vector bundle is always true when $X$ is compact. This is an essential result in the proof of Swans theorem. In order to prove it we need a lemma for paracompact spaces first.
%	\begin{definition}[Paracompact space]
%		A  Hausdorff topological space $X$ is said to be paracompact if every open cover of $X$ has a locally finite open refinement.
%		
%		(An open cover is locally finite if there exists a neighbourhood for every $x \in X$ which intersects only finitely many elements of the cover.
%		A refinement of an open cover $\{U_i\}$ consists of a open cover $\{V_j\}$ such that for each $j, V_j	\subset U_i$ ).
%	\end{definition}
%	
%	\begin{lemma}
%		Let \( X \) be a paracompact space, and let \( E \) and \( F \) be vector bundles over \( X \). Suppose \( \alpha: E \to F \) is a morphism such that \( \alpha_x: E_x \to F_x \) is surjective for each point \( x \in X \). Then there exists a morphism \( \beta: F \to E \) such that \( \alpha \circ \beta = \mathrm{id}_F \).
%	\end{lemma}
%	\begin{proof}
%		In this proof we very liberally use the various morphisms as seen in Theorem \ref{thtrivialbundlemorphisms}.
%		
%		Fix a point $x \in X$ by local trivialization we pick a neighborhood $U$ of $x$ such that $E_U$ and $F_U$ are trivial bundles. That is, $E|_U \cong M \times V$ and $F|_U \cong U \times N$.
%		
%		Now with this representation we have $\alpha|_U: U \times M \to U \times N$, can be expressed as $\tilde{\theta}$ (as in \ref{thtrivialbundlemorphisms}) for the associated continuous map:
%		\(
%		\theta: U \to \mathrm{Hom}_{\mathrm{VB}}(V, W).
%		\)
%		
%		Decomposing $M$ as $N\oplus \ker (\theta (x))$ (which we can do thanks to surjectivity of $\alpha_x$) allows us to choose a matrix representation for $\theta(y):M\to N$ i.e. $\theta(y):N \oplus \ker (\theta( x)) \to N$ as
%		\[
%		\theta(y) = 
%		\begin{bmatrix} 
%			\theta_1(y) & \theta_2(y) 
%		\end{bmatrix},
%		\]
%		the first component goes to 1 and the second to 0 continuously, i.e. an endomorphism of $N$. Realized as a topological vector space $\mathrm{Aut}(N)$ is an open subset (i.e. vector subspace) of $\mathrm{End}(N)$. 
%		
%		Therefore we can pick a neighbourhood of $x$ say $V_x$ such that $\theta_1(y)$ is an isomorphism for $y \in U_x$. Consider associated to this the map $\theta': V_x \to \Hom_{\mathrm{VB}}(N,M)$ represented now by the matrix,
%		\[ \theta'_x(y)=\begin{bmatrix}
%			\theta_1(y)^{-1}\\0
%		\end{bmatrix} \]
%			
%		This now induces the morphism $\tilde{\theta}'_x: F_|{V_x} \to E_|{V_x}$ so that $\alpha_{V_x} \tilde{\theta}'_x = 1$. 
%		
%		Varying the point $x$ enables us to construct a locally finite open cover $\{V_i\}$ of $X$ obeying the following properties, all morphisms $\beta_i: F_{V_i} \to E_{V_i}$ are right inverses of $\alpha_{V_i}$ as seen.
%		
%		Now consider a `partition of unity' $\{ \eta_i\}$ associated with the cover \footnote{A sequence of non negative real valued functions $\{\eta_i \}$ whose sum evaluated for every point $x \in X$ is $1$. And such that every point $x\in X$ has an open neighbourhood not intersecting the support of $\eta_i $ for all but finitely many $i$. Which implies the sums are finite and therefore well defined.} and $\beta:F \to E$ is defined using it as $\sum_{i} \eta_i(x)\beta_i(e)$ for $e\in E_x$. Continuity is maintained due to the fact that these sums are necessarily finite (see footnote). This gives us \[ \alpha \beta (e)= \sum_i \eta_i(x) (\alpha \beta_i) (e) = (\sum_i \eta_i(x)) (\alpha \beta_i (e)) = e \]
%		Which completes the proof.
%	\end{proof}
%	
%	\begin{theorem}\label{stablytrivialcompact}
%		If $E$ is a vector bundle over a compact base space $X$ then there exists a vector bundle $E'$ such that $E \oplus E' \cong X \times k^n$
%	\end{theorem}
%	\begin{proof}
%		Pick a finite open cover \( \{ U_i \}_{i=1}^r \). By local trivialisation we know that \( E|_{U_i} \cong U_i \times k^{n_i} \). 
%		
%		Let \( \{\eta_i\} \) be a `partition of unity' associated to the cover similarly as before. So there exist \( n_i \) linearly independent sections \( s_i^1, s_i^2, \dots, s_i^{n_i} \) of \( E|_{U_i} \) (as seen in Definition \ref{deflinindsections}). By extending these local sections to zero outside \( U_i \), we obtain globally defined sections \( \eta_i s_i^1, \eta_i s_i^2, \dots, \eta_i s_i^{n_i} \), which are linearly independent sections of \( E|_{V_i} \), where \( V_i = \eta_i^{-1}((0,1]) \).
%		
%		Let \( \sigma_i^j \) denote the sections \( \eta_i s_i^j \) for \( 1 \leq j \leq n_i \). These sections \( \sigma_i^j(x) \) generate \( E_x \) as a vector space for each \( x \in X \). As constructed in $Definition \ref{deflinindsections}$, there exists a morphism
%		\[
%		\alpha: T = X \times k^n \to E,
%		\]
%		where \( n = \sum_{i=1}^r n_i \), such that \( \alpha_x: T_x \to E_x \) is surjective for every \( x \in X \).
%		
%		Now by the above Lemma for paracompact spaces, there exists a morphism \( \beta: E \to T \) such that \( \alpha \circ \beta = 1_E \). Let \( E' \) be the kernel of the idempotent morphism \( p = \beta \circ \alpha \). 
%		
%		Define a morphism from \( E \oplus E' \) to \( T \) by taking the sum of $\beta: E\to T $ and the inclusion $i: E' \to T$. This morphism induces a fibrewise isomorphism since \( E'_x \cong \ker(p_x) \) and \( E_x \cong \ker(1-p_x) \). Thus, the morphism is an isomorphism by Proposition \ref{propsciso}	
%	\end{proof}
%	
%	\section{Karoubian categories and some results on vector bundles}
%	In this section we cover an essential theorem which is applied in order to prove Swan's theorem. We follow the results as proven in Karoubi's book \cite{karoubi2008k}.
%	
%	\begin{definition}[Karoubian category]
%		A Karoubi category is an Ab-Enriched category such that every idempotent endomorphism (a morphism of the form $e:A \to A$ such that $e^2=e$) has a kernel.
%	\end{definition}
%	These are sometimes referred to as pseudo-abelian categories (note that in an abelian category proper all morphisms have kernels and cokernels in this case its only the idempotents).
%	\begin{example}
%		The category of vector bundles is Karoubian. We already know it is additive and so Ab-Enriched. In the conclusion of Theorem \ref{stablytrivialcompact} we have implicitly shown that the idempotent $p \in \mathrm{VB}(X)$ has a kernel.
%	\end{example}
%	\begin{example}
%		Hinting towards Swans theorem we can see that also $\mathrm{Proj}(A)$ for a ring $A$ is Karoubian. We will see the relation between projective modules and idempotents in more detail in Sec. \ref{k0withidempotent}
%	\end{example}
%	Idempotent elements occur ubiquitously in $K-$theory we will see another useful application of idempotents in computations of $K_0$.
%	
%	The first theorem we cover in this section is well known by various different names. It involves showing the existence of a Karoubi envelope for an additive category. But this is often referred to as the Cauchy completion or idempotent completion.
%	\begin{theorem}\label{thm:pseudoabelian}[Existence of Karoubi envelope]
%		Let $\mathcal{C}$ be an additive category. Then there exists a Karoubian category $\widetilde{\mathcal{C}}$ and a fully faithful additive functor $\varphi:\mathcal{C} \to \widetilde{\mathcal{C}}$ universal in the sense that for any other additive functor $\psi: \mathcal{C} \to \mathcal{D}$ where $\mathcal{D}$ is Karoubian there exists a unique additive functor ${\psi'}: \widetilde{\mathcal{C}} \to \mathcal{D} $ such that the below diagram commutes.
%		\[\begin{tikzcd}
%			{\widetilde{\mathcal{C}}} \\
%			\\
%			{\mathcal{C}} && {\mathcal{D}}
%			\arrow["{\psi'}",dashed, from=1-1, to=3-3]
%			\arrow["\varphi", from=3-1, to=1-1]
%			\arrow["\psi"',from=3-1, to=3-3]
%		\end{tikzcd}\]
%	\end{theorem}
%	\begin{proof}
%		We directly construct $\widetilde{\mathcal{C}}$ and $\varphi.$ The objects of $\widetilde{\mathcal{C}}$ are of the form $(E,p)$ for $E \in \mathrm{Ob}(\mathcal{C})$ and $p$ idempotent endomorphism over $E$. 
%		
%		Arrows between two such objects $(E,p) $ and $(F,q)$ comprise of the arrows $(f: E \to F) \in \mathcal{C}$ such that $fp=qf=f$. Composition of morphisms is inherited from $\mathcal{C}$. The identity morphism comprises of $1_{(E,p)}=p$, and te sum of two objects $(E,p) \oplus (F,q) $ is defined naturally as $(E \oplus F, p \oplus q)$. This demonstrates that $\widetilde{\mathcal{C}}$ is indeed an additive category. 
%		
%		It remains to be verified that it is indeed Karoubian which is the main concern. Let $f$ be an idempotent endomorphism of the object $(E,p) $ in $\widetilde{\mathcal{C}}$ we wish to show that $f$ indeed has a kernel. 
%		
%		Examining the below commutative diagram will help us conclude. The elements $F, g, q, h$ are defined directly as seen below. Note that the condition $fp=pf=f$ is present in the righthand square
%		
%	\[\begin{tikzcd}
%		& F \\
%		E && E & E \\
%		E && E & E \\
%		& F
%		\arrow["h"', dashed, from=1-2, to=2-1]
%		\arrow["g", from=1-2, to=2-3]
%		\arrow["q"{description}, curve={height=-12pt}, from=1-2, to=4-2]
%		\arrow["{p-f}", from=2-1, to=2-3]
%		\arrow["{(1-f)p}"', from=2-1, to=3-1]
%		\arrow["f", from=2-3, to=2-4]
%		\arrow["p"', from=2-3, to=3-3]
%		\arrow["p", from=2-4, to=3-4]
%		\arrow["{p-f}"', from=3-1, to=3-3]
%		\arrow["f"', from=3-3, to=3-4]
%		\arrow["h", dashed, from=4-2, to=3-1]
%		\arrow["g"', from=4-2, to=3-3]
%	\end{tikzcd}\]
%		Since $(1-f)p$ is itself an idempotent endomorphism on $E$ we have $(E,(1-f)p)$ is an object in $\widetilde{\mathcal{C}}$ and $p-f$ defines an arrow from this object to $(E,p)$. Since $(p-f)((1-f)p) = (p)(p-f)=p-f $ as expected.
%		
%			Now we claim that the object $ (E,(1-f)p)$ with the arrow ${p-f}$ is a kernel of $f: (E,p) \to (E,p) $. In particular it is a pullback of the below form. The diagram below drawn internally in $\widetilde{C}$ makes this image clearer.
%			\[\begin{tikzcd}
%				{(F,q)} \\
%				& {(E,(1-f)p)} && 0 \\
%				\\
%				& {(E,p)} && {(E,p)}
%				\arrow["h", dashed, from=1-1, to=2-2]
%				\arrow[curve={height=-18pt}, from=1-1, to=2-4]
%				\arrow["g"', curve={height=18pt}, from=1-1, to=4-2]
%				\arrow[from=2-2, to=2-4]
%				\arrow["{p-f}"', from=2-2, to=4-2]
%				\arrow[from=2-4, to=4-4]
%				\arrow["f", from=4-2, to=4-4]
%			\end{tikzcd}\]
%			
%			
%			Compare this to the first diagram.
%			$(F,q) \xrightarrow{g} (E,p)$ is picked such that $fg=0$. And we obtain uniqueness of $h$ is due to the fact that any such arrow $h$ must obey the expression $h=(1-f)ph=p(1-f)h=pg=g$. Conversely if $h=g$ the diagram commutes naturally.
%			
%			This shows that $\widetilde{\mathcal{C}}$ is Karoubian. Finally we construct $\varphi: \mathcal{C } \to \widetilde{\mathcal{C}}$ defined as sending $E \in \mathrm{Ob}(\mathcal{C})$ to $(E,1_E)$ and $\varphi(f) =f $. This is naturally a full faithful functor by construction.
%			
%			Also we can see that based on an analogous argument $(E,p)$ is the kernel of $1-p$ as an idempotent endomorphism over $\varphi(E)=(E,1_E)$. Meaning that $\varphi(E) \cong (E,p) \oplus (E,1-p), $ i.e. the functor is additive. 
%			
%			Finally to show that these constructions define $\psi'$.	
%			
%			If $\psi: \mathcal{C} \to \mathcal{D}$ (resp. $\psi': \widetilde{\mathcal{C}} \to \mathcal{D}$) is an additive functor from $\mathcal{C}$ (resp. $\widetilde{\mathcal{C}}$) to another Karoubian category $\mathcal{D}$, such that ${\psi'}\varphi \cong \psi$.
%			Then we have $\psi(\ker f) \cong \ker(\psi'(f))$ for every idempotent endomorphism $f$. Hence $\psi'(E, p) = \ker \psi(1-p): \psi(E) \to \psi(E)$ and $\psi'(f) = \psi(f)_{\ker \psi(1-p)}$ on the objects and morphisms respectively. Conversely, these formulas define $\psi'$ (up to isomorphism).
%	\end{proof}
%	
%	
%	Before proceeding for the last result in this section, recall the definition of equivalence of categories.
%	\begin{definition}[Equivalence of categories]
%		Two categories $\mathcal{C},\mathcal{D}$ are said to be equivalent if there exist functors $E:\mathcal{C}\rightleftarrows \mathcal{D}:F$ and a pair of natural \textit{isomorphisms} $\alpha: 1_\mathbf{C} \to F \circ E$ and $\beta: 1_\mathbf{D} \to E \circ F$. 
%		
%		This is a weaker condition than isomorphism of categories in which we have an actual equality instead of natural isomorphism.
%	\end{definition}
%	
%	A more useful form of the definition is as such, the proof may be seen in \cite{Awodey}[7.7.25]	
%	\begin{proposition}
%		A functor $F: \mathcal{C} \to \mathcal{D}$ induces an equivalence of categories iff $F$ has the following properties
%		\begin{enumerate}
%			\item $F$ is full (The map $F_{A,B}: \Hom_\mathcal{C}(A,B) \to \Hom_\mathcal{D}(FA, FB)$ defined as $f \mapsto F(f)$ is surjective for all $A,B \in \mathrm{Ob}(\mathcal{C})$).
%			\item $F$ is faithful (The map $F_{A,B} $ as defined above is injective for all pairs $A,B$).
%			\item $F$ is essentially surjective on objects (For every $D \in \mathrm{Ob}(\mathcal{D})$ there exists $C \in \mathrm{Ob}(\mathcal{C})$ such that $FC\cong D$).
%		\end{enumerate}
%	\end{proposition}
%	
%	\begin{corollary}\label{thm:equivpseudoabelian}
%		Let $\mathcal{C}$ be an additive category, $\mathcal{D}$ a Karoubian category, and $\psi: \mathcal{C} \to \mathcal{D}$ an additive functor which is fully faithful such that every object of $\mathcal{D}$ is a direct factor of an object in the image of $\psi$. Then the functor $\psi'$ as defined in Theorem \ref{thm:pseudoabelian} forms an equivalence between the categories $\mathcal{C}$ and $\mathcal{D}$.
%	\end{corollary}
%	\begin{proof}
%		We will prove that $\psi'$ is essentially surjective and fully faithful. 
%		
%		Let $G \in \mathcal{D}$. We seek $X \in \widetilde{\mathcal{C}}$ such that $\psi'(X) \cong G$.
%		
%		By the hypothesis we have that for $G \in \mathcal{D}$, there exists $E \in \mathcal{C}$ and $G' \in \mathcal{D}$ with $\psi(E) \cong G \oplus G'$.
%		Due to this we can choose an idempotent endomorphism $q: \psi(E) \to \psi(E)$ such that $\text{Ker}(q) \cong G$ we are in a pseudo-abelian category.
%		
%		Now as $\psi$ is fully faithful, there's a idempotent $p: E \to E$ in $\mathcal{C}$ with $\psi(p) = q$. Then by the formulas in the end of Theorem \ref{thm:pseudoabelian} we have $G \cong \varphi' (E,1-p).$ This proves essential surjectivity.
%		
%		Lastly to prove $\varphi'$ is fully faithful consider two objects $H, H' \in \widetilde{\mathcal{C}}$ direct factors of $\varphi(E), \varphi(E')$. Then the following diagram shows that $\psi'_{H,H'} $ is an isomorphic function,
%		\[\begin{tikzcd}
%			{\Hom_{\widetilde{\mathcal{C}}}( \varphi(E), \varphi(E'))} & {\Hom_{\mathcal{C} }(E,E')} & {\Hom_{\widetilde{\mathcal{C}}}(H,H')} \\
%			\\
%			& {\Hom_\mathcal{D} (\psi(E), \psi(E'))} & {\Hom_\mathcal{D}(\psi'(H), \psi'(H'))}
%			\arrow["{\cong }", from=1-1, to=1-2]
%			\arrow["{\psi'_{\varphi(E), \varphi(E')}}"', from=1-1, to=3-2]
%			\arrow[shift left=2, from=1-2, to=1-3]
%			\arrow["{\psi_{E,E'}}", from=1-2, to=3-2]
%			\arrow[shift left=2, from=1-3, to=1-2]
%			\arrow["{\psi'_{H,H'}}", from=1-3, to=3-3]
%			\arrow[shift right=2, from=3-2, to=3-3]
%			\arrow[shift right=2, from=3-3, to=3-2]
%		\end{tikzcd}\]
%		where the horizontal arrows are induced by the decompositions $\varphi(E)=H \oplus H_1$ and $\varphi(E')=H' \oplus H_1'$, since $\psi_{E,E'} $ is an isomorphism by hypothesis.
%	\end{proof}
%	
%	
%
%	\section{Swan's theorem}
%	
%	We can now prove the celebrated Swan's theorem with the results we've built up so far.
%	\begin{theorem}[Swan's theorem]\label{thm:serreswan}
%		Let $X$ be a compact Hausdorff space, and let $A = C(X)$. Then the section functor $\Gamma$ induces an equivalence of categories $\mathrm{VB}(X) \simeq \mathrm{Proj}(C(X))$.
%	\end{theorem}
%	
%	\begin{proof}
%		Since we assume that $X$ is compact the section map $\Gamma$ as seen in Proposition \ref{sectionfunctor} is indeed a functor $\Gamma: \mathrm{VB}(X) \to \mathrm{Proj}(C(X))$ due to Theorem \ref{stablytrivialcompact}. Furthermore it induces a functor $\Gamma_T: \mathrm{VB}_{T}(X) \to \mathrm{Free}(C(X))$.
%		
%		Where $\mathrm{VB}_T(X)$ refers to the full subcategory of $\mathrm{VB}(X)$ consisting of the trivial bundles over $X$, and $\mathrm{Free}(C(X))$ refers to finitely generated free modules over $C(X)$.
%		
%		Since $C(X)^n \cong \Gamma_T(E)$ for $E=X\times k^n$, we have $\Gamma_T$ is essentially surjective.
%		
%		If $F:X \times k^p$ is some other trivial vector bundle and $f:E \to F$ is a morphism of vector bundles then as seen in Theorem \ref{thtrivialbundlemorphisms} we have full faithfullness of the functor $\Gamma_T$. Which shows that $\Gamma_T$ induces a equivalence of categories between $\mathrm{VB}_T(X) $ and $\mathrm{Free}(C(X))$.
%		
%		To extend this to our required case we make use of Theorem \ref{thm:pseudoabelian} and Theorem \ref{thm:equivpseudoabelian}.
%		
%		Comparing with Theorem \ref{thm:pseudoabelian} since $\mathrm{VB}(X)$ being Karoubian itself is naturally the Karoubian envelope of its subcategory $\mathrm{VB}_T(X)$ and with the functor $\Gamma$ realized as $\psi'$ we see the below diagram commutes.
%		\[\begin{tikzcd}
%			{VB(X)} \\
%			\\
%			{\mathrm{VB}_T(X)} && {\mathrm{Proj}(C(X))}
%			\arrow["{\Gamma =\psi'}", from=1-1, to=3-3]
%			\arrow["i", from=3-1, to=1-1]
%			\arrow["\psi"', from=3-1, to=3-3]
%		\end{tikzcd}\]
%		Finally due to Theorem \ref{thm:equivpseudoabelian} we are done.
%		
%%		using Theorem \ref{thm:equivtrivbundles} which ensures that the trivial bundles suffice in building up to the construction.  Theorems \ref{thm:pseudoabelian} and \ref{thm:equivpseudoabelian} combined guarantee that if a functor is fully faithful and satisfies the direct-factor property, then itâ€™s an equivalence.  Since Theorem [reference needed for fully faithful proof] demonstrates that $\Gamma$ is fully faithful, $\Gamma$ is an equivalence of categories.  Therefore,  $\mathrm{VB}(X) \simeq \mathrm{Proj}(C(X))$.
%	\end{proof}

	
	\chapter{Grothendieck group $K_0$}
	The Grothendieck group $K_0$ arises from the natural idea of wanting to extending a commutative monoid to a group in a universal manner. This concept finds its roots in many naturally occurring mathematical structures, such as finitely generated projective modules or vector bundles. 
	
	Recall a monoid is an algebraic object consisting of a set of symbols $A$ with a associative binary operation $+$ and an identity element $e$ (where $a+e=e+a=a$ for all $a \in A$).
	
%	This is a fairly natural approach which results in a Free-Forgetful adjoint pair between $\mathrm{CMon}$ and $\mathrm{Ab}$. 
	
	\section{Definitions and basic results}
	The group completion of a monoid proceeds as such. We begin with a commutative monoid $A$ to complete it into a group we formally add inverses for each symbol $[a]\in A$. Consider the free group on the set of symbols in the monoid labelled as $F(A)$. Now quotient away all the nontrivial monoidal relations $F(A)/\sim $ where $[a+b]\sim [a]+[b] \sim [b]+[a] \sim [b+a]$. 
	
	This gives us the group completion of a monoid, i.e. the smallest group which has $A$ as a submonoid.
	
	\begin{proposition}\label{propk0nz}
		The group completion of the natural numbers $\N$ is $\Z$. Following the group completion procedure as described above we obtain a formal inverse symbol $[b]$ for each symbol $[a] \in \N $, i.e. a symbol $[b]$ such that $[b]+[a]=[a]+[b]=[0]$ for all $[a] \in \N$, but note that this is naturally isomorphic to $\Z $ as $[b] \mapsto [-a]$.
	\end{proposition}
		
	\begin{definition}[$K_0$ of a monoid (Group completion functor)]
	For a commutative monoid $A$, the group completion of $A$ is denoted as $K_0(A).$
	\end{definition}
	
%	The mapping is an injection iff the monoid is cancellative, i.e. ($a+b=a+c \implies b=c$) for all $a,b,c$ in the monoid.
	\begin{definition}[Reduced $K_0$ group of a commutative monoid $A$]
	There is a canonical homomorphism $i: \Z \to K_0(A)$ given by $z \mapsto z[m]=\underbrace{[m]+\cdots + [m]}_{z \text{ times}$ the reduced $K$ group is defined as $\tilde{K}_0(A):=K_0(A)/\image \ i. $
	\end{definition}
	
%	\begin{proposition}[Mayer-Vietoris for group completions]
%		content...
%	\end{proposition}
	We return now to the case of modules over a commutative ring $A$. 
	
	Recall the notion of stable isomorphisms and stably free modules Definitions \ref{stabiso} and \ref{stabfree}.
	
	\begin{definition}[$K_0$ for a ring $A$]
		Consider the stable isomorphism classes of finitely generated projective modules over $A$ denoted as $\mathrm{Proj}(A)$. This forms a commutative monoid so $K_0(A)$ is defined as $K_0(\mathrm{Proj}(A))$.
	\end{definition}
	\begin{definition}[$G_0$ for a ring $A$]
	The group completion of $M(A) $ the monoid of all finitely generated modules over $A$ is denoted as $G_0(A) $. 	There is a canonical inclusion map $K_0(A) \to G_0(A)$.
	\end{definition}


The reason we require the caveat of finitely generated projective modules instead of simply considering the class of all projective modules is because for the non finitely generated case $K_0(A)$ becomes trivial as we see below.
	\begin{proposition}[Eilenberg Swindle] If we consider $R^\infty$ as a non finitely generated free module over a ring $R$ if $P \oplus Q \equiv R^n$ then \[ P \oplus R^\infty \cong P \oplus (Q \oplus P) \oplus (Q \oplus P) \oplus \dots \equiv (P \oplus Q) \oplus (P \oplus Q) \oplus \dots \equiv R^\infty \] but this relation would imply $[P]=0 $ for all projectives. 
	\end{proposition}
%	
%	This extends to higher K groups with an analogue that demonstrates the Quillen K space contracts, see V.1.9 in \cite{weibel2013k}.
%	
%	\begin{definition}[Morita equivalence for rings and ]
%		content...
%	\end{definition}
%	`

	\section{Computing $K_0$ groups with idempotent matrices and Morita invariance}\label{k0withidempotent}
	We now see a few examples of computations of $K_0$. We must first prove a result about the invariant basis property. Recall that a ring $A$ has the invariant basis property if $A^n \cong A^m $ implies $n = m$. 
	
	A division ring (also called a skew field) is any nontrivial ring in which every non-zero element has a multiplicative inverse. Division rings need not be commutative, in fact commutative division ring is simply a field.
	\begin{example}[Non-commutative division ring]
		The set of quaternions $\mathbb{H}$ forms a non-commutative division ring.
	\end{example}
	
	\begin{proposition}\label{skewfieldsibp}
		Any division ring $A$ has the invariant basis property.
	\end{proposition}
	\begin{proof}
		Consider a free $A$-module $M$ with two finite bases $B = \{b_1, \dots, b_n\}$ and $C = \{c_1, \dots, c_m\}$, then if we prove $n=m$ we are done. We prove with induction on $n$.
		
		If $n=1$, then $B = \{b_1\}$. If $C = \{c_1, \dots, c_m\}$ for some $m>1$, we can express the $c_i$ in terms of $b_1$ as, $c_1 = a_1 b_1$ and $c_2 = a_2 b_1$ where $a_1, a_2 \in A$ and $a_1, a_2 \neq 0$. Then $a_1^{-1}c_1 - a_2^{-1}c_2 = 0$, contradicting the linear independence of $C$. Therefore $m=1=n$.
		
		Proceeding inductively assume the statement holds for $n=k$. 
		Let $M$ be a free $A$-module with a basis $B = \{b_1, \dots, b_{k+1}\}$ and let $C = \{c_1, \dots, c_m\}$ be another basis. 
		
		Since $B$ spans $M$, we can write $b_{k+1}$ as a linear combination of the $c_i$: $b_{k+1} = a_1 c_1 + \dots + a_m c_m$ for some $a_i \in A$. Since $b_{k+1} \neq 0$, at least one $a_i \neq 0$. Without loss of generality, assume $a_m \neq 0$.
		
		Consider the quotient module $M/(b_{k+1})$. The set $\{b_1, \dots, b_k\}$ forms a basis for $M/(b_{k+1})$. Similarly, $\{c_1, \dots, c_{m-1}\}$ is a basis for $M/(b_{k+1})$.  Applying the inductive hypothesis to $M/(b_{k+1})$, we have $k = m-1$.  Therefore $k+1 = m$.
	\end{proof}
	
	\begin{corollary}\label{comringibp}
		Nonzero commutative rings $A$ have invariant basis property.
	\end{corollary}
	\begin{proof}
		For a free $A-$module $M $ with basis $B=\{b_1, \ldots, b_n\}$, under the canonical surjection $A \to A/\mathfrak{m}$, $M/\mathfrak{m}M$ is also a free module over $A/\mathfrak{m}$ with basis $\{b_1+\mathfrak{m} M, \ldots, b_n + \mathfrak{m}M\}$. Since every basis for $M/\mathfrak{m}M$ has $n$ elements due to the fact that $A/\mathfrak{m}$ is a field, Proposition \ref{skewfieldsibp} shows it has invariant basis property. This implies any basis of $M$ also has only $n$ elements, i.e. $A$ itself has the invariant basis property.
	\end{proof}
	\begin{proposition}\label{k0pidisZ}
	If $A$ is a field/division ring/local ring/principal ideal domain then $K_0(A)\cong\Z$.
	\end{proposition}
	\begin{proof}
		For fields and division rings this is true due to all finitely generated modules being free, i.e. having a basis. We prove this directly for division rings for simplicity.
		
		The similar linear algebraic proof extends to division rings for $M$ a module over division ring $A$. Pick a maximally linearly independent subset $B$ by Zorn's lemma. To show \( B \) is a generating set, the argument uses \( B \)'s maximality. If \( m \in M \) then, if $m \in B$ we are done. If $m \not \in B$ then $B \cup \{m\}$ is linearly dependent by maximality of $B$ therefore there exists $a\in A$ such that $am \in \mathrm{span}(B)$ for some $a \neq 0$ and since $a $ is invertible due to $F$ being a division ring we have $m \in \mathrm{span}(B)$.
		Therefore, \( B \) must span \( M \), making it a basis and so $ M \cong A^n$.
		
		Similarly as seen in Theorem \ref{a2} and  Proposition \ref{projfgpidfree} finitely generated projective modules in a local ring/principal ideal domain are free.
		
		So in each case $\mathrm{Proj}(A) \cong \N$ so its group completion is $\Z.$ 
		
		Throughout the proof we have implicitly assumed $A$ has the invariant basis property which was proved above in Proposition \ref{skewfieldsibp} and Corollary \ref{comringibp}
		\end{proof}
		
	\begin{lemma} For commutative ring $A$, 
		$K_0(A) \cong \Z $ implies projective modules over $A$ are stably free.
	\end{lemma}
	\begin{proof}
		For a commutative ring $A$, $K_0(A) \cong \Z $ implies $ \mathrm{Spec}(A)$ is connected. For if not then there exists a non trivial idempotent in $A$ which results in a splitting of $A$ as a product which would contradict $\mathrm{Spec}(A)$ being connected.
		
		In light of Definition \ref{def:rankproj} we know that the rank of the projective modules must be constant due to the connectedness of $\mathrm{Spec}(A)$ and the fact that the only connected components in $\Z $ are singletons. 
		
		So the rank map $\phi:K_0(A) \to \Z $ defined as $P \mapsto \mathrm{Rank}(P)$ is well defined and surjective. $A$ with rank $1$ maps to $1$, i.e. the generator of $\Z$. By our assumption, this is an isomorphism.				
		
		So any $[P]=n=[A]^n=[A^n]$ i.e. there exists $Q$ projective such that $Q\oplus P \cong Q \oplus A^n$, i.e. $P$ is stably free.
	\end{proof}
	
	We end this section with computing $K_0$ for semisimple rings. We first define what is means for a ring to be simple.
	
	\begin{definition}[Simple ring]
		A simple ring is a non-zero ring which have no non-trivial two-sided ideals.
	\end{definition}
	\begin{example}
		A commutative ring is simple iff it is a field.
	\end{example}
	\begin{example}
		All division rings are simple rings.
	\end{example}
	\begin{example}
		Not all division rings are simple consider $M_n(F)$ for some field $F$ not all elements need be invertible.
	\end{example}
	
	A simple module is naturally now any module which is non-zero and has no non-trivial submodules.
	
	\begin{lemma}[Schur's lemma]\label{schurs}
		If $A$ is any ring and $M$ is a simple $R-$module then $\mathrm{End}_A(M)$ is a division ring.
	\end{lemma}
	\begin{proof}
		Let $f \in \mathrm{End}_A(M)$ be non-zero. Then $\image (f) \neq 0, \ker (f) \neq M$, but since they are both submodules of $M$ it follows due to simplicity that $\image (f)=M, \ker (f)=0$. That is to say all non-zero endomorphisms are invertible, i.e. it is a division ring.
	\end{proof}
	
	
	Now we move onto semisimple rings. There are various equivalent definitions of a semisimple ring.
	\begin{definition}[Semisimple ring]
		A ring $A$ is called semisimple if
		\begin{itemize}
			\item $A$ is Artinian with trivial Jacobson ideal.
			\item $A$ is a finite product of simple Artinian rings.
			\item Every left/right $A-$module is projective.
		\end{itemize}
	\end{definition}
	
	A useful characteristic of semisimple rings is the Wedderburn-Artin theorem (see \cite{lam2001first}[3.5] for a proof).

	\begin{theorem}[Wedderburn-Artin]\label{wedart}
		A ring $A$ is semisimple iff it is isomorphic to a direct product of $n_i \times n_i$ matrix rings over division rings $D_i$, i.e. $A \cong \prod_{i=1}^r M_{n_i}(D_i)$ where $D_i =\Hom_A(V_i,V_i), \dim_{D_i}(V_i)=n_i$ for $V_i$ the simple $A$-modules components of $A$.
	\end{theorem}
	
	
	We now discuss the role of idempotent matrices in computing $K_0$ following \cite{weibel2013k} this is presented in detail in \cite{rosenberg1995algebraic}.
	We claim that idempotent matrices over $A$ are in a one to one correspondence to finitely generated projective modules. 
		
	For a finitely generated projective module $P$ over $A$, such that $P \oplus Q \cong A^n$ we can define a $R-$module homomorphism which is identity restricted to $P$ and zero else. This is clearly an idempotent element in $M_n(A)$, i.e. $P$ is represented by a $n\times n $ matrix over $A$.
	
	Conversely any idempotent matrix $e \in M_n(A)$ determines a projective. Simply consider the associated module morphism induced by the matrix $e$ and then the image under $e$ is projective, i.e. $eA^n$. This is true because $A \cong eA^n \oplus (1-e)A^n$ \footnote{Idempotent property is used to show $eA^n \cap (1-e)A^n = 0$ since $e^2=e\implies e(1)$}.
	
	We must make a note of the fact that different idempotent matrices may induce projective modules in the same isomorphism class. This is made precise in the following result.
	
	\begin{proposition}
		If $e, f $ are idempotent matrices over $A$ of possibly different sizes then the associated finitely generated projective modules are isomorphic iff $e,f $ are conjugate over a larger common matrix group of order $r$ (obtained by placing the matrices in the top left corner of a larger 0 matrix).
	\end{proposition}
	\begin{proof}
		Suppose we have two conjugate idempotent matrices $e,f \in M_n(A)$, i.e. there exists $u \in GL_n(A)$ such that $ueu^{-1}=f$ or $ue=fu.$ If $x $ lies in the image of $e$ say $x=ey$ then $ux$ lies in the image of $f $ since $ux=uey=fuy=f(uy)	$. By symmetry using $u^{-1}$ we see also that, elements from $fA^n$ belong to $eA^n$.
		
		Now conversely, assume the projective modules corresponding to idempotent matrices $e$ and $f$ are isomorphic.  Let $e \in M_n(A)$ and $f \in M_m(A)$.  This isomorphism $\image e \cong \image f$, i.e. $e A^n \cong  fA^m$, extends to an $A$-module homomorphism $\tilde{f} \colon A^n \to A^m$, similarly $\tilde{f}^{-1} = \tilde{g} \colon A^m \to A^n$. 
		
		We can represent $\tilde{f}$ and $\tilde{g}$ by right multiplication with matrices $\alpha \in M_{m,n}(A)$ and $\beta \in M_{n,m}(A)$ respectively. These obey the following relations $\alpha \beta = f, \beta \alpha=e, \alpha=\alpha e=f \alpha, \beta= \beta f= e \beta  $.
		
		Choose $r = n + m$, claim that the following block matrix is invertible 
		\[
		\varphi = \begin{bmatrix}
			1-e & \beta   \\
			\alpha & 1-f
		\end{bmatrix}
		\]
		and is conjugate to $\begin{bmatrix} e & 0 \\ 0 & 0 \end{bmatrix}$ and $\begin{bmatrix} 0 & 0 \\ 0 & f \end{bmatrix}$.  
		This is true since $\varphi^2=I_{r}$. A computation then shows that \[ \varphi \begin{bmatrix}
			e & 0 \\
			0 & 0
		\end{bmatrix} \varphi= \varphi  \begin{bmatrix}
		0 & \beta \\
		0& 0
		\end{bmatrix} = \begin{bmatrix}
		0 & 0\\
		0& f
		\end{bmatrix}\]
		
		A permutation matrix then conjugates $\begin{bmatrix} 0 & 0 \\ 0 & f \end{bmatrix}$ to $\begin{bmatrix} f & 0 \\ 0 & 0 \end{bmatrix}$. Thus $e$ and $f$ are conjugate after appropriate embedding into $GL_r(A)$ and therefore represent isomorphic modules.
	\end{proof}
	
	Consider $GL_n(A) \subset GL_{n+1}(A)$ by placing the $n\times n $ matrix in the top right. In this manner we have a filtered system and we can define $GL(A)= \lim_{\to} GL_i(A)$ as the colimit. Similarly define $M(A)$. Denote the set of idempotent matrices in $M(A)$ as $\mathrm{Idem}(A)$ so we have that the group $GL(A)$ acts on the set $\mathrm{Idem}(A)$ by conjugation.
	
	With the above discussion in mind we now have a alternate description for the monoid $\mathrm{Proj}(A)$ in terms of idempotent matrices. In particular $\mathrm{Proj}(A)$ corresponds to the conjugacy classes of the action of $GL(A)$ on $\mathrm{Idem}(A)$. The monoid operation $e +f$ is the block matrix $\begin{bmatrix}
		e & 0 \\ 0 & f
	\end{bmatrix}. $
	
	\begin{corollary}[Morita invariance of $K_0$]\label{morita}
		Let $A$ be a ring and $n \in \N $ arbitrary. Then $K_0(A) \cong K_0(M_n(A))$.
	\end{corollary}
	\begin{proof}
		Note that the infinite general linear matrices over $M_n(A) $ and $A$ are canonically equivalent, i.e. $GL(M_n(A)) = GL(A)$ in particular their infinite idempotent matrices are also equivalent $\mathrm{Idem}(M_n(A)) = \mathrm{Idem}(A)$. Consequently by the correspondence between idempotent matrices and projective modules their monoid of finitely generated protectives are the same meaning their group completions are isomorphic.
	\end{proof}
	
	\begin{corollary}\label{propdirectproductofk0}
		For commutative ring $A$ if $A \cong A_1 \times A_2$ for rings. Then	$K_0(A) \cong K_0(A_1) \times K_0(A_2)$.
	\end{corollary}
	\begin{proof}
	Notice that $GL(A) \cong GL(A_1 \times A_2) \cong GL(A_1) \times GL(A_2)$ and $\mathrm{Idem}(A) \cong \mathrm{Idem}(A_1 \times A_2) \cong \mathrm{Idem}(A_1) \times \mathrm{Idem}(A_2)$.
	\end{proof}
	\begin{corollary}\label{directsystem}
		If $A$ is the direct limit of rings, i.e. $A\cong \lim_{\to i \in I} A_i $ then $K_0(A) \cong \lim_{\to i \in I} K_0(A_i)$.
	\end{corollary}
	
	The below result is a generalization of Proposition \ref{k0pidisZ} (since every division ring is a simple ring)
	\begin{lemma}
		Let $A$ be a simple ring then $K_0(A) \cong \Z $.
	\end{lemma}
	\begin{proof}
		By Morita invariance \ref{morita} we know that $K_0(A) \cong K_0(M_n(A)) \cong K_0(\mathrm{End}(A)) \cong K_0(D)$ for some division ring $D$. The last isomorphism is due to Schur's lemma \ref{schurs}. Now applying Proposition \ref{k0pidisZ} we are done.
	\end{proof}
	\begin{theorem}
		If $A$ is a semisimple ring then $K_0(A)\cong \Z^r$.
	\end{theorem}
	\begin{proof}
		Due to Wedderburn-Artin \ref{wedart}, we know $A \cong \prod_{i=1}^r M_{n_i} (D_i)$ now applying Morita invariance \ref{morita}, Corollary \ref{propdirectproductofk0} (the result for $n$ direct sums is obtained via induction).
		 $$K_0(A) \cong K_0\left(\prod_{i=1}^r M_{n_i} D_i\right) \cong \prod_{i=1}^r K_0\left( M_{n_i}D_i\right) \cong \prod_{i=1}^r K_0(D_i) \cong \Z^r.$$
	\end{proof}
	
%
%\section{$K_0$ for exact and abelian categories}
%	$K_0$ being the prototypical K group is easier to generalize. We will refer to Weibel for most of the definitions of $K_0$ \cite{weibel2013k}. The benefit of this approach will mainly be for building up an understanding for Higher K theory. Also this machinery allows for easier computations. In particular this will allow for a proof of Hilbert-Serre as a simple observation which we will use in the proof of Quillen-Suslin.
%	
%	We begin with the definition of an exact category and then define $K_0$ for an exact category. This will subsume the definition of $K_0$ for an abelian category. Since every abelian category is exact over itself.
%	
%	\begin{definition}[Exact category]
%		An exact category (sometimes referred to as a Quillen exact category) is a pair $\mathcal{(E},E)$ for $\mathcal{E}$ an additive category which is a full subcategory of some abelian category $\mathcal{A}$. Along with a family of sequences $E$ of the form \[ 0 \to A \to B \to C \to 0 \] which are short exact sequences in $\mathcal{A}$ and if in a sequence of the above form $A, C \in \mathcal{E}$ then $B $ is isomorphic to some element which is in $\mathrm{Ob}(C)$
%	\end{definition}
%	\begin{example}
%		Every abelian category is trivially exact over itself.
%	\end{example}
%	\begin{example}Torsion free abelian groups over the category of abelian groups is exact but not abelian. (Non abelian-ness was shown in Example \ref{expreabnotab}.2).
%	\end{example}
%%	\begin{example}
%%		The vector bundles on a scheme $X$ form a exact category.
%%	\end{example}
%	
%	\begin{definition}[$K_0$ for an exact category $\mathcal{E}$]
%		$K(\mathcal E)$ is generated by $[B]$ for each $B \in \mathrm{Ob}(\mathcal{E})$ and a relation of $[B]=[A]+[C]$ for all short exact sequences \[ 0 \to A \to B \to C \to 0 \]
%		Naturally since every abelian category is exact this applies for abelian categories in particular.
%	\end{definition}
%	
%	\section{Fundamental theorems for $K_0,G_0$}
%	In this section we present here for reference the important 'fundamental' theorem for $K_0$ and $G_0$ of abelian categories. The proofs will be provided in the subsequent project. 
%	
%	The proofs are omitted here due to the need for a more in-depth discussion of concepts such as the localization of categories and multiplicative systems. Furthermore, the proofs for the $K_0$ case are readily extended to the higher $K$ groups, especially in the context of Quillen-Q constructions, which are based on the calculus of fractions of categories. As such, it is more fitting to address these in detail in the next project, which will build on the work presented here.
%	
%%	\section{Devissage}
%	\begin{theorem}[Devissage for $K_0$ in abelian categories]\label{devissagek0}
%		Let $\mathcal B \subset \mathcal A$ be abelian categories which are small (i.e. proper set of objects) then $K_0(\mathcal A) \cong K_0(\mathcal B)$ and the inclusion functor $i:\mathcal{B} \to \mathcal{A}$ is exact if the following conditions are met
%		\begin{enumerate}
%			\item $\mathcal B$ is a abelian exact subcategory of $B$ closed under subobjects and quotients from $\mathcal{A}$.
%			\item Objects in $\mathcal{A}$ have finite filtrations \[ A_n=0 \subset A_{n-1} \subset \cdots \subset A_0 =A \] with each of the quotients $A_i/A_{i+1} \in \mathcal{B}$
%		\end{enumerate}
%	\end{theorem}
%%	\begin{proof}
%		Since $i:\mathcal{B} \subseteq \mathcal{A} $ we denote by $ \tilde{i} : K_0(\mathcal{B}) \to K_0(\mathcal{A})$ the natural induced homomorphism. This is naturally injective so we need to prove surjectivity and additivity.
%		
%		Based on the hypothesis we can always find a finite filtration on $A \in \mathcal{A}$ of the form $\{A_i\}_{i=0}^n$ with the quotients in $\mathcal{B}$. We can then represent its consequent preimage in $K_0(\mathcal{B})$ as $[A] = \sum_i [A_i / A_{i+1}]$ in $ K_0(\mathcal{A} )$, i.e. $\phi^{-1}([A])=\sum_i A_i/A_{i+1}$.
%			
%		Note that such a preimage is also independent of the filtration due to the Schrier-Refinement theorem for abelian categories which states that we can always find a common refinement of filtrations. The proof is identical to the standard group theoretic proof.
%			
%		To verify this claim look at a single refinement, say changing $A_i \supset A_{i+1}$ to $A_i \supset A' \supset A_{i+1}$. 
%		\[
%		0 \to A' / A_{i+1} \to A_i / A_{i+1} \to A_i / A' \to 0,
%		\]
%		
%		we see that $[A_i / A_{i+1}] = [A_i / A'] + [A' / A_{i+1}]$ in $K_0(\mathcal{B})$, as claimed. This is essentially 
%		
%		For additivity and exactness, note that given a short exact sequence $0 \to A \to B \to C \to 0$, we can construct a filtration $\{B_i\}$ for $B$ by combining the filtration for $A$ along with pullback of a filtration of $C$ in $B$. For this filtration we have $\sum [A_i / A_{i+1}] = f(A') + f(A'')$. Therefore $f$ is an additive function and defines a map $K_0(\mathcal{A}) \to K_0(\mathcal{B})$. By inspection, $f$ is the inverse of the canonical map $i_*$.
%	\end{proof}
%	\begin{corollary}
%		For a nilpotent ideal $N$ in a noetherian ring $A$ we have $G_0(A/N) \cong G_0(A	)$
%	\end{corollary}
%	\begin{proof}
%		Every finitely generated module has a natural filtration which goes to zero found by by multiplying a module with copies of $N$.
%	\end{proof}	
%	Nil ideals (ideals consisting of all nilpotent elements) are in general not nilpotent ideal. However, due to a theorem by Levitzky (see \cite[Theorem 10.30]{lam2001first}) which states that nil ideals of right noetherian rings are indeed nilpotent we can say that this holds for nil ideals as well.



%	\section{Localization of categories, Serre quotient}
%		We take a short detour to define clearly the concepts used for localizing a category. Mainly for the purpose of defining a Serre quotient. 
%		
%		This is a very fundamental idea that we require to be well established. As it is also relevant in the definition of the Quillen Q construction of higher K theory. The primary reference for this section is the book due to Gabriel-Zisman \cite{gabriel1967calculus}. To avoid set theoretic complications wherever convenient we consider the categories involved to be locally small/skeletally small/small.
%		
%		The basic definition of a category $\mathcal{C}$ localized at any arbitrary subcollection $S$ of morphisms in $\mathcal{C}$ is just defined universally as a category $S^{-1}\mathcal{C}$ being the initial category such that the functor $L: \mathcal{C} \to S^{-1}\mathcal{C}$ takes every $s \in S$ to an isomorphism. But such a construction is not the most useful in a vacuum. The construction of $S^{-1}\mathcal{C}$ in the special case of $\mathcal{C}$ being abelian is relevant to the Localization theorem of $K_0$. So we shall only focus on that case.
%		
%		Motivated by commutative algebra it is useful to restrict the choice of $S$ to be of the following form.
%		
%		\begin{definition}[Left multiplicative system]
%			A collection of morphisms $S$ in a category $\mathcal{C}$ is said to be a left multiplicative system if,
%			\begin{itemize}
%				\item $S$ contains all identity maps of objects from $\mathcal{C}$.
%				\item $S$ is closed under compositions.
%				\item For $f: A \to B $ in $S$ and $g: A \to C$ arbitrary there exists an object $D$ and $i$ in $S$ and $h$ arbitrary as below making the diagram commute.
%				\[\begin{tikzcd}
%					& D \\
%					B & A & C
%					\arrow["h", dashed, from=2-1, to=1-2]
%					\arrow["f", from=2-2, to=2-1]
%					\arrow["g"', from=2-2, to=2-3]
%					\arrow["i"', dashed, from=2-3, to=1-2]
%				\end{tikzcd}\]
%				\item (Left cancelibility) Given $f,g: A\to B $ and $h: B \to C$ in $S$ such that $hf=hg$ there exist $i:X \to A$ in $S$ such that $fi=gi$
%				\[\begin{tikzcd}
%					X & A & B & C
%					\arrow["i", from=1-1, to=1-2]
%					\arrow["g"', shift right=2, from=1-2, to=1-3]
%					\arrow["f", shift left=2, from=1-2, to=1-3]
%					\arrow["h", from=1-3, to=1-4]
%				\end{tikzcd}\]
%			\end{itemize}
%		\end{definition}
%		A multiplicative system with both right and left cancelibility is called a multiplicative system.
%		\begin{example}
%			The collection of all isomorphism from $\mathcal{C}$ forms a left multiplicative system.
%		\end{example}
%		\begin{example}\label{ex-derived}
%			Collection of all quasi-isomorphisms in $ \mathcal{K}(\mathcal{A})$ the homotopy category of chain complexes over an abelian category $\mathcal{A}$ forms a multiplicative system. 
%		\end{example}
%		
%		The notion of adding a formal inverse in $S^{-1}\mathcal{C}$ is made precise by the notion of roofs.
%		\begin{definition}[Roofs]
%			A roof from an object $A$ to $B$ in a category $\mathcal{C}$ is a diagram of the form.
%			\[\begin{tikzcd}
%				& \bullet \\
%				A && B
%				\arrow[from=2-1, to=1-2]
%				\arrow[from=2-3, to=1-2]
%			\end{tikzcd}\]
%		\end{definition}
%		Two roofs are said to be equivalent if there is a larger common roof 
%		\[\begin{tikzcd}
%			&& \bullet \\
%			& \bullet && \bullet \\
%			A &&&& \bullet
%			\arrow[dashed, from=2-2, to=1-3]
%			\arrow[dashed, from=2-4, to=1-3]
%			\arrow[from=3-1, to=2-2]
%			\arrow[from=3-1, to=2-4]
%			\arrow[from=3-5, to=2-2]
%			\arrow[from=3-5, to=2-4]
%		\end{tikzcd}\]
%		such that the outer sides consist of a morphism of two arrows the composition of which belongs to $S$.
%		
%		\begin{definition}[Localization over a left multiplicative system in an abelian category]
%			We define $S^{-1} \mathcal{A}$ as such,
%			\begin{itemize}
%				\item The objects is $S^{-1} \mathcal{A}$ are the same as $\mathcal{A}$.
%				\item The morphisms in $S^{-1} \mathcal{A}$ are the roofs over $A, B$ whose left arrow is in $S$.
%			\end{itemize}
%			
%		\end{definition}
%		
%		\begin{example}
%			Localizing the quasi-isomorphisms in $\mathcal{K}(A)$ (Example \ref{ex-derived})gives us the derived category of $\mathcal{A}$.
%		\end{example}
%		For an abelian category $\mathcal{A}$ a Serre subcategory of $\mathcal{A}$ is a specific kind of subcateogry which allows us to create a `quotient' which we call a Serre quotient. In reality this is more akin to a localization than a quotient proper. 
%	
%	\begin{definition}[Serre subcategory]
%		Let $\mathcal{A}$ be an abelian category, a full subcategory $\mathcal{B} \subset \mathcal{A}$ is called a Serre subcategory of $\mathcal{A}$ if \begin{itemize}
%			\item For exact sequence $0 \to A \to B \to C $ in $\mathcal{A}$, $B \in \mathcal{B} \iff A,C \in \mathcal{B}$
%			\item Equivalently this means that $\mathcal{B}$ is closed under quotients, subobjects and extensions.
%		\end{itemize}
%	\end{definition}
%	
%	\begin{definition}[Serre quotient]
%		Given $\mathcal{B} \subset \mathcal{A}$ a locally small Serre subcategory of an abelian category we can define its Serre question $\mathcal{A}/\mathcal{B}$ with the following construction. \begin{itemize}
%			\item $\mathrm{Ob}(\mathcal{A}/\mathcal{B})$ consists of objects from $\mathcal{A}$
%			\item Morphisms between $A\to B$ as $\Hom_{\mathcal{A}/\mathcal{B}} (A,B) =  \lim_\to \Hom_\mathcal{A} (\tilde A, Y/\tilde Y)$ where $\tilde A \leq A, \tilde Y \leq Y$ are subobjects.
%		\end{itemize}
%	\end{definition}
%	When $\mathcal{A}$ is small we can treat morphisms $A \to B $ as equivalence classes of diagrams of the form \[ A \xleftarrow{f} \bullet \xrightarrow{g} B \]
%	Where $\ker, \mathrm{coker}$ of $f$ are in $\mathcal{B}$. Equivalence with another diagram $A \leftarrow \circ \rightarrow B$ is defined with the existence of the below commuting diagram
%	\[\begin{tikzcd}
%		& \bullet \\
%		A & X & B \\
%		& \bullet
%		\arrow[from=1-2, to=2-1]
%		\arrow[from=1-2, to=2-3]
%		\arrow[from=2-2, to=1-2]
%		\arrow[from=2-2, to=2-1]
%		\arrow[from=2-2, to=2-3]
%		\arrow[from=2-2, to=3-2]
%		\arrow[from=3-2, to=2-1]
%		\arrow[from=3-2, to=2-3]
%	\end{tikzcd}\]
%	Where for $\bullet \leftarrow X \rightarrow \circ $ we have $\ker,\mathrm{coker}$ of both the arrows in $\mathcal{B}$, making the below diagram commute.
%	
%	
%	
%	\begin{theorem}
%		$\mathcal{A/B}$ is abelian and the inclusion functor $L:\mathcal{A} \to \mathcal{A/B}$ is exact
%	\end{theorem}
%	\begin{proposition}
%		The Serre quotient $\mathcal{A/B}$ universal in the following sense. Any exact functor $U: \mathcal{A} \to \mathcal{C}$ such that $U(B)\cong 0$ for $B \in \mathcal{B}$ will factor through $L$. i.e. the below diagram commutes	
%		\[\begin{tikzcd}
%			&& {\mathcal{A/B}} \\
%			\\
%			{\mathcal{A}} && {\mathcal{C}}
%			\arrow[dashed, from=1-3, to=3-3]
%			\arrow["L", from=3-1, to=1-3]
%			\arrow["U", from=3-1, to=3-3]
%		\end{tikzcd}\]
%	\end{proposition}
%	
%	This result is the reason why the Serre subcategory is defined the way it is. The conditions required in the definitions are precisely those such that the above proposition may hold.
%	
%	
	
	
	%	\begin{proof}
		%		The functor we use is sending a vector bundle to its set of sections which takes on a natural module structure over $C(X)$. To show that it infact goes to finitely generated proj modules 
		%	\end{proof}
		
%	\section{Localization theorem for $K_0$}\label{Localizationk0}
%%	Recall the definitions of Serre quotient.
%	\begin{theorem}[Localization theorem for $K_0$]
%		 For a small abelian category $\mathcal{A}$ and $\mathcal{B} \subset \mathcal{A}$ a Serre subcategory. The following sequence is exact
%		 \[ K_0(\mathcal{B}) \xrightarrow{f} K_0(\mathcal{A}) \xrightarrow{L} K_0(\mathcal{A/B}) \to 0 \]
%	\end{theorem}
%	\begin{proof}
%		By construction we know that $L$ is surjective.
%		Note we already know that $\mathrm{coker} f \to  K_0(\mathcal{A/B})$ is surjective due to the fact that $K_0(B) $ under composition through $T$ goes to zero.
%		
%		Consider the function $g:\mathcal{A/B} \to \mathrm{coker}f$ as $g(L(A)):=[A]$ as a natural candidate. If this is additive from we have found the required inverse.
%		
%		We already know that $T $ is bijective as a set function on objects of $\mathcal{A}$ by construction. Consider two isomorphic elements in the Serre quotient and claim their images under $g$ in $\mathrm{coker} f $ are also isomorphic. Consider $L(A) \cong L(B)$ by the definition of the morphisms this means we have a diagram representative as such.
%		\[ A \xleftarrow{n} X \xrightarrow{m} B \] with $\ker(n), \ker{m}, \mathrm{coker} (n) , \mathrm{coker}(m)$ in $\mathcal{B}$ (since its an isomorphism).
%		
%			As such in $K_0(\mathcal{A})$ we have, $$[X]=[A]+[\ker n]-[\mathrm{coker}(n)]=[B]+[\ker m]- [\mathrm{coker}(n)]$$ so in $\mathrm coker f$ we have $[X] = [A]=[B]$.
%			
%		We have shown $L(A) \cong L(B) \implies [A]=[B]$ in $\mathrm{coker} f$. Now to show additivity.
%		
%		To see that \( g \) is an additive function, suppose we are given an exact sequence in \( \mathcal{A/B} \) of the form
%		\[
%		0 \rightarrow L(A) \xrightarrow{u	} L(B) \xrightarrow{v} L(C) \rightarrow 0;
%		\]
%		we have to show that \( [B] = [A] + [C] \) in \( F \). Represent \( v \) by a diagram representative \( B \xleftarrow{o} Y \xrightarrow{p}	 C \) with \( o \) with $\ker o , \coker o \in \mathcal{B}$
%		
%		Now since canonically
%		\[
%		[Y] = [A] + [\ker(o)] - [\coker(o)] \text{ in } K_0(A),
%		\]
%		we have \( [Y] = [A] \) in \( \coker f \). Since \( L \) is exact and we know the below sequence is canonically exact
%		\[
%		0 \rightarrow \ker(p) \rightarrow Y \xrightarrow{p} B \rightarrow \coker(p) \rightarrow 0	\]
%	
%		Applying $L $ to above gives us that \( \coker(p) \) is in \( \mathcal B \) and that \( L(\ker(p)) \cong L(A) \) in \( \mathcal{A/B} \). Hence, \( [\ker(p)] = [A] \) in \( \coker f \), and in \( \coker f \) we have
%		\[
%		[B] = [Y] = [C] + [\ker(p)] - [\coker(p)] = [A] + [C],
%		\]
%	\end{proof}
%	\begin{example}
%		Consider the following non-example for why the above sequence need not be left exact.
%%		 Consider $A=k[t]$ for a field $k$. Consider the subcategory of modules annhilated by a power of $x$. Then all the terms are isomorphic to $\mathbb{Z}$.
%	\end{example}
%	\begin{corollary}\label{localizationk0corrolary}
%		For a multiplicative set $S$ then the category of $S$ torsion modules over $A$ denoted as $M_S(A)$ form a Serre subcategory. And we have \[ K_0(M_S(A) ) \to G_0(A) \to G_0(S^{-1}A) \to 0 \]
%		When $S=\{1,s,s^2,\cdots \}$ then just \[ K_0(A/sA) \to G_0(A) \to G_0[\frac{1}{s}]	 \to 0\]
%		The change is due to Devissage considering each module has a finite filtration given by multiplying by powers of $s$.
%	\end{corollary}


	\section{Fundamental theorems for $G_0, K_0$}
	We state a few important results here without proof their detailed proofs can be seen in \cite{weibel2013k}. These will be covered in the next project. As they lend themselves to quick generalizations and motivate the introduction of higher K groups.
	\begin{theorem}[Fundamental theorem for $G_0$ for noetherian rings $A$]\label{g0fund}
		$G_0[A] \cong G_0(A[t]) \cong G_0(A[t,t^{-1}])$.
	\end{theorem}
%	\begin{theorem}[Resolution theorem for $K_0$ for additive categories]
%		Let $\mathcal{A}$ be abelian and $\mathcal{C} \subset \mathcal{B} \subset \mathcal{A}$ additive subcategories. If the following conditions hold,
%		\begin{itemize}
%			\item Every $B \in \mathrm{Ob}(\mathcal{B})$ has finite $\mathcal{C}$ dimension, in the sense that there exist a minimal finite $\mathcal{C}$ resolution of $\mathcal{B}$ (in the sense of Definition \ref{defresolution})
%			\item $\mathcal{B}$ is closed under kernels of epis in $\mathcal{A}$.
%		\end{itemize}
%		then the inclusion functor $i:\mathcal{C } \to \mathcal{B}$ induces an isomorphism $K_0(\mathcal{C}) \cong K_0(\mathcal{B})$
%	\end{theorem}
%
%%	\begin{proof}
%%		This is a theorem due to Grothendieck.
%%		The evaluation morphism $e: A[t] \to A$ provides an inclusion $M(A) \subset M(A[t])$ and consequently a map $\tilde{e}: G_0(A) \to G_0(A[t])$ by Corollary \ref{localizationk0corrolary}. We obtain a exact sequence \[ G_0(A) \xrightarrow{\tilde{e}} G_0(A[t]) \to G_0(A[t,t^{-1}]) \to 0 \]
%%		
%		Now consider the exact sequence in $G_0(A[t])$ given by \[ 0 \to M[t]\to M[t] \to M \to 0 \] i.e. $\tilde e [M]=[M]=[M[t]]-M[[t]]=0$ so $\tilde e =0$ in $G_0[A[t]]$ so $ \implies G_0[A[t]] \cong G_0[A[t,t^{-1	}]]$.
%		
%		Since $A=A[t]/tA[t]$ applying Serres formula we get $\tilde e [M]=[M/Mt]- \mathrm{Ann}_M(t)$
%	\end{proof}
	
	
	\begin{definition}[Regular ring] A ring is called regular if every finitely generated ideal has finite projective dimension (minimal length of resolution by projective modules).
	\end{definition}
	\begin{example}
		Any Dedekind domain is a regular ring in particular a principal ideal domain is a regular ring.
	\end{example}

	\begin{theorem}[Fundamental theorem for $K_0$ of regular rings]\label{extensionk0iscong}
		For a regular ring $A$, $K_0(A)\cong G_0(A)$ and by Theorem \ref{g0fund} we have, \[ K_0(A) \cong K_0(A[t]) \cong K_0(A[t,t^{-1}]) .\]
	\end{theorem}

	
%%	These results can be naturally extended to schemes. Recall the definition of a scheme as such.
%%	\section{Basic $K_0, G_0$ theory for schemes}
%%	\begin{definition}[Scheme]
%%		content
%%	\end{definition}
%%	\begin{definition}[$G_0, K_0$ for noetherian scheme $X$]
%%		The category of coherent $\mathcal{O}_X$ modules form an abelian category. So its monoid completion is $G_0(X)$
%%	\end{definition}
%%	\begin{theorem}
%%		content
%%	\end{theorem}
%%	
%%	\begin{definition}[$K_0$ for Waldhausen categories]
%%		
%%	\end{definition}
%	
	
	
	\chapter{Quillen-Suslin Theorem}
	We will now move towards a detailed proof of Horrock's theorem which will give us a concise proof of the famous Quillen-Suslin theorem which states that projective modules over polynomial rings over principal ideal domains are free. 
	
	We follow Lang's book for the first few results which recounts Vaserstein's proof of Quillen-Suslin \cite{lang02}.
	

	\section{Hilbert-Serre and stable freeness}
%
%	\begin{theorem}\label{noetherianstabfree}
%		If $A$ is a noetherian ring such that every finitely generated projective $A-$module is stably free then every finitely generated projective $A[x]-$module is also stably free.
%	\end{theorem}
%	\begin{proof}
%		We prove this using the finite free resolution criteria for stable freeness proved in Lemma \ref{stabfreefinfreeres}.
%		
%		
%	\end{proof}
%	
	Recall the definitions of stably free modules \ref{stabfree} and resolutions of chain complexes \ref{defresolution}. We begin with a theorem due to Serre.
	\begin{theorem}[Hilbert-Serre]
	Finitely generated module over $k[x_1,\dots x_n]$ are stably free where $k$ is a principal ideal domain.
	\end{theorem}
	\begin{proof}
		Applying Theorem\ref{extensionk0iscong} and then Theorem\ref{k0pidisZ} gives us a quick proof of this result since $k[x_1,\dots,x_n]$ is regular. 
		
%		Alternatively we know that for a noetherian ring $k$, $k[X]$ is also noetherian and consequently so is $k[X_1,\ldots,X_n]$. This is the Hilbert basis theorem. 
%		
%		Now in a principal ideal domain $k$ every finitely generated projective module is free as seen in Proposition \ref{projfgpidfree}. Therefore every finitely generated projective module over $k$ is naturally stably free and by Theorem \ref{noetherianstabfree} and Hilbert basis we inductively have that finitely generated projective modules over $k[x_1,\dots,x_n]$ is stably free.
	\end{proof}
	
	\section{Unimodular rows}
	We now introduce an important concept of a unimodular row. This perspective helps greatly simplify the proof of Quillen-Suslin.
	
	\begin{definition}[Unimodular row]
		For a ring $A$, an element of $A^n$ is said to be a unimodular row if its components generate $A$. We denote the set of all unimodular rows of length $n$ in $A$ as $\mathrm{Um}_n(A)$.
	\end{definition}
	
	In particular $v=(v_1, \cdots, v_n) \in \mathrm{Um}_n(A) $ if there exists $a=(a_1, \cdots a_n) \in A^n$ such that $ v \cdot a = v^t a = \sum_{i=1}^n v_i a_i = 1$.
	\begin{definition}[Unimodular matrix]
		In general we say an arbitrary matrix over $A$ not necessarily square is unimodular if it is right invertible (i.e. a surjective map).
	\end{definition}
	Alternatively it can be useful to view a unimodular row as as element of $M_{1 \times n} (A) $ as such it represents a surjective linear map $A^n \to A$, or even an element in $M_{n \times 1}$ in which case it represents a injection from $A \to A^n$.
	
	Recall the definition of a stably free projective module (Definition \ref{stabfree}). Based on these definitions we can see that the kernel of the surjective $1 \times n $ matrix $A^n \to A$ (i.e. of a unimodular row) is precisely a stably free projective of the form $\underbrace{P}_{\ker v} \times A \cong A^n$.
	
	
	
	\begin{definition}[Equivalence of unimodular rows]
		For unimodular rows $v,w\in A^n$ we say $v \sim w $ if there exists $ \alpha \in GL_n(A)$ such that $v\alpha =w$.
	\end{definition}
	
	\begin{definition}[Unimodular completion property]
		Given a unimodular row $v=(v_1,\dots v_n) \in A^n$ if we can construct an invertible $n \times n $  matrix with $v$ in the first column we say $v$ has the unimodular completion property.
	\end{definition}
	

	
	\begin{lemma}
		A unimodular row $v \in A^n$ has the unimodular completion property iff $v \sim (1,0,\dots ,0)$.
	\end{lemma}
	\begin{proof}
		If $v$ can be extended to an invertible matrix $\alpha \in GL_n(A)$ then \[ v\alpha^{-1}  = (1,0,\dots, 0). \]
		Conversely if $\alpha' \in GL_n(A) $ s.t. $v\alpha'=(1,0,\dots,0)$ then $\alpha'^{-1}$ has $v$ in the first column.
	\end{proof}
		\begin{corollary}\label{row-of-inv-mat-unimod}
		Based on the above lemma we can see that naturally any row of an invertible matrix (and column realized as a row of its transpose) is a unimodular row. 
	\end{corollary}
	\begin{corollary}
		A projective module $P$ is free iff the unimodular row $v: A^n \to A$ such that $P=\ker v$ is completable to an invertible matrix (since we can adjoin the basis of $P$).
	\end{corollary}
	
	\begin{example}[Stably free projective module which is not free]
		Consider the ring $R$ of polynomial functions on the sphere $S^2$, $R=\mathbb{R}[x,y,z]/\langle x^2+y^2+z^2=1 \rangle$ the ring of real valued polynomials on $S^2$. Consider the unimodular row $v=(x,y,z)$. The associated projective module is $P=\ker v = \ker \{(p,q,r) \mapsto xp+yq+zr\}$. By definition $P \oplus R \cong R^3$. 
		
		Every element $(f, g, h)$ of $R^3$ yields a vector field in $\R^3$.
		
		The unimodular row $v$ is the vector field extending outward normal to the sphere. Therefore an element in $P$ yields a vector field in tangent to the 2-sphere $S^2$. 
		
		If $P$ were free, i.e. $P \cong R^2$ a basis of $P$ would yield two tangent vector fields on $S^2$ which are linearly independent at every point of $S^2$. This would mean we could construct a nowhere vanishing vector field on $S^2$ as a linear combination of these basis vector fields which is linearly independent at each point of $S^2$. This leads to a contradiction. The 'Hairy ball theorem' states that \cite{hairyball} any continuous vector field on $S^2$ must have at least one zero.
	\end{example}
	
	\begin{proposition}\label{inductionbaseforprequillensuslin}
		Over a principal ideal domain $A$ any two unimodular rows in $A^n$ are equivalent.
	\end{proposition}
	\begin{proof}
		Let $v $ be a unimodular row. So that we get a split sequence $0 \to A \xrightarrow{v} A^n \to P \to 0 $ for some stably free $P$. We have that $\coker v = A^n/ \image \{v\} $ is free as submodules of free finitely generated modules over a principal ideal domain are free (Proposition \ref{submodoffreemodisfreepid}). So there exists a basis for $A^n$ containing $v$, i.e. $v \sim (1,0,\cdots,0)$

	\end{proof}
	Using Theorem \ref{a2} which says that that projective finitely generated modules over local rings are free we obtain.
	\begin{proposition}
		Over a local ring $A$ any two unimodular rows are equivalent.
	\end{proposition}
	
	\section{Proof of Quillen-Suslin theorem}
	We begin with a useful theorem due to Horrocks.
	\begin{theorem}[Horrocks' theorem]
	If $(A, \mathfrak{m})$ is a local ring then for any arbitrary unimodular row $v(x)$ in $A[x]^n$ such that one of its component elements has leading coefficient one implies that $v$ has the unimodular completion property. Furthermore, any such $v$ is equivalent to $v(0)$.
	\end{theorem}
	\begin{proof}
	Recall that for a local ring $x \not \in \mathfrak m$ iff $ x  $ is a unit.
	
	When $n=1 $ there is nothing to prove. If $n=2$ by unimodularity of $v(x)$ we have $v_1(x)w_1(x)+v_2(x)w_2(x)=1$ simply consider the matrix
	\[ \begin{bmatrix}
		v_1(x) & -w_2(x)\\
		v_2(x) & w_1(x)
	\end{bmatrix}. \]
	
	We proceed with $n \geq 3$.
	Without loss of generality, we take $v_1(x)$ with degree $d $ among components with leading coefficient $1$ and $\deg v_i < d, $ for $i \neq 1$ by repeated elementary row operations to move the components around. We proceed by inducting on $d$.
	
	By unimodularity we know there exists $w(x)\in A[x]^n$ such that,
	\[ \sum_{i=1}^n w_i v_i = 1 \]
	Now we can say that not all of the coefficients of $v_2, \dots v_n $ lie in $\mathfrak m$. For if it were the case, then reducing the above expression mod $\mathfrak m$ we arrive at a contradiction. Since after reducing mod $\mathfrak m$ all $v_i$ for $i \geq 2$ go to $0.$ Note that we assumed $v_1 $ has leading coefficient 1 which means that $w_1v_1$ wouldn't have a constant residue but then since the rest of the $v_i \in \mathfrak{m}$ they are non units and cannot account for the right hand side of the expression either.
	
	Therefore at least one of the other $v_i$ contains a unit in its coefficients say this is $v_2(x)$ and and as such one of its coefficients is a unit.
	In particular
	\begin{align*}
		v_1(x)&= x^d +a_{d-1} x^{d-1} + \cdots +a_0\\
		v_2(x)&=b_s x^s + \cdots + b_0,
	\end{align*}
	with some $b_j$ a unit.
	
	Now consider the ideal $I$ generated by the leading coefficients of polynomials of the form $z_1v_1+z_2v_2$ with degree $< d.$ Our claim is that $I $ contains all of the coefficients of $v_2$.
	
	This can be seen inductively. The trivial case is when we pick $z_1=0, z_2=1$ this gives us the coefficient of the $x^s$ term, i.e. $b_s$. Since $0v_1+1v_2=v_2$ and its leading coefficient is $b_s.$
	
	For $b_{s-1}$ consider $z_1=-b_s$ and $z_2=x^{d-s}$, then $z_1v1+z_2v_2$ has leading coefficient $b_{s-1}$ as we can see below.
	\begin{align*}
		&-b_s v_1(x)+x^{d-s}v_2(x) \\
		&=(b_sx^d + (-b_sa_{d-1} x^{d-1}) + \cdots +(-b_s a_0) )- (b_s x^d + b_{s-1}x^{d-1}\cdots + x^{d-s}b_0)\\
		&= (-b_sa_{d-1}-b_{s-1})x^{d-1} + \cdots 
	\end{align*}
	Note $b_s \in I, $ so $-b_sa_{d-1} \in I$ and so we have $-b_{s-1} \in I$ too.
	
	 Continuing this process we find that all coefficients of $v_2$ are in $I$, a fortiori the unit coefficient is in $I$. Meaning $I$ is a unit ideal, and so with a choice of $z_1, z_2$ we can construct any polynomial we require.
	
	Consequently this means there exists some choice of polynomials $y_1v_1+y_2v_2$ of degree $<d$ with leading coefficient $1$, increasing exponentials in $y_i$ appropriately we can adjust this to be of degree $d-1$. 
	
	Now consider $v_3$ by our construction we know it has degree $<d$ if its leading coefficient is a unit then multiply by the inverse and get a component with leading coefficient one of smaller degree than $v_1$ and repeat the process. Else if the leading coefficient is not a unit and $c \in \mathfrak{m}$, adding the above choice of $y_1v_1+y_2v_2$ to $v_3$ gives us a degree $d-1$ polynomial with a unital leading term since $1+c$ is a unit if $c \in \mathfrak{ m }$ due to locality.
	
	We keep repeating this process of reducing $d$ until $d=0$ leaving us with a unit component allowing us to cancel out the other components and be left with $v \sim (1,0,\ldots, 0)$ as expected.
	\end{proof}
	
	We now extend the idea of Horrock's theorem.
	
	\begin{lemma}\label{horrocksbutforlocal}
		For an integral domain $A$ and a multiplicative subset $S$ if $v(x) \sim v(0)$ unimodular over $A_S[x]^n $ then there exists $b \in S$ such that \\$v(x+by) \sim v(x) $ over $A[x,y]^n.$
	\end{lemma}
	\begin{proof}
		By the equivalence $v(x) \sim v(0)$ we know there exists a matrix $\alpha (x) \in GL_n(A_S[x])$ such that $\alpha(x)v(x)=v(0) $. Now consider \[ \beta(x,y) := \alpha(x)^{-1} \alpha(x+y) \]
		
		Note that this gives us the relation, $$\beta(x,y)v(x+y)=\alpha(x)^{-1}\alpha(x+y) v(x+y)=\alpha(x)^{-1}v(0)=v(x).$$ Under the mapping $y \mapsto by$ we have that $\beta(x,by)v(x+by)=v(x).$
		
		Now we have to show that indeed $\beta(x,by)\in A[x,y]$ for some choice of $b \in S$. Note this is true since $\beta(x,0)=I_n $. This implies $\beta(x,y)=I+yP $ for some $P \in A_S[x,y],$ but this just means there is some appropriate choice of $b \in S$ that allow us to cancel out all the denominators in $P$ so that $P[x,by] \in A[x,y]$. So with a choice of matrix $\beta(x,by) \in GL_A[x,y]$ we are done, as this forms an equivalence between $v(x+y) $  and $v(x).$
	\end{proof}
	
	\begin{lemma}\label{horrocksbuteverything}
		For an integral domain $A$ and $v(x)$ unimodular row in $A[x]^n$ with at least one component having leading coefficient one implies $v(x) \sim v(0)$.
	\end{lemma}
	\begin{proof}
		Consider the set $I$ containing all $b \in A$ such that $v(x+by)\sim v(x)$ as rows in $A[x,y]$. If the ideal contains $1$, then sending $x \to 0$ would give us $v(y)\sim v(0) $ in $A[y].$ We proceed to show that the ideal $I$ contains $1$.
		
		We can achieve this by first showing $I$ is an ideal and then showing that its not contained in any maximal ideal.	To do this last step we will localize at the maximals and use the previous result.
		
		First prove that $I$ is an ideal.
		\begin{enumerate}
			\item $I \neq \emptyset $ as $0 \in I$
			\item If $b,c \in I$ then $b-c \in I$ as $v(x+(b-c)y)=v(x+by-cy) \sim v(x+by) \sim v(x)$ by a substitution $x \mapsto x+by$
			\item For $a \in A, b \in I$ then simply $v(x+bay) \sim v(x)$ by the $y \mapsto ay$
		\end{enumerate}
		
		Now to show $I$ is not contained in any maximal ideal. Pick a maximal ideal $\mathfrak m$ and localize at it first due to Horrocks we know $v(x) \sim v(0) $ in $A_{\mathfrak m} [x]$ and then due to the previous Lemma \ref{horrocksbutforlocal} we find some $b \in A\setminus \mathfrak m$ such that $v(x+by) \sim v(x) \sim v(0)$. Note this just means that $ b \in I$ and so $I\not \subset \mathfrak m$ this applies to any maximal and so we are done.  
	\end{proof}
	
	\begin{theorem}
		For $A=k[x_1, \dots, x_n]$ where $k $ is a principal ideal domain, then $v \sim (1,0,\dots, 0)$ for any unimodular row $v \in A^n$.
	\end{theorem}
	\begin{proof}
		Proceed with induction on $n$. We proved $n=0$ above Proposition \ref{inductionbaseforprequillensuslin}.
		
		Assume the result holds for $m-1$ greater than $0$.
		
		Then $v \in k[x_1, \dots, x_m] \cong k[x_1,\dots, x_{m-1}] [x_m]$ can be realized as $v(x_m) $ with coefficients in $k[x_1,\dots, x_{m-1}]$. If $v(x_m)$ has some component with leading coefficient $1$ then by Lemma \ref{horrocksbuteverything} we now $v(x_m) \sim v(0) \in k[x_1, \dots, x_{m-1}]$ and we can reduce by induction.
		
		So if not by some appropriate change of variables as amongst $x_1, \dots, x_{m-1}$ in the form of $x_i \mapsto x_i-x_m^{p_i}$ for very large $p_i$'s this allows us obtain the leading coefficient in terms of $x_m$ to be 1 as needed.
	\end{proof}

	
	
	\begin{theorem}[Quillen-Suslin]
		Finitely generated projective modules over $A=k[x_1,\dots,x_n]$ where $k$ is a principal ideal domain are free.
	\end{theorem}
	\begin{proof}
		We know such finitely generated projective modules are stably free, and from above we know any unimodular row in $A$ is equivalent to $(1,0,\dots,0)$.
		
		That is to say given a finitely generated projective module $P$ which is stably free, i.e. $P \oplus R^{m_1} \cong R^{m_2}$ then $P$ is free.
		
		When $m_1=1$ this is the split exact sequence (since P is projective see \ref{projtfae}),
		\[ 0 \to A \to A^{m_2}  \to P \to 0 \]
		The injection $A \to A^{m_2}$ is precisely a unimodular row by definition which we know must correspond to the canonical embedding of $1 \mapsto (1,0,\cdots, 0)$.
		So,$$P = \mathrm{im}(A^{m_2} \to P) \cong A^{m_2}/\ker (A^{m_2} \to P) \cong A^{m_2}/\mathrm{im}(A \to A^{m_2}).$$
		Note $A^{m_2}/\mathrm{im}(A \to A^{m_2})$ is free since $\mathrm{im}(A \to A^{m_2})$ is naturally free due to the embedding.
		
		When $m_1 \neq 1$ just take $(P \oplus A^{m_1-1}) \oplus A$.
	\end{proof}


	
	\chapter{Whitehead group $K_1$}
	\begin{definition}[Whitehead group for a ring] $K_1$ for a ring $A$ is defined as the abelianization of its infinite general linear group.
		$$K_1:= \frac{GL(A)}{[GL(A):GL(A)]},$$
		Where $GL(A)$ the infinite general linear group is the colimit of $GL_n(A)$ with $GL_{n}$ realized as a subgroup of $GL_{n+1}$ by placing the matrix in the top left corner. 
	\end{definition}
	Note that $[GL(A):GL(A)]$ denotes the derived/commutator subgroup of $GL(A)$, the subgroup generated by all commutators $[g:h]=g^{-1}h^{-1}gh$ for $g,h \in GL(A)$.
	\begin{definition}[Elementary matrices]
		We denote the $n\times n$ elementary matrices as $E_n(A)$ generated by standard elementary matrices of the form $e_{ij}(\lambda) := I_{n}+ \lambda E_{ij} $ where $E_{ij}$ is the matrix with $1$ in the $(i,j)$ entry and zero elsewhere.
	\end{definition}
	
	\begin{lemma}\label{diag1andprodelementary}
		A nonsingular triangular matrix with $1$'s in the diagonal is a product of standard elementary matrices.
	\end{lemma}
	\begin{proof}
		Let $\alpha \in GL_n(A)$ then consider the following inductive procedure.
		\begin{align*}
			\alpha&= \begin{bmatrix}
				1 & a_{12} &\cdots &a_{1n}\\
				0& 1 & \cdots &a_{2n}\\
				\vdots & \vdots  & \ddots  & \vdots \\
				0 & 0 & \dots & 1
			\end{bmatrix}
			= \begin{bmatrix}
				1 & a_{12} &\cdots &a_{1n}\\
				0&  &   &\\
				\vdots &  & \alpha_{n-1}  &  \\
				0 &  & & 
			\end{bmatrix}\\
			\alpha&=\begin{bmatrix}
				1 & 0 &\cdots &0\\
				0&  &   &\\
				\vdots &  & \alpha_{n-1}  &  \\
				0 &  & & 
			\end{bmatrix} e_{12}(a_{12}) e_{13}(a_{13}) \cdots e_{1n}(a_{1n})\\
			\intertext{Repeat the procedure for $\alpha_{n-1}$, which is of the same form as $\alpha$. We obtain}
			\alpha&= \begin{bmatrix}
				1 & 0 & 0 & \cdots & 0 \\
				0 & 1 & 0 & \cdots & 0\\
				0 & 0 &   &  &\\
				\vdots & 0 &   &\alpha_{n-2}  &\\
				0 & 0 &   &  &
			\end{bmatrix}\prod_{j=2}^n e_{2j}(a_{2j}) \prod_{i=1}^n e_{1i} (a_{1i}).
		\end{align*}
		Continuing this process we obtain the required result.
	\end{proof}
	
	\begin{proposition}\label{whiteheadsimple}
		Let $A$ be a ring and $u$ be a unit in $A$, i.e. $u \in A^\times$. Then,
		\[ {\displaystyle {\begin{bmatrix}u&0\\0&u^{-1}\end{bmatrix}}} \equiv I_2 \mod E_2(A).\]
	\end{proposition}
	\begin{proof}
		${\displaystyle {\begin{bmatrix}u&0\\0&u^{-1}\end{bmatrix}}=e_{21}(u^{-1})e_{12}(1-u)e_{21}(-1)e_{12}(1-u^{-1}).}$
	\end{proof}
	\begin{lemma}[Whitehead]\label{whiteheadmain}
		For $\alpha,\beta \in GL_n(A),$ \[ \begin{bmatrix}
			\alpha \beta & 0 \\ 0 & I_n
		\end{bmatrix} \equiv \begin{bmatrix} \alpha & 0 \\ 0 & \beta
		\end{bmatrix} \equiv \begin{bmatrix}
			\beta \alpha  & 0 \\ 0 & I_n 
		\end{bmatrix} \mod E_{2n} (A).\]
	\end{lemma}
	\begin{proof}
		Let $A=M_n(A)$ and note $E_2(M_n(A) ) \subset E_{2n}(A)$ in Proposition \ref{whiteheadsimple}.
	\end{proof}
		\begin{proposition}
		\[ [GL(A):GL(A)]=E(A) .\]
	\end{proposition}
	\begin{proof}
		Using Lemma \ref{whiteheadmain} we can see that \[ \begin{bmatrix}
			\alpha^{-1}\beta^{-1} & 0 \\ 0 & I_n
		\end{bmatrix} \equiv \begin{bmatrix}
			\beta^{-1} \alpha^{-1 } & 0 \\
			0 & 1_n
		\end{bmatrix} \mod E_{2n}(A)\]
		So the derived subgroup of $GL_n(A)$ is contained in $E_{2n}(A)$. Furthermore, every elementary matrix $e_{ij}(\lambda)$ is realized as a commutator since, $e_{ij}(\lambda)=[e_{ik}(1 ), e_{kj} (\lambda)]$.
	\end{proof}	
	
	\begin{lemma}
		For a Euclidean domain $A$ we have $SL_n(A)=EL_n(A)$ for all $n \in \N$.
	\end{lemma}
	\begin{proof}
		With elementary row and column operations arrange the matrix so that the element with the smallest norm is in the top right position. Using elementary row operations reduce it to a matrix with a unit in the top left and 0s in the rest of the first column and first row. Proceeding similarly for the remaining $(n-1) \times (n-1) $ matrix left we reduce it down to a matrix of the form.
		
		\[ \begin{bmatrix}
			u_1 & 0 & \dots & 0 \\
			0 & u_2 & \dots & 0 \\
			\vdots & 0 & \ddots & 0\\
			0 & 0 & \dots & u_n 
		\end{bmatrix} \]
		
		Now apply Whiteheads lemma 
	\end{proof}
	
	\begin{definition}[Relative $K_1$]
		$SK_1(A):= \ker \det,$
		
		where, $\det : K_1(A) \to A^\times$. We have a split exact sequence
		\[ 0 \to SK_1(A) \to K_1(A) \to A^\times \to 0 .\]
	\end{definition}
	
	
%	\section{Relationship between $K_0$ and $K_1$}
%	\begin{theorem}[Mayer-Vietoris]
%	\end{theorem}
%	\begin{theorem}
%		Let $A$ be a ring and $S$ denote a multiplicatively closed set of central elements in $A$. We obtain the following exact sequence
%		\[ K_1(A)  \to K_1(S^{-1}A ) \to K_0(A \text{ on } S) \to K_0(A) \to K_0(S^{-1} A)\]
%	\end{theorem}
	\chapter{Results on linear groups}
	
	\section{Suslin's Normality theorem}
		We now consider a result due to Suslin about the normality of $E_n(A) $ in $GL_n(A)$. The following Lemma due to Vaserstein will be useful.
		\begin{lemma}[Vaserstein]\label{vasersteinlem}
			Let $\alpha \in M_{m,n} (A)$ and $\beta \in M_{n,m}(A)$ then $I_m+\alpha \beta \in GL_m(A)$ implies that $I_n+\beta \alpha \in GL_n(A)$ and, \[ \begin{bmatrix}
				I_m+\alpha \beta & 0 \\ 0 & (I_n+\beta \alpha)^{-1}
			\end{bmatrix} \in E_{m+n} (A).\] 
		\end{lemma}
		\begin{proof}
			Note that $(I_n+\beta \alpha )^{-1}=I_n-\beta (I_m+\alpha \beta )^{-1} \alpha$. Consider,

%			Lemma \ref{whiteheadsimple} cannot be applied in this case since $n\neq m$ in general. But the idea is nearly the same. 
			
			\[ \begin{bmatrix}
				I_m+\alpha \beta & 0 \\ 0 & (I_n+\beta \alpha)^{-1}
			\end{bmatrix} =
			\]
			\(\begin{bmatrix}
			I_m & 0 \\
			(I_n+\beta \alpha )^{-1}\beta I_n
			\end{bmatrix}\begin{bmatrix}
			I_m & -\alpha \\
			0 & I_n
			\end{bmatrix} \begin{bmatrix}
			I_m & 0\\
			-\beta  & I_n
			\end{bmatrix} \begin{bmatrix}
			I_m & (I_n+\alpha \beta )^{-1} \alpha \\
			0 & I_n
			\end{bmatrix}\in E_{m+n} (A).\)
			 
			By Proposition \ref{diag1andprodelementary}, the triangular matrices here are indeed elementary.
		\end{proof}
		
		\begin{corollary}\label{corofvaserstein}
		Let $v = (v_1,\ldots,v_n)^t$ and $w = (w_1,\ldots,w_n)^t$ be column vectors in $R^n$ such that $w^tv = 0$, and suppose $w_i = 0$ for some $i \leq n$. Then $I_n + vw^t \in E_n(R)$.
		\end{corollary}
		\begin{proof}
			When $w_i =0$ for $i \neq n $ we have $\alpha(I_n+vw^t)\alpha^{-1}=I_n+(\alpha v)(w^t\alpha^{-1})$for $\alpha=e_{in}(-1)e_{ni}(1)e_{in}(-1)$, which acts as a permutation matrix making the nth term i.e. $(w^t \alpha^{-1})^t_n=0$.
			
			Therefore, without loss of generality we may assume that $w_n=0$. Now define $w'=(w_1,\cdots, w_{n-1})^t, v'=(v_1, \cdots, v_{n-1}) \in R^{n-1}$. Since $w_n=0$ and $w^tv=0 $ implies that $w'^tv'=0$ also. 
			
			Proceeding inductively on $n$. We can say that $I_{n-1}+v'w'^t \in E_{n-1}(R)$. Note that the base case $n=1$ is given by Lemma \ref{vasersteinlem}.
			
			Therefore we have  \[
			I_n + v w^t = \begin{bmatrix}  & 0 \\ 
			I_{n-1} + v' w'^t	& 0\\
				 & \vdots \\ \hline
				* & 1 \end{bmatrix},
			\]
			We can make the last row zero using appropriate column transformations using the last column (which are all elementary matrices). Therefore, $I_n +vw^t \in E_n(R).$
		\end{proof}
		
		\begin{lemma}\label{kernelf}
			For $v$ unimodular row in $R^n,$ and $f: R^n \to R$ a $R-$ linear map determined by $e_i \mapsto v_i $, where $e_i $ is the standard basis element of $R^n$. We have,
			\[ \ker (f) =\left\{w=(w_1,\cdots w_n)^t \mid \sum_i^n w_i v_i =0\right\} \] and it is generated by elements of the form \( \{ v_j e_i - v_i e_j \} \) for positive $i \leq n$.
			\end{lemma}
		\begin{proof}
			We wish to show that $\ker(f)$ is generated by the elements $$\{v_je_i - v_ie_j \mid 1 \leq i \leq n\}.$$
			By definition of unimodularity of $v$, there exist elements $r_1, \ldots, r_n \in R$ such that $\sum_{i=1}^n r_iv_i = 1$. Consider the 
			$R$-module homomorphism $g: R \to R^n$ given by $g(1) = (r_1, \ldots, r_n)^t$. This provides a splitting 
			on the right of the exact sequence \[ 0 \to \ker (f ) \to R^n \xrightarrow{f} R \to 0 \] since $f(g(1))=\sum_i r_iv_i = 1$. So the sequence is split exact and $R^n \cong \ker (f) \oplus R.$
			
			Now, consider a map $h:R^n \to \ker f$ defined as  $h(x)=x - g(f(x))$. This creates a splitting on the left side of the 
			exact sequence, since  $h|_{\ker(f)} = 1_{\ker(f)}$. Since $h$ is surjective, the 
			elements $h(e_i)$ generate $\ker(f)$.
			\begin{align*}
				h(e_i) &= e_i - g(f(e_i)) = e_i - g(v_i) = e_i-v_ig(1)\\
				&=e_i-(v_ir_1, v_i r_2, \ldots, v_i r_n)= e_i - v_i \sum_j r_je_j\\
				&= (\sum_j r_jv_j)e_i - \sum_j r_jv_ie_j = \sum_j r_j(v_je_i - v_ie_j)
			\end{align*}
			
			This shows that $\ker(f)$ is indeed generated by the claimed elements.
		\end{proof}
		
		We finally generalize Corollary \ref{corofvaserstein} to the following lemma which will be used in the proof of the normality theorem.
		\begin{proposition}\label{finalpropfornormality}
			Let $n \geq 3$. If $v \in R^n$ is unimodular, and $w \in R^n$ such that $w^tv = 0$, then $I_n + vw^t \in E_n(R)$ and this is also true if $w$ is unimodular and $v$ is arbitrary by transposition.
		\end{proposition}
		
		\begin{proof}
			Consider the $R$-linear map $f:R^n \to R$ defined as $e_i \mapsto v_i$. The condition $w^tv = 0 $ implies $w^t \in Ker(f)$. By Lemma \ref{kernelf}, there exists $r_{ij} \in R$ such that we can decompose $w^t$ as such
			\[
			w^t = \sum_{i<j} r_{ij}(v_ie_j - v_je_i).
			\]
			
			Label $w_{ij}^t = v_ie_j - v_je_i$ and decompose $I_n+vw^t$ 
			\[
			I_n + vw^t = I_n + v\sum_{i<j} w_{ij}^t = \prod_{i<j}(I_n + vw_{ij}^t).
			\]
			
			We have $w_{ij}v=0$ and since $n \geq 3$, there exists a zero component and so we have from Corollary \ref{corofvaserstein} that $I_n + vw_{ij}^t \in E_n(R)$ for all $i < j$. This completes the proof.
		\end{proof}
	
	\begin{theorem}[Suslin's Normality theorem]
		For $A$, a commutative ring with unity, $E_n(A)$ normal in $GL_n(A)$ for $n \geq 3$. 
	\end{theorem}
	\begin{proof}
		Since $E_n(R)$ is generated by $e_{ij} (\lambda) $ it suffices to check that $\alpha e_{ij}(\lambda) \alpha^{-1} \in E_n(R)$ for $\alpha \in GL_n(A)$.
		
		 Recall from \ref{row-of-inv-mat-unimod} that the columns of $\alpha$ and the rows of $\alpha^{-1}$ are unimodular.
		\[ \alpha e_{ij} (\lambda ) \alpha^{-1}= \alpha(I_n+\lambda E_{ij}) \alpha^{-1} = I_n +\lambda c_i r_j\]
		Where $c_i$ is the $i^\mathrm{th}$ column of $\alpha$ and $r_j$ is the $j^{\mathrm{th}}$ row of $\alpha^{-1}$.
		
		Furthermore since $\alpha^{-1}\alpha =I_n $ implies $r_jc_i=\delta_{ij} $ implies using Proposition \ref{finalpropfornormality} that $\alpha e_{ij}(\lambda) \alpha^{-1} = I_n + \lambda c_i r_j \in E_n(A)$.
	\end{proof}
	
%	\begin{proposition}[Cohn] If $n=2$ $E_2(A)$ need not be normal in $SL_2(A)$
%		content
%	\end{proposition}
		\section{Local-global principle for unimodular vectors}
		In this section, we establish an important result that plays a crucial role in proving Suslinâ€™s factorial theorem. Specifically, we prove a useful `Local-global principle' for unimodular polynomial vectors.
		
		
		\begin{lemma}\label{lemlocalglobal}
			Let $S$ be a multiplicative set in $A$. For $f(x) \in GL_n(A_S[x])$ such that $f(0) = I_n$, there exists $\hat{f}(x) \in GL_nA[x])$ such that $\hat{f}(x)$ under the localization map maps to $f(sx)$ (for some $s \in S$), and $\hat{t}(0) = I_n$.
		\end{lemma}
		
		\begin{proof}
			Since $f(x) \in GL_n(A_S[x])$, there exists $g(x) \in GL_n(A_S[x])$ such that $f(x)g(x) = I_n$. The condition $f(0) = I_n$ implies $g(0) = I_n$.
			
			In particular this means that the diagonal entries belong to $1 + xA_S[x]$ and off diagonal entries are of the form $x A_S[x]$.
			
			Since only finitely many denominators appear in the entries of $f(x)$ and $g(x)$, there exists $s_1 \in S$ which is a common denominator.  This allows us `cancel' the denominators and to define matrices $f(s_1 x)$ and $g(s_1 x)$ with coefficients in $A$. 
			
			This means there exist $f_1(x)$ and $g_1(x)$ with polynomial entries in $A[x]$ with $f_1(0) = g_1(0) = I_n$ which map to $f(s_1x), g(s_1x)$ under the localization map.
			
			Let $h(x) = f_1(x)g_1(x)$. Then $h(x)$ maps to $f(s_1x)g(s_1x) = I_n$ under the localization map. Since $h(0) = I_n$, there exists $s_2 \in S$ such that $h(s_2x) = I_n$.  This implies that $f_1(s_2x)$ is invertible over $A[x]$ with inverse $g_1(s_2x)$.
			
			Therefore, we define $\hat{f}(x) = f_1(s_2x)$.  Then $\hat{f}(x) \in GL_n(A[x])$, $\hat{f}(0) = I_n$, and the image of $\hat{f}(x)$ under the localization map is $f(s_1 s_2 x)$. Thus, setting $s = s_1 s_2$, the lemma is proved.
			\end{proof}
		
			The below result is a generalization of Lemma \ref{horrocksbutforlocal}.
	\begin{proposition}\label{generaliationoflocalhorrocks}
		Let $A$ be a commutative ring and $S$ a multiplicative subset of $A$. For $v = (v_1, \dots, v_n) \in \mathrm{Um}_n(A[x])$, the following statements are equivalent:
		\begin{enumerate}
			\item $v(x) \sim v(0)$ over $A_S[x]$.
			\item There exists $b \in S$ such that $v(x + by) \sim v(x)$ over $A[x, y]$.
		\end{enumerate}
	\end{proposition}
	
	\begin{proof}
	We first prove $2$ implies $1$. Consider a change of variable in $A_S[x,y]$ given by $x=0, y=b^{-1}x$ so we have that under the localization map $v(0+b b^{-1}x ) = v(x) \sim v(0) $ over $A_S[x]$ as required.
	
	For the other direction.
	There exists \( \alpha(x) \in GL_n(A_S[x]) \) such that \( v(x) \cdot \alpha(x) = v(0) \). Define $\beta$ as such  
	\(
	\beta(x, y) = \alpha(x + y) \alpha(x)^{-1} \in GL_n(A_S[x, y]).
	\)
	\begin{align*}
			v(x + y)  \beta(x, y) &= v(x + y)  \alpha(x + y)  \alpha(x)^{-1}\\
			&=v(0) \alpha(x)^{-1} = v(x) \in A_S[x,y].
	\end{align*}
	This shows $v(x+y) \sim v(x) $ over $A_s[x,y]$ now we lift it to $A[x,y]$.
	
	Since \( \beta(x, 0) = \alpha(x) \cdot \alpha(x)^{-1} = I_n \), we can apply Lemma \ref{lemlocalglobal} over \( A[x] \) to obtain \( \hat{\beta}(x, y) \in GL_n(A[x, y]) \) such that under the localization map it goes to \( \beta(x, sy) \in GL_n(A_S[x,y])\) for some \( s \in S \), and \( \hat{\beta}(x, 0) = I_n \). 
	
	With $y\mapsto sy$ in the above relation lifted to \( A[x, y]^n \), we have  
	\[
	v(x + sy)  \hat{\beta}(x, y) - v(x) = y  g(x, y)
	\]
	for some \( g(x, y) \) that localizes to 0, so there exists \( s' \in S \) such that 
	\[
	v(x + ss'y) \hat{\beta}(x, s'y) - v(x) = y  s' g(x, s'y) = 0.
	\]
	Choose $n=ss' $ and we are done.
	\end{proof}
		
	\begin{proposition}
		Let $v(x) = (v_1(x), \dots, v_n(x)) \in \mathrm{Um}_n(A[x])$. Define the ideals $\mathfrak{a}$ and $\mathfrak{b}$ as follows:
		\begin{align*} \mathfrak{a} &= \{a \in A \mid v(x) \sim v(0) \text{ over } A_a[x] \} \\ \mathfrak{b} &= \{b \in A \mid v(x + by) \sim v(x) \text{ over } A[x, y] \} \end{align*} 
		Then $\mathfrak{a}$ and $\mathfrak{b}$ are ideals in $A$, with $\mathfrak{a} = \text{rad}(\mathfrak{b})$.
	\end{proposition}
	
	\begin{proof}
		If $b \in \mathfrak{b}$, then $v(x + by) \sim v(x)$.  With a substitution of variables for any $r \in A$, we have $v(x +bry) \sim v(x)$, so $br \in \mathfrak{b}$.  If $b, b' \in \mathfrak{b}$, then the substitution $x \mapsto x+b'y$ shows that $\mathfrak{b}$ is an ideal. Since, $ v(x+(b'+b)y) \sim v(x+b'y) \sim v(x)$.
		
		 The equality $\mathfrak{a} = \text{rad}(\mathfrak{b})$ follows from the above proposition.
	\end{proof}
	
	\begin{theorem}[Local-global principle]\label{localglobalprinciple}
		Let $v = (v_1, \dots, v_n) \in \mathrm{Um}_n(A[x])$. If $v(x) \sim v(0)$ over $A_{\mathfrak{m}}[x]$ for all maximal $\mathfrak{m} \in A$, then $v(x) \sim v(0)$ over $A[x]$.
	\end{theorem}
	
	\begin{proof}
		Define $\mathfrak{a}$ and $\mathfrak{b}$ as above. Suppose $v(x) \sim v(0)$ over $A_\mathfrak{m}[x]$ Proposition \ref{generaliationoflocalhorrocks} implies that there exist $b \in A \setminus \mathfrak m$ such that $v(x+by) \sim v(x)$ over $A[x,y]$.
		
		i.e $A\setminus \mathfrak{m}$ contains an element of $\mathfrak{b}$ this implies $\mathfrak{b} = A$.  Since $\mathrm{rad}(\mathfrak{b})= \mathrm{rad}(A)=A$, we have $\mathfrak{a} = A$, which implies $v(x) \sim v(0)$ over $A[x]$.
	\end{proof}
		
		\section{Suslin's factorial theorem}	
		In this section we will prove a celebrated theorem due to Suslin. \begin{theorem}[Suslin's factorial theorem]\label{suslinfactorial}
			Given $(v_0,\dots,v_n) \in \mathrm{Um}_{n+1}(A)$ then $n! | \prod_{i=0}^n m_i$, then $(v_0^{m_1}, \dots, v_n^{m_n}) \in \mathrm{Um}_{n+1}(A).$ 
		\end{theorem}
		
			The proof of the theorem in this section can be seen in detail in the papers by Suslin \cite{suslin1977} and the expository book by Lam \cite{lam2010serre}. 
			
			The converse of this result is also true as proved by Suslin in \cite{suslin1982}. 
			
	
%	We will first prove that given $(v_0,\cdots,v_n) \in \mathrm{Um}_{n+1}(A)$ if $n! | \prod_{i=0}^n m_i$ then $(v_0^{m_1}, \cdots, v_n^{m_n}) \in \mathrm{Um}_{n+1}(A)$ and it is completable.
%	
	\begin{proposition} If there exists $v=(v_0, v_1, \cdots v_n) \in \mathrm{Um}_{n+1}(A)$ such that $\bar{v}=(\bar{v}_0, \cdots, \bar{v}_{n-1})$ is completable over the ring $\bar{A}=A/Av_n$ then, $$(v_0,\cdots, v_{n-1} ,v_n^n) \in \mathrm{Um}_{n+1}(A)$$ and it is completable in $A$.
		
	\end{proposition}
	\begin{proof}
		Let $\alpha \in M_{n}(A)$ be some matrix with first row $(v_0 \cdots, v_{n-1})$ such that $\bar{\alpha} \in GL_{n}(\bar{A})$ (which we know exists due to $v$ being completable) let $\beta \in M_{n}(A)$ be the lift of $\bar{\alpha}^{-1},$ i.e., $\bar{\alpha}\bar{\beta} = I_{n}$. Then $$\alpha \beta= I_n+v_n \gamma, \ \ \beta \alpha=I_n+v_n \delta$$ for some $\gamma,\delta \in M_{n}(A)$.
		
		The matrix $\begin{bmatrix}
			\alpha & v_n I_{n}\\
			\delta & \beta 
		\end{bmatrix} \in GL_{2n}(A)$ since $$\begin{bmatrix}
		\alpha & v_n I_n\\ \delta & \beta 
		\end{bmatrix} \cdot \begin{bmatrix}
		\beta & -v_n I_n \\ -\gamma & \alpha 
		\end{bmatrix} = \begin{bmatrix}
		I_n & 0 \\ * & I_n
		\end{bmatrix} \in GL_{2n}(A).$$ 
		
		Note that $\det(\alpha)$ is a unit in $\bar{A}$ using Lemma \ref{whiteheadmain} on $\bar{A}$ and pulling back through the surjection $E_n(A) \to E_n(\bar{A})$ we have $$\begin{bmatrix}
			v_n^n & 0 \\ 0 & I_{n-1}
		\end{bmatrix} = (v_n I_n) \epsilon + \det(a) \zeta $$ for some $\epsilon \in E_n(A)$ and $\zeta  \in M_n(A)$.
		
	 Let $\alpha' = \text{adj}(\alpha)$ be the adjoint of $\alpha$. Recall that $\alpha \cdot \mathrm{adj}(\alpha )= \det (\alpha) I_n$, define a matrix $\varphi$ as such
		\begin{align*}
			\varphi = \begin{bmatrix} \alpha & v_nI_n \\ \delta & \beta \end{bmatrix} \begin{bmatrix} I_n & \alpha't \\ 0 & \epsilon \end{bmatrix} &= \begin{bmatrix} \alpha & \alpha \alpha' \zeta + v_n \epsilon  \\ \delta & * \end{bmatrix}\\
			&= \begin{bmatrix} \alpha & \det(\alpha) \zeta + v_n \epsilon \\ \delta & * \end{bmatrix} \\
			&= \left[ \begin{array}{c|c}
				\alpha & \begin{matrix}
					v_n^n & 0\\
					0 & I_{n-1}
				\end{matrix}\\ \hline
				\delta & *
			\end{array} \right ]\in GL_{2n}(R) 
		\end{align*}
		We now rewrite $\varphi$ in the following adjusted block form
		
		\[\begin{bmatrix} a_1 & a_2 \\ a_3 & a_4 \end{bmatrix},\] 
		
		where $a_1$ is $n \times (n+1)$ comprising of $a$ along with the column $(v_n^n, 0, \ldots, 0)^t$) adjoined at the right, $a_2 = \begin{bmatrix} 0 \\ I_{n-1} \end{bmatrix}$. 
		
		With appropriate elementary transformations on the last $n$ rows of $\varphi$, we obtain a matrix of the form
		\[\varphi' = \begin{bmatrix} a_1 & a_2 \\ a_3' & 0 \end{bmatrix}\]
		Now consider the submatrix of $\varphi'$ formally complementary to $I_{n-1}$ which we obtain by deleting the $2$nd up to the $n$th rows and the last $n-1$ columns. This is the required invertible $(n+1) \times (n+1)$ matrix with top row $(v_0,\ldots,v_{n-1},v_n^n)$.

		
	\end{proof}
	By induction on $n$, we obtain the following corollary.
	\begin{corollary}\label{corprefactorial}
		For $(v_0, \cdots, v_n) \in \mathrm{Um}_{n+1}(A)$ the row $(v_0, v_1, v_2^2, \cdots, v_n^n)$ is completable.
	\end{corollary}
	
	We now prove a result involving moving powers of coefficients in a unimodular row. Which in conjunction with the above corollary will prove the forward direction of Theorem \ref{suslinfactorial}.
	\begin{proposition}\label{propshifting}
		For $(v_0, \cdots, v_n) \in \mathrm{Um}_{n+1}(A)$ and any $r \in \N, i \neq j $ \[ (v_0, \cdots, v_i^r, \cdots, v_n) \sim (v_0, \cdots, v_j^r, \cdots, v_n) .\]
	\end{proposition}
	\begin{proof} Begin with the case of $i=0,j=1$. Define $f(t)=(v_0^r, v_1+v_0t, \cdots, v_n) \in \mathrm{Um}_{n+1}(A[t])$. 
		
		Claim that $f(t)\sim f(0)$ over $A[t]$. Using Theorem \ref{localglobalprinciple} local-global principle to check this equivalence in $A_\mathfrak{m}$ for some arbitrary $\mathfrak{m}$ maximal in $A$. 
		
		Assume that $v_0, v_2, \cdots, v_n \in \mathfrak{m}$ else the claim is naturally true as they will be invertible if not, so $v_1 \in A\setminus \mathfrak{m}$ is a unit. 
		
		Note that $(v_0^r, v_1 + v_0 t) \in \mathrm{Um}_2(A[t])$ since, which is naturally completable, unimodularity is due to the fact that not both $v_0^r$ and $v_1+v_0t \in \mathfrak m$ for if that is the case then $v_0,v_1 \in \mathfrak{m}$ which is a contradiction. Since this is true for all $\mathfrak m$. We have by the local-global principle that $(v_0^r, v_1 + v_0 t) \in \mathrm{Um}_2 (A[t])$ this is also completable as all length $2$ unimodular rows are naturally completable. In particular if $v_0^r b_0 + (v_1+v_0t) b_1 =1 $ then consider the matrix $\alpha \in GL_2(A[t])$ defined as $$\alpha = \begin{bmatrix}
			v_0^r & v_1 + v_0 t \\
			- b_1 & b_0
		\end{bmatrix}$$
		
		Therefore over $A[t]$ we have $f(t)$ is also completable with the block matrix \[ \beta = \begin{bmatrix}
			\alpha & \beta \\
			0 & I_{n-2}
		\end{bmatrix} \in GL_n(A)\] where the first row of $\beta$ equals $(v_2, \cdots, v_n)$. Therefore we have \[ f(t) \sim (1, 0, \ldots, 0) \sim f(0) \] as claimed. 
		
		Now note that $f(t) \sim f(0)$ over $A[t]$ implies that $f(-1) \sim f(0)$ over $A$ 
		\begin{align*}
			(v_0^r, v_1, v_2, \cdots, v_n) &\sim (v_0^r, v_1 - v_0, v_2, \cdots, v_n).
			\intertext{With the substitution $v_0 \mapsto v_1$ and $v_1 \mapsto v_1 - v_0$}
			&\sim (v_1^r, -v_0, v_2, \ldots, v_n)\\
			&\sim(v_0, v_1^r, v_2, \ldots, v_n).
		\end{align*}
		The last equivalence is true since the block matrix $\begin{bmatrix}
			-I & 0 \\ 0 & I
		\end{bmatrix} $ is elementary (with column transformations it is equivalent to the block matrix with $I$ in both diagonal places).
		
		Repeating this procedure for other $i \neq j $ completes the proof.	
  \end{proof}
	
	
	Combining Corollary \ref{corprefactorial} and Proposition \ref{propshifting} we obtain the proof of Theorem \ref{suslinfactorial} as required.
	
%	For the forward direction we require some additional machinery. Mainly the concept of a Mennicke symbol.
%	
%	\begin{definition}[Mennicke symbol]
%		A Mennicke symbol is a map $\phi : \mathrm{Um}_{n}(A) \to G $ where $G$ is a group such that,
%		\begin{enumerate}
%			\item $\phi(1,0,\dots, 0)=1, \phi(v)=\phi(v M)$ for $M \in E_n(A)$
%			\item $\phi(a,a_2,\dots,a_n)\cdot \phi(b,a_2, \dots a_n)=\phi(ab,a_2,\dots, a_n)$ if \\
%			$(a,a_2,\dots,a_n), (b,a_2,\dots,b_n) \in \mathrm{Um}_n(A)$.
%		\end{enumerate}
%	\end{definition}
%	
%	When $K_1(A)$ we obtain a special symbol. Which following the paper of  and \cite{Fossum1980} we label as $\mathrm{wt}$. It is constructed via a procedure called whitehead torsion the verification of the fact that it is indeed a Mennicke symbol can be seen in \cite{Fossum1980}.
%	\subsubsection{warning}
%	\begin{definition}
%		Let $A$ be a ring.  A \textit{Mennicke $n$-symbol} is a map $\phi: \text{Um}_n(A, \mathfrak{a}) \to C$ (where $\text{Um}_n(A, \mathfrak{a})$ denotes the set of unimodular rows of length $n$ congruent to $e_1$ modulo an ideal $\mathfrak{a}$ and $C$ is an abelian group) satisfying certain properties (see the original paper for details).  A universal Mennicke $n$-symbol exists.
%	\end{definition}
%	
%	\begin{definition}
%		For a unimodular row $v = (a_1, \dots, a_n) \in \text{Um}_n(A)$, the \textit{Whitehead torsion} $\text{wt}(v) \in K_1(A)$ is defined using a Koszul complex and contraction (see Section 2 of the paper for the detailed construction).
%	\end{definition}
%	
%	
%	\begin{proposition}[Fossum, Foxby, Iversen]
%		Let $A$ be a ring. The map $v \mapsto \text{wt}(v) \in K_1(A)$ is a Mennicke $n$-symbol.  If $n > d$ where $d = \dim A$, then $\text{wt}(v) \in SK_1(A)$ (the special K-group).
%	\end{proposition}
%	
%	\begin{proposition}
%		If $\alpha \in GL_n(A)$ and $v \in \text{Um}_n(A)$, then $\text{wt}(v\alpha) = \text{wt}(v) + (-1)^n [\alpha]$, where $[\alpha]$ denotes the class of $\alpha$ in $K_1(A)$.
%	\end{proposition}
%	
%	
%	
%	\begin{theorem}
%		Suppose that $F$ is a field and $m_1, \dots, m_n$ are natural numbers.  For $x_1, \dots, x_n$ as in Corollary 2.7 (related to the universal unimodular row), the unimodular row $\begin{pmatrix} x_1^{m_1} & \cdots & x_n^{m_n} \end{pmatrix}$ can be completed to an invertible matrix if and only if $\prod_{i=1}^n m_i$ is divisible by $(n-1)!$.
%	\end{theorem}
%	
%	\begin{proof}
%		The sufficiency of the condition is proved in [17]. Suppose that $\begin{pmatrix} x_1^{m_1} & \cdots & x_n^{m_n} \end{pmatrix}$ is the first row of an invertible matrix $Y$. Then $\text{wt}(x_1^{m_1}, \dots, x_n^{m_n}) = \prod_{i=1}^n m_i \text{wt}(x_1, \dots, x_n) = (-1)^n [\gamma]$ where $\gamma \in \text{SL}_n(F_n)$ and hence $[\gamma] = r \text{wt}(x_1, \dots, x_n)$.  The result follows.
%	\end{proof}
%	
	
	
%	\section{Higher K theory}
%	\section{Quillen + Construction}
%	\section{Quillen Q construction}
%	\section{$+=Q$}
%	\section{Waldhausen construction}
%	
	
%	\begin{appendices}
	
	

%	
%	\begin{definition}[Pullbacks of bundles]
%		content...
%	\end{definition}
%	
%	\begin{definition}[Whitney sums]
%		content...
%	\end{definition}
%	
%	\begin{definition}[Steifel Whitney Class]
%		content...
%	\end{definition}
%	\section{Categories}
	
%	\subsubsection{Important results}
%	There are a few concepts and definitions relevant in the conversation of abelian categories which we will list out here for completeness. Firstly is the notion of \textbf{exact functors} the typical notion of a functor carrying forward exact sequences. With the prefix of left/right added to determine it carrying forward only left or right sides of the exact sequence.
	
	
%	\begin{proposition}\label{adjointinjective}
%		Given a pair of adjoint functors $F \dashv U$ between abelian categories $F:\mathcal{C} \rightleftarrows \mathbf{D}:U$ if the left adjoint $F$ is exact, faithful and if $ \mathbf{D}$ has enough injectives also $\mathcal{C}$ has enough injectives.
%	\end{proposition}
%	\begin{proof}
%		content...
%	\end{proof}
%	\section{Derived categories}
%	\section{Exact categories}
%	
%	\section{Factorization systems, Model categories}
%	\section{Triangulated categories}
%	Add examples from Puppe sequence discussion from homological alg notes they form the triangulation in the case of the stable homotopy category.
%	
%	Also include quillen model cats somewhere in between.
%	
%	\section{Waldhausen categories}
%	Every exact category has a Waldhausen structure.
%	\section{Stable homotopy and Spectra (relevant or not? in top k yes in alg k ?) }
%	The definitions in this section are mainly using the convention in Adam's blue book \cite{adams1974stable}.
%	\begin{definition}[CW-Spectrum]
%		A sequence of based CW-complexes $\{E_n\}_{n \in \mathbb{Z}}$ with structure maps $\sum E_n \to E_{n+1}$
%	\end{definition}
%	The suggestive notation is pointing in the direction of the canonical spectrum known as the suspension spectrum when the structure maps are indeed suspensions.
%	\end{appendices}
%	\appendix

	
	
	\bibliographystyle{alpha}
	\bibliography{references}
\end{document}