\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{fontawesome5}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[toc,page]{appendix}
\usepackage[nottoc]{tocbibind}
\numberwithin{equation}{section}
\graphicspath{ {./Images/} }
\usepackage[raggedright]{titlesec}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{float}
\usepackage[autostyle]{csquotes}\usepackage{quiver}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}
\usepackage{hyperref}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Hom}{{\mathrm{Hom}}}
\newcommand{\image}{{\mathrm{Im}}}
\newcommand{\kernel}{{\mathrm{Ker}}}
\newcommand{\coker}{{\mathrm{coker}}}
% \newtheorem{dummy}{Dummy}[section]
\newcounter{dummy} \numberwithin{dummy}{section}
\newtheorem{theorem}[dummy]{Theorem}
\newtheorem{definition}[dummy]{Definition}
\newtheorem{corollary}[dummy]{Corollary}
\newtheorem{lemma}[dummy]{Lemma}
\newtheorem{proposition}[dummy]{Proposition}
\newtheorem{example}[dummy]{Example}
%opening
\title{Algebraic K-Theory}
\author{Bhoris Dhanjal}
\begin{document}
	\tableofcontents
	\maketitle
	\section{Classical K-Theory}
	The category of finitely generated projective modules is the main object of study in algebraic K-theory. This is largely motivated by the following theorem due to Swan \cite{Swan1962} which relates algebraic K-theory to topological K-theory.
	\begin{theorem}[Swan's theorem]
		There exists an equivalence of categories between $\mathrm{Vect}(X)$ the category of vector bundles over a compact, Hausdorff space $X$ and f.g. projective $C(X)$ modules. With the cross section functor.
	\end{theorem}
%	\begin{proof}
%		The functor we use is sending a vector bundle to its set of sections which takes on a natural module structure over $C(X)$. To show that it infact goes to f.g. proj modules 
%	\end{proof}
	
	\subsection{Grothendieck group $K_0$}
	The big picture idea that Grothendieck had was that of a free completion of a commutative monoid. Commutative monoids occurred in nature very often as f.g. projective modules/vector bundles. 
	
	This is a fairly natural approach which results in a Free-Forgetful adjoint pair between $\mathrm{CMon}$ and $\mathrm{Ab}$. 
		
	\begin{proposition}[$K_0$ of a monoid (Group completion functor)]
		Assign $(A,+) \in \mathrm{CMon} $ to \[K_0(A) \in \mathrm{Grp}\] by taking the free group on symbols $[a]$ for $a \in A$ and quotienting the monoidal relations $[m+n]-[m]-[n]$.
	\end{proposition}
	
	The mapping is an injection iff the monoid is cancellative.
	\begin{definition}[Reduced $K_0$ groups]
	There is a canonical homomorphism $i: \Z \to K_0(A)$ given by $z \mapsto z[m]$ the reduced $K$ group is defined as $\tilde{K}_0(A):=K_0(A)/\image i $
	\end{definition}
	
%	\begin{proposition}[Mayer-Vietoris for group completions]
%		content...
%	\end{proposition}
	
	\begin{definition}[$K_0$ for a ring $A$]
		Consider the isomorphism classes of f.g. projective modules over $A$. This forms a commutative monoid so consider its group completion $K_0(A)$
	\end{definition}
	\begin{definition}[$G_0$ for a ring $A$]
	The group completion of $M(A) $ the monoid of all f.g. modules over $A$ is denoted as $G_0(A)$
	\end{definition}
	There is a canonical inclusion map $K_0(A) \to G_0(A)$.

	\begin{proposition}[Eilenberg Swindle]
		$K_0$ for many abelian categories are trivial. If we consider $R^\infty$ as a inf.g. free module over a ring $R$ if $P \oplus Q \equiv R^n$ then \[ P \oplus R^\infty \cong P \oplus (Q \oplus P) \oplus (Q \oplus P) \oplus \dots \equiv (P \oplus Q) \oplus (P \oplus Q) \oplus \dots \equiv R^\infty \] but this relation would imply $[P]=0 $ for all projectives. 
	\end{proposition}
	This extends to higher K groups with an analogue that demonstrates the Quillen K space contracts, see V.1.9 in \cite{weibel2013k}.
	
%	\begin{definition}[Morita equivalence for rings and ]
%		content...
%	\end{definition}
%	
	\begin{proposition}\label{k0pidisZ}
	If $A$ is a Field/local ring/PID then $K_0(A)\cong\Z$
	\end{proposition}
	\begin{proof}
		For fields and division rings its just due to all f.g. modules being equal to some $A^n$. Similarly as seen in \ref{a2} and \ref{projfgpidfree} f.g. projective modules in a local ring/PID are free.
		
		So in each case $\mathrm{Proj}(A) \cong \N$ so its group completion is $\Z.$
		\end{proof}
		
	\begin{lemma} For commutative ring $A$, 
		$K_0(A) \cong \Z \implies $ projective modules over $A$ are stably free.
	\end{lemma}
	\begin{proof}
		For a commutative ring $A$, $K_0(A) \cong \Z \implies \mathrm{Spec}(A)$ is connected. For if not then there exists a non trivial idempotent in $A$ which results in a splitting of $A$ as a product which would contradict $\mathrm{Spec}(A)$ being connected.
		
		In light of Def. \ref{def:rankproj} we know that the rank of the projective modules must be constant due to the connectedness of $\mathrm{Spec}(A)$ and the fact that the only connected components in $\Z $ are singletons. 
		
		So the rank map $\phi:K_0(A) \to \Z $ defined as $P \mapsto \mathrm{Rank}(P)$ is well defined and trivially surjective. $A$ with rank $1$ maps to $1$, i.e. the generator of $\Z$. But by our assumption this is an isomorphism.				
		
		So any $[P]=n=[A]^n=[A^n]$ i.e. there exists $Q$ such that $Q\oplus P \cong Q \oplus A^n$ if $Q$ is projective add what's needed to make it projective.
	\end{proof}
	
	\begin{example}[Stably free module that is not free]
		Consider $S^2$ described as the ring $R=\mathbb{R}[x,y,z]/\langle x^2+y^2+z^2-1 \rangle $. Then the tangent space $T=\{ (a,b,c) \mid ax+by+cz=0  \}$ is stably free since $T \oplus R \equiv R^3 $ but $T \neq R^2$
	\end{example}
	\begin{proof}
		content...
	\end{proof}
	$K_0$ being the prototypical K group is easier to generalize. We will refer to Weibel for most of the definitions of $K_0$ leading upwards to its definition for a Waldhausen category \cite{weibel2013k}. The benefit of this approach will mainly be for building up an understanding for Higher K theory. Also this machinery allows for easier computations.
	
	\begin{definition}[$K_0$ for an exact category $\mathcal{E}$]
		$K(\mathcal E)$ is generated by $[A]$ for each $A \in \mathrm{Ob}(\mathcal{E})$ and a relation of $[A]=[A']+[A'']$ for all short exact sequences \[ 0 \to A' \to A \to A'' \to 0 \]
		Naturally since every abelian category is exact this applies for abelian categories in particular.
	\end{definition}
	\begin{theorem}[Devissage for $K_0$ in abelian categories]
		Let $\mathcal B \subset \mathcal A$ be abelian categories which are small (i.e. proper set of objects) then $K_0(\mathcal A) \cong K_0(\mathcal B)$ and the inclusion functor $i:\mathcal{B} \to \mathcal{A}$ is exact if the following conditions are met
		\begin{enumerate}
			\item $\mathcal B$ is a abelian exact subcategory of $B$ closed under subobjects and quotients from $\mathcal{A}$.
			\item Objects in $\mathcal{A}$ have finite filtrations \[ A_n=0 \subset A_{n-1} \subset \cdots \subset A_0 =A \] with each of the quotients $A_i/A_{i+1} \in \mathcal{B}$
		\end{enumerate}
	\end{theorem}
	\begin{proof}
		Since $i:\mathcal{B} \subseteq \mathcal{A} $ we denote by $ \tilde{i} : K_0(\mathcal{B}) \to K_0(\mathcal{A})$ the natural induced homomorphism. This is naturally injective so we need to prove surjectivity and additivity.
		
		Based on the hypothesis we can always find a finite filtration on $A \in \mathcal{A}$ of the form $\{A_i\}_{i=0}^n$ with the quotients in $\mathcal{B}$. We can then represent its consequent preimage in $K_0(\mathcal{B})$ as $[A] = \sum_i [A_i / A_{i+1}]$ in $ K_0(\mathcal{A} )$, i.e. $\phi^{-1}([A])=\sum_i A_i/A_{i+1}$.
			
		Note that such a preimage is also independent of the filtration due to the Schrier-Refinement theorem for abelian categories which states that we can always find a common refinement of filtrations. The proof is identical to the standard group theoretic proof.
			
		To verify this claim look at a single refinement, say changing $A_i \supset A_{i+1}$ to $A_i \supset A' \supset A_{i+1}$. 
		\[
		0 \to A' / A_{i+1} \to A_i / A_{i+1} \to A_i / A' \to 0,
		\]
		
		we see that $[A_i / A_{i+1}] = [A_i / A'] + [A' / A_{i+1}]$ in $K_0(\mathcal{B})$, as claimed. This is essentially 
		
		For additivity and exactness, note that given a short exact sequence $0 \to A \to B \to C \to 0$, we can construct a filtration $\{B_i\}$ for $B$ by combining the filtration for $A$ along with pullback of a filtration of $C$ in $B$. For this filtration we have $\sum [A_i / A_{i+1}] = f(A') + f(A'')$. Therefore $f$ is an additive function and defines a map $K_0(\mathcal{A}) \to K_0(\mathcal{B})$. By inspection, $f$ is the inverse of the canonical map $i_*$.
	\end{proof}
	\begin{corollary}
		For a nilpotent ideal $N$ in a noetherian ring $A$ we have $G_0(A/N) \cong G_0(A	)$
	\end{corollary}
	\begin{proof}
		Every f.g. module has a natural filtration which goes to zero by multiplying it with copies of $N$.
	\end{proof}	
	Nil ideals (ideals consisting of all nilpotent elements) are in general not nilpotent ideal. However, due to a theorem by Levitzky (see \cite[Th. 10.30]{lam2001first}) which states that nil ideals of right noetherian rings are indeed nilpotent we can say that this holds for nil ideals as well.
	
	Recall the definitions of Serre quotient.
	\begin{theorem}[Localization theorem for $K_0$]
		 For a small abelian category $\mathcal{A}$ and $\mathcal{B} \subset \mathcal{A}$ a Serre subcategory. The following sequence is exact
		 \[ K_0(\mathcal{B}) \xrightarrow{f} K_0(\mathcal{A}) \xrightarrow{L} K_0(\mathcal{A/B}) \to 0 \]
	\end{theorem}
	\begin{proof}
		By construction we know that $L$ is surjective.
		Note we already know that $\mathrm{coker} f \to  K_0(\mathcal{A/B})$ is surjective due to the fact that $K_0(B) $ under composition through $T$ goes to zero.
		
		Consider the function $g:\mathcal{A/B} \to \mathrm{coker}f$ as $g(L(A)):=[A]$ as a natural candidate. If this is additive from we have found the required inverse.
		
		We already know that $T $ is bijective as a set function on objects of $\mathcal{A}$ by construction. Consider two isomorphic elements in the Serre quotient and claim their images under $g$ in $\mathrm{coker} f $ are also isomorphic. Consider $L(A) \cong L(B)$ by the definition of the morphisms this means we have a diagram representative as such.
		\[ A \xleftarrow{n} X \xrightarrow{m} B \] with $\ker(n), \ker{m}, \mathrm{coker} (n) , \mathrm{coker}(m)$ in $\mathcal{B}$ (since its an isomorphism).
		
			As such in $K_0(\mathcal{A})$ we have, $$[X]=[A]+[\ker n]-[\mathrm{coker}(n)]=[B]+[\ker m]- [\mathrm{coker}(n)]$$ so in $\mathrm coker f$ we have $[X] = [A]=[B]$.
			
		We have shown $L(A) \cong L(B) \implies [A]=[B]$ in $\mathrm{coker} f$. Now to show additivity.
		
		To see that \( g \) is an additive function, suppose we are given an exact sequence in \( \mathcal{A/B} \) of the form
		\[
		0 \rightarrow L(A) \xrightarrow{u	} L(B) \xrightarrow{v} L(C) \rightarrow 0;
		\]
		we have to show that \( [B] = [A] + [C] \) in \( F \). Represent \( v \) by a diagram representative \( B \xleftarrow{o} Y \xrightarrow{p}	 C \) with \( o \) with $\ker o , \coker o \in \mathcal{B}$
		
		Now since canonically
		\[
		[Y] = [A] + [\ker(o)] - [\coker(o)] \text{ in } K_0(A),
		\]
		we have \( [Y] = [A] \) in \( \coker f \). Since \( L \) is exact and we know the below sequence is canonically exact
		\[
		0 \rightarrow \ker(p) \rightarrow Y \xrightarrow{p} B \rightarrow \coker(p) \rightarrow 0	\]
	
		Applying $L $ to above gives us that \( \coker(p) \) is in \( \mathcal B \) and that \( L(\ker(p)) \cong L(A) \) in \( \mathcal{A/B} \). Hence, \( [\ker(p)] = [A] \) in \( \coker f \), and in \( \coker f \) we have
		\[
		[B] = [Y] = [C] + [\ker(p)] - [\coker(p)] = [A] + [C],
		\]
	\end{proof}
	\begin{example}
		Consider the following non-example for why the above sequence need not be left exact.
%		 Consider $A=k[t]$ for a field $k$. Consider the subcategory of modules annhilated by a power of $x$. Then all the terms are isomorphic to $\mathbb{Z}$.
	\end{example}
	\begin{corollary}\label{localizationk0corrolary}
		
	\end{corollary}
	\begin{theorem}[Fundamental theorem for $G_0$]
		$G_0[A] \cong G_0(A[t]) \cong G_0(A[t,t^{-1}])$
	\end{theorem}

	\begin{proof}
		This is a theorem due to Grothendieck.
		The evaluation morphism $e: A[t] \to A$ provides an inclusion $M(A) \subset M(A[t])$ and consequently a map $\tilde{e}: G_0(A) \to G_0(A[t])$ by Cor. \ref{localizationk0corrolary}. We obtain a exact sequence \[ G_0(A) \xrightarrow{\tilde{e}} \to G_0(R[t]) \to G_0(R[t,t^{-1}]) \to 0 \]
	\end{proof}
	
	
	\begin{definition}[Regular ring] A ring is called regular if
	\end{definition}
	\begin{example}
		content...
	\end{example}
	\begin{theorem}\label{extensionk0iscong}[Fundamental theorem for $K_0$]
		For a regular ring $A$ the map $A \to A[x]$ induces an isomorphism $K_0(A) \cong K_0(A[x])$ 
	\end{theorem}
	\begin{proof}
	
	\end{proof}
	
	These results can be naturally extended to schemes. Recall the definition of a scheme as such.
	\begin{definition}[Scheme]
		content
	\end{definition}
	\begin{definition}[$G_0, K_0$ for noetherian scheme $X$]
		The category of coherent $\mathcal{O}_X$ modules form an abelian category. So its monoid completion is $G_0(X)$
	\end{definition}
	\begin{theorem}
		content
	\end{theorem}
%	
%	\begin{definition}[$K_0$ for Waldhausen categories]
%		
%	\end{definition}
	
	
	
	\subsection{Quillen-Suslin Theorem}
	We will know move towards Horrock's theorem which will enable a short proof of the famous Quillen-Suslin theorem. We follow Lang's book for the first few results which recounts Vaserstein's proof of Quillen-Suslin \cite{lang02}.
	
	\begin{definition}
	An $A$ module $M$ is stably free if there exists a f.g. free module $F$ such that $M \oplus F$ is free.
	\end{definition}
	\begin{lemma}
	A proj. module is stably free iff if has a finite free resolution.
	\end{lemma}
	\begin{theorem}[Hilbert-Serre]
	Every f.g. module over $k[x_1,\dots x_n]$ is stably free where $k$ is a PID.
	\end{theorem}
	\begin{proof}
		Apply Th \ref{k0pidisZ} and Th \ref{extensionk0iscong}
	\end{proof}
	
	
	\begin{definition}[Unimodular row]
		For a ring $A$, an element of $A^n$ is said to be a unimodular row if its components generate	$A$. We denote the set of all unimodular rows as $U_n(A)$
	\end{definition}
	\begin{definition}[Unimodular matrix]
		In general we say an arbitrary matrix over $A$ not nessecarily square is unimodular if it is right invertible.
	\end{definition}
	Alternatively it can be useful to view a unimodular row as as element of $M_{1 \times n} (A) $ as such it represents a surjective linear map $A^n \to A$, or even an element in $M_{n \times 1}$ in which case it represents a injection from $A \to A^n$.
	
	\begin{definition}[Equivalence of unimodular rows]
		For unimodular rows $v,w\in A^n$ we say $v \sim w $ if $\exists M \in GL_n(A)$ such that $Mv=w$.
	\end{definition}
	
	\begin{definition}[Unimodular extension property]
		Given a unimodular row $v=(v_1,\dots v_n) \in A^n$ if we can construct a invertible $n \times n $  matrix with $v$ in the first column we say $v$ has the unimodular extension property.
	\end{definition}
	

	
	We don't use the above terminology in the light of the following fact.
	
	\begin{lemma}
		A unimodular row $v \in A^n$ has the unimodular extension property iff $v \sim (1,0,\dots ,0)$
	\end{lemma}
	\begin{proof}
		If $v$ can be extended to a invertible matrix $M \in GL_n(A)$ then \[ M{^-1} = (1,0,\dots, 0) \].
		Conversely if $M' \in GL_n(A) $ s.t. $M'v=(1,0,\dots,0)$ then $M'{^-1}$ has $v$ in the first column.
	\end{proof}
		\begin{corollary}\label{row-of-inv-mat-unimod}
		Based on the above lemma we can see that trivially any row of a invertible matrix (and column realized as a row of its transpose) is a unimodular row. 
	\end{corollary}
	
	\begin{proposition}\label{inductionbaseforprequillensuslin}
		Over a PID $A$ any two unimodular rows in $A^n$ are equivalent.
	\end{proposition}
	\begin{proof}
		We will instead show that any unimodular row is equivalent to $(1,0,\dots, 0)$. Since its a PID one element must generate $A$ move this to the first coordinate by elementary row operations then make it equivalent to $1$ by another row operation.
	\end{proof}
	\begin{proposition}
		Over a local ring $A$ any two unimodular rows are equivalent
	\end{proposition}
	\begin{proof}
		Use the fact that projective modules over local rings are free.
	\end{proof}
	\begin{theorem}[Horrocks' theorem]
	If $(A, \mathfrak{m})$ is a local ring then for any arbitrary unimodular row $v(x)$ in $A[x]^n$ such that one of its component elements has leading coefficient 1 implies that $v$ has the unimodular extension property. Furthermore, any such $v$ is equivalent to $v(0)$.
	\end{theorem}
	\begin{proof}
	Recall that for a local ring $x \not \in \mathfrak m \iff x  $ is a unit.
	
	When $n=1,2 $ there is nothing to prove. Assume $n \geq 3$.
	
	
	Without loss of generality, we take $v_1(x)$ with degree $d $ among components with leading coefficient $1$ and $\deg v_i < d, $ for $i \neq 1$. We shall induct on $d$.
	
	By unimodularity we know there exists $w(x)\in A[x]^n$ such that,
	\[ \sum_{i=1}^n w_i v_i = 1 \]
	So we can say that not all of the coefficients of $v_2, \dots v_n $ can lie in $\mathfrak m$. For if it were the case, then reduced mod $\mathfrak m$ we arrive at a contradiction since we assumed $v_1 $ has leading coefficient 1 and $w_1v_1$ wouldn't have a constant residue.
	
	Once again without loss of generality, assume some coefficient of $v_2(x)$ does not lie in $\mathfrak m$, and as such is a unit.
	
	Now consider the ideal $I$ generated by the leading coefficients of $w_1v_1+w_2v_2$ of degree $< d.$ 
	
	$I$ contains the coefficients of $v_2$ this can be inductively found when $w_1=0, w_2=1$ we get the coefficient of the $x^m$ term where $\deg v_2 = m$.
	Using repeatedly different choices of polynomials we are done.
	
	Since $I$ has a unit which means it generates $A$. And consequently implies that there was some choice of polynomial $y_1v_1+y_2v_2$ of degree $<d$ with leading coefficient $1$.
	
	The the appropriate row actions we can obtain this in some component of $v$. Repeating this process until we get $d=0$ finishes the proof.
	
	Now because of $\sum_{i=1}^n w_i v_i =1 $ there must be some constant term not in $\mathrm m $ and unital as such. So $v(0) \sim (1,0,\dots ,0 ) \sim v$ as seen above.
	\end{proof}
	
	We now extend the idea of Horrock's theorem.
	
	\begin{lemma}\label{horrocksbutforlocal}
		For an integral domain $A$ and a multiplicative subset $S$ if $v(x) \sim v(0)$ over $A_S[x]^n $ then there exists $c \in S$ such that $v(x+cy) \sim v(x) $ over $A[x,y]^n$
	\end{lemma}
	\begin{proof}
		By the equivalence $v(x) \sim v(0)$ we know there exists a matrix $M \in GL_n(R_S[x])$ such that $M(x)v(x)=v(0) $ now consider \[ N(x,y) = M(x)^{-1} M(x+y) \]
		
		Note that now $N(x,y)v(x+y)=v(x)$ and so also $y \mapsto cy$ implies that $N(x,cy)v(x+cy)=v(x).$
		
		Now to show that indeed $N(x,cy)\in R[x,y]$ for some choice of $c \in S$ but this is true since $N(x,0)=I_N \implies N(x,y)=I+yP $ for some $P \in R_S[x,y]$ but this just means there is some appropriate choice of $c \in S$ that allow us to cancel out all the denominators in $P$ so that $P[x,cy] \in R[x,y]$.
	\end{proof}
	
	\begin{lemma}\label{horrocksbuteverything}
		For an ID $A$ and $v(x)$ unimodular row in $A[x]^n$ with at least one component having leading coefficient one implies $v(x) \sim v(0)$.
	\end{lemma}
	\begin{proof}
		Consider the set $I$ containing all $c \in A$ such that $v(x+cy)\sim v(x)$ as rows in $A[x,y]$ if the ideal contains $1$ then sending $x \to 0$ would give us $v(y)\sim v(0) $ in $A[y].$
		
		We can achieve this by first showing $I$ is an ideal and then showing that its not contained in any maximal ideal.	To do this last step we will localize at the maximals and use the previous result.
		
		First prove that $I$ is an ideal.
		\begin{enumerate}
			\item $I \neq \emptyset $ as $0 \in I$
			\item If $c,d \in I$ then $c-d \in I$ as $v(x+(c-d)y)=v(x+cy-dy) \sim v(x+cy) \sim v(x)$ by a substitution $x \mapsto x+cy$
			\item For $a \in A, c \in I$ then simply $v(x+cay) \sim v(x)$ by the $y \mapsto ay$
		\end{enumerate}
		
		Now to show $I$ isn't contained in any maximal ideal. Pick a maximal ideal $\mathfrak m$ and localize at it first due to Horrocks we know $v(x) \sim v(0) $ in $A_{\mathfrak m} [x]$ and then due to the previous lemma \ref{horrocksbutforlocal} we find some $c \in A\setminus \mathfrak m$ such that $v(x+cy) \sim v(x) \sim v(0)$ but this just means that $ c \in I$ and so $I\not \subset \mathfrak m$ this applies to any maximal and so we are done.  
	\end{proof}
	
	\begin{theorem}
		For $A=k[x_1, \dots, x_n]$ where $k $ is a PID, then $v \sim (1,0,\dots, 0)$ for any unimodular row $v \in A^n$.
	\end{theorem}
	\begin{proof}
		Proceed with induction on $n$. We proved $n=0$ above Prop. \ref{inductionbaseforprequillensuslin}.
		
		Assume $n\geq 1$ and that the result holds for $m-1$.
		
		Then $v \in k[x_1, \dots, x_m] \cong k[x_1,\dots, x_{m-1}] [x_m]$ can be realized as $v(x_m) $ with coefficients in $k[x_1,\dots, x_{m-1}]$. If $v(x_m)$ has some component with leading coefficient $1$ then by Lemma \ref{horrocksbuteverything} we now $v(x_m) \sim v(0) \in k[x_1, \dots, x_{m-1}]$ and we can reduce by induction.
		
		So if not by some appropriate change of variables as amongst $x_1, \dots, x_{m-1}$ in the form of $x_i \mapsto x_i-x_m^{p_i}$ for very large $p_i$'s this allows us obtain the leading coefficient in terms of $x_m$ to be 1 as needed.
	\end{proof}

	
	
	\begin{theorem}[Quillen-Suslin]
		Finitely generated projective modules over $A=k[x_1,\dots,x_n]$ where $k$ is a PID are free.
	\end{theorem}
	\begin{proof}
		We know such f.g. proj. modules are stably free. And from above we know any unimodular row in $A$ is equivalent to $(1,0,\dots,0)$.
		
		That is to say given a f.g. proj. module $P$ which is stably free, i.e. $P \oplus R^{m_1} \cong R^{m_2}$ then $P$ is free.
		
		When $m_1=1$ this is the split exact sequence (since P is projective see \ref{projtfae}),
		\[ 0 \to A \hookrightarrow A^{m_2}  \twoheadrightarrow P \to 0 \]
		The injection $A \to A^{m_2}$ is precisely a unimodular row by definition which we know must correspond to the canonical embedding of $1 \mapsto (1,0,\cdots, 0)$.
		So,$$P = \mathrm{im}(A^{m_2} \to P) \cong A^{m_2}/\ker (A^{m_2} \to P) \cong A^{m_2}/\mathrm{im}(A \to A^{m_2}).$$
		But $A^{m_2}/\mathrm{im}(A \to A^{m_2})$ is free since $\mathrm{im}(A \to A^{m_2})$ is naturally free due to the embedding.
		
		When $m_1 \neq 1$ just take $(P \oplus A^{m_1-1}) \oplus A$.
	\end{proof}
	\subsection{Mennicke symbols(Relevance? Maybe move to results in lingrps)}
	\begin{definition}[Mennicke symbol]
		A Mennicke symbol is a map $\phi : \mathrm{Un}_{n}(A) \to G $ where $G$ is a group such that,
		\begin{enumerate}
			\item $\phi(1,0,\dots, 0)=1, \phi(v)=\phi(v M)$ for $M \in E_n(A)$
			\item $\phi(a,a_2,\dots,a_n)\cdot \phi(b,a_2, \dots a_n)=\phi(ab,a_2,\dots, a_n)$ if $(a,a_2,\dots,a_n), (b,a_2,\dots,b_n) \in \mathrm{Um}_n(A)$.
		\end{enumerate}
	\end{definition}

	
	\subsection{Whitehead group $K_1$}
	\begin{definition}[Whitehead group for a ring] $K_1$ for a ring $A$ is defined as the abelianization of its infinite general linear group.
		$$K_1:= \frac{GL(A)}{[GL(A):GL(A)]}$$
		Where $GL(A)$ the infinite general linear group is the colimit of $GL_n(A)$ with $GL_{n}$ realized as a subgroup of $GL_{n+1}$ by placing the matrix in the top left corner. 
	\end{definition}
	\begin{proposition}
		\[ [GL(A):GL(A)]=E[A] \]
	\end{proposition}
	\begin{proof}
		Using Lemma \ref{whiteheadmain} we can see that \[ \begin{bmatrix}
			a^{-1}b^{-1} & 0 \\ 0 & I_n
		\end{bmatrix} \equiv \begin{bmatrix}
			b^{-1} a^{-1 } & 0 \\
			0 & 1_n
		\end{bmatrix} \mod E_{2n}(A)\]
		So the derived subgroup of $GL_n(A)$ is contained in $E_{2n}(A)$. 
	\end{proof}	
	
	
	\begin{definition}[Relative $K_1$]
		$SK_1(A):= \ker \det$
		
		Where, $\det : K_1(A) \to A^\times$. We have a split exact sequence
		\[ 0 \to SK_1(A) \to K_1(A) \to A^\times \to 0 \]
	\end{definition}
	
	
	\subsection{Some results on linear groups}
	\begin{definition}[Elementary matrices]
		We denote the elementary matrices as $E_n(A)$ generated by standard elementary matrices of the form $I_{n}+ \lambda E_{ij} $ where $E_{ij}$ is the matrix with $1$ in the $(i,j)$ entry and zero elsewhere. In shorthand notation we will write it as $e_{ij}(\lambda)$. 
	\end{definition}
	
	\begin{lemma}\label{diag1andprodelementary}
		A nonsingular triangular matrix with $1$'s in the diagonal is a product of standard elementary matrices.
	\end{lemma}
	\begin{proof}
		Let $A \in GL_n(A)$ then consider the following inductive procedure.
		\begin{align*}
			A&= \begin{bmatrix}
				1 & a_{12} &\cdots &a_{1n}\\
				0& 1 & \cdots &a_{2n}\\
				\vdots & \vdots  & \ddots  & \vdots \\
				0 & 0 & \dots & 1
			\end{bmatrix}
			= \begin{bmatrix}
				1 & a_{12} &\cdots &a_{1n}\\
				0&  &   &\\
				\vdots &  & A_{n-1}  &  \\
				0 &  & & 
			\end{bmatrix}\\
			&=\begin{bmatrix}
				1 & 0 &\cdots &0\\
				0&  &   &\\
				\vdots &  & A_{n-1}  &  \\
				0 &  & & 
			\end{bmatrix} e_{12}(a_{12}) e_{13}(a_{13}) \cdots e_{1n}(a_{1n})\\
			\intertext{Repeat the procedure for $A_{n-1}$ to obtain}
			&= \begin{bmatrix}
				1 & 0 & 0 & \cdots & 0 \\
				0 & 1 & 0 & \cdots & 0\\
				0 & 0 &   &  &\\
				\vdots & 0 &   &A_{n-2}  &\\
				0 & 0 &   &  &
			\end{bmatrix}\prod_{j=2}^n e_{2j}(a_{2j}) \prod_{i=1}^n e_{1i} (a_{1i})
		\end{align*}
	\end{proof}

	\begin{proposition}\label{whiteheadsimple}
		Let $A$ be a ring and $u \in A^\times$
		\[ {\displaystyle {\begin{bmatrix}u&0\\0&u^{-1}\end{bmatrix}}} \equiv I_2 \mod E_2(A)\]
	\end{proposition}
	\begin{proof}
		${\displaystyle {\begin{bmatrix}u&0\\0&u^{-1}\end{bmatrix}}=e_{21}(u^{-1})e_{12}(1-u)e_{21}(-1)e_{12}(1-u^{-1}).}$
	\end{proof}
\begin{lemma}[Whitehead]\label{whiteheadmain}
	For $a,b \in GL_n(A)$ \[ \begin{bmatrix}
		ab & 0 \\ 0 & I_n
	\end{bmatrix} \equiv \begin{bmatrix} a & 0 \\ 0 & b
	\end{bmatrix} \equiv \begin{bmatrix}
		ba & 0 \\ 0 & I_n 
	\end{bmatrix} \mod E_{2n} (A)\]
\end{lemma}
\begin{proof}
	Let $A=M_n(A)$ and note $E_2(M_n(A) ) \subset E_{2n}(A)$ in Prop. \ref{whiteheadsimple}.
\end{proof}
	
	
	\begin{lemma}
		For E.D. $A$ we have $SL_n(A)=EL_n(A)$ for all $n.$
	\end{lemma}
	\begin{proof}
		With elementary row and column operations arrange the matrix so that the element with the smallest norm is in the top right position. And using elementary row operations reduce it to a matrix with a unit in the top left and 0s in the rest of the first column and first row. Proceeding similarly for the remaining $n-1 \times n-1 $ matrix left we reduce it down to a matrix of the form.
		
		\[ \begin{bmatrix}
			u_1 & 0 & \dots & 0 \\
			0 & u_2 & \dots & 0 \\
			\vdots & 0 & \ddots & 0\\
			0 & 0 & \dots & u_n 
		\end{bmatrix} \]
		
		Now apply Whiteheads lemma 
	\end{proof}
%	\subsubsection{Suslin's Normality theorem}
	We now consider a result due to Suslin about the normality of $E_n(A) $ in $GL_n(A)$. The following Lemma due to Vaserstein will be useful.
	\begin{lemma}[Vaserstein]
		Let $a \in M_{m,n} (A)$ and $b \in M_{n,m}(A)$ then if $I_m+ab \in GL_m(A)	\implies $ $I_n+ba \in GL_n(A)$ and \[ \begin{bmatrix}
			I_m+ab & 0 \\ 0 & (I_n+ba)^{-1}
		\end{bmatrix} \in E_{m+n} (A)\] 
	\end{lemma}
	\begin{proof}
		Note that $(I_n+ba)^{-1}=I_n-b(I_m+ab)^{-1}a$. Lem. \ref{whiteheadsimple} cannot be applied in this case since $n\neq m$ in general. But the idea is nearly the same. 
		\( \begin{bmatrix}
			I_m+ab & 0 \\ 0 & (I_n+ba)^{-1}
		\end{bmatrix} 
		\)
		
		
		\(=\begin{bmatrix}
		I_m & 0 \\
		(I_n+ba)^-1b I_n
		\end{bmatrix}\begin{bmatrix}
		I_m & -a\\
		0 & I_n
		\end{bmatrix} \begin{bmatrix}
		I_m & 0\\
		-b & I_n
		\end{bmatrix} \begin{bmatrix}
		I_m & (I_n+ab)^{-1}a\\
		0 & I_n
		\end{bmatrix}\in E_{m+n} (A)\) 
		We implicitly use Prop. \ref{diag1andprodelementary} to justify that the triangular matrices there are indeed elementary.
	\end{proof}
	
	\begin{theorem}[Suslin's Normality theorem]
		For $A$ a commutative ring with unity, $E_n(A)$ normal in $GL_n(A)$ for $n \geq 3$. 
	\end{theorem}
	\begin{proof}
		Let $a \in GL_n(A)$ consider $e_{ij}(\lambda) \in E_n(A)$ arbitrary. Recall from \ref{row-of-inv-mat-unimod} that the columns of $a$ and the rows of $a^{-1}$ are unimodular.
		\[ ae_{ij} (\lambda ) a^{-1}= I_n +\lambda c_i r_j\]
		Where $c_i$ is the $i^\mathrm{th}$ column of $a$ and $r_j$ is the $j^{\mathrm{th}}$ row of $a^{-1}$.
		
		Furthermore since $a^{-1}a=I_n \implies b_ja_i=\delta_{ij} \implies $ using Prop. that $ae_{ij}(\lambda) a^{-1} = I_n + \lambda c_i r_j \in E_n(A)$ and since $E_n(A)$ is generated by matrices of the form $e_{ij}(\lambda )$ we are done.
	\end{proof}
	
	\begin{proposition}[Cohn] If $n=2$ $E_2(A)$ need not be normal in $SL_2(A)$
		content
	\end{proposition}
	
	\begin{theorem}[Suslin]
		Given $(x_1,\dots,x_n) \in U_n(A)$ then $(x_1^{m_1}, \dots, x_n^{m_n}) \in U_n(A)$ iff $(n-1)! | m_1\dot m_2 \cdots m_n$
	\end{theorem}
	
	\subsection{Relationship between $K_0$ and $K_1$}
	\begin{theorem}[Mayer-Vietoris]
	\end{theorem}
	\begin{theorem}
		Let $A$ be a ring and $S$ denote a multiplicatively closed set of central elements in $A$. We obtain the following exact sequence
		\[ K_1(A)  \to K_1(S^{-1}A ) \to K_0(A \text{ on } S) \to K_0(A) \to K_0(S^{-1} A)\]
	\end{theorem}
	
%	\section{Higher K theory}
%	\subsection{Quillen + Construction}
%	\subsection{Quillen Q construction}
%	\subsection{$+=Q$}
%	\subsection{Waldhausen construction}
%	
	
	\begin{appendices}
	\section{Homological algebra}
	We define and prove the essential results that we require. For further details refer to \cite{eisenbud2013commutative, weibel_1994}
	\subsection{Chain complexes}
	A \textbf{chain complex} $(F_\bullet, \varphi_\bullet)$ is a collection of modules over a commutative ring and homomorphisms $\varphi_i: F_i \to F_{i-1}$ such that $\varphi_i \varphi_{i+1}=0$,
	\[\begin{tikzcd}
		\cdots & {F_{i+1}} & {F_i} & {F_{i-1}} & \cdots
		\arrow["{\varphi_{i+1}}", from=1-2, to=1-3]
		\arrow["{\varphi_i}", from=1-3, to=1-4]
		\arrow["{\varphi_{i-1}}", from=1-4, to=1-5]
		\arrow["{\varphi_{i+2}}", from=1-1, to=1-2]
	\end{tikzcd}\]
	The \textbf{homology} of the complex at $F_i$ is denoted as its $i^{\mathrm{th}}$ homology defined as follows,
	\[ H_iF := \ker \varphi_i/ \mathrm{im} \varphi_{i+1} \]
	Reversing the arrows gives us the analogous definitions for cochain complexes and cohomology.
	
	The homomorphisms are often called \textbf{`boundary operators'} or \textbf{`differentials'}. This nomenclature is motivated by the de Rahm cohomology. Furthermore elements of $\ker \varphi_i$ are called `\textbf{cycles}' and elements of $\mathrm{im} \varphi_{i+1}$ are called \textbf{boundaries}, this echoes the aphorism `cycles modulo boundaries' often encountered in singular homology.
	
	A chain complex is said to be \textbf{exact} if all its homologies are zero. In particular it is exact at one object if its homology there is zero.
	
	Note that these definitions can be easily viewed in terms of objects of Abelian categories.
	
	\subsection{Projective modules}
	Recall a\textbf{ free module } of rank $n$ is one that is isomorphic to $n$ direct sums of its underlying ring. In particular this means that there exists a linearly independent spanning set of the module with $n$ elements.
	
	And homomorphisms from free modules to other modules are determined by the image of their generators, i.e. free objects are left adjoints to forgetful functors. \footnote{This holds in free monoids $\mathrm{Hom}_\mathbf{Mon}(F(X), M) \cong \mathrm{Hom}_\mathbf{Sets} (X, U(M))$ where $F(X)$ denotes the free monoid generated by elements from the set $X$ and $U(M)$ is the underlying set of a monoid $M$, refer to \cite[p. ~208]{Awodey} }
	
	A module $P$ is said to be \textbf{projective} if it satisfies the following lifting property, every morphism from $P$ to $N$ factors through an epi into $N$. Note that the lift need not be unique this is \textit{not} an UMP
	\[\begin{tikzcd}
		&& M \\
		\\
		P && N
		\arrow[two heads, from=1-3, to=3-3]
		\arrow[from=3-1, to=3-3]
		\arrow[dashed, from=3-1, to=1-3]
	\end{tikzcd}\]
	

	\begin{lemma}[Free modules are projective]
	\end{lemma}
	\begin{proof}
		Consider the preimages of images of basis of $P$ in $N$, that lie in $M$. Then map basis elements from $P$ into these preimages.
	\end{proof}
	\begin{proposition}[Equivalent definitions of projectivity]\label{projtfae}
		TFAE,
		\begin{enumerate}
			\item $P$ is projective.
			\item For all epi's between $M\twoheadrightarrow N$, the induced map $\Hom(P,g):\mathrm{Hom}(P,M) \to \mathrm{Hom}(P,N)$ sending $f \mapsto g \circ f$ for $g:M \to N$ and $f:P \to M$ is an epi.
			\item For some epi from a free module $F$ to $P$, $\mathrm{Hom}(P,F) \to \mathrm{Hom}(P,P)$ is an epi.
			\item There exists $Q$ s.t. $P \oplus Q$ is free
			\item Short exact sequences of the form $0 \to A \to B \to P \to 0$ split, i.e. isomorphic to another short exact where middle term is $A \oplus P$ \footnote{In general any epis into projective objects split (i.e. have an inverse).}
		\end{enumerate}
	\end{proposition}
	\begin{proof}
		$1 \iff 2$ is restatement of definitions.
		
		$2 \implies 3$ is also just substitution.
		
		$3 \implies 4$ consider a map in the preimage of identity in $\Hom(P,P)$ which is a splitting (inverse) of the epi $F$ into $P$,
		\[\begin{tikzcd}
			& P \\
			\\
			F && P
			\arrow["g", shift left=3, two heads, from=3-1, to=3-3]
			\arrow[""{name=0, anchor=center, inner sep=0}, "f"', from=1-2, to=3-1]
			\arrow[""{name=1, anchor=center, inner sep=0}, "{\mathrm{Id}_P=g \circ f}", dashed, two heads, from=1-2, to=3-3]
			\arrow[shorten <=6pt, shorten >=6pt, Rightarrow, from=0, to=1]
		\end{tikzcd}\]
		Now we have a short exact sequence $0 \to \ker g \to F \to P \to 0$, and also $f\circ g $ is idempotent so it naturally admits a decomposition $F = \image(f \circ g) \oplus \kernel (f \circ g)$\footnote{For some idempotent $e$, $1-e$ is also an idempotent and images under these two mappings decompose any module, furthermore image of $1-e$ is just kernel of $e$}=$\image (g) \oplus \kernel (g)$ the first by the 1st isomorphism theorem and the second by $f $ being a mono.
		
		$4 \implies 2$ simply as $\hom (P \oplus Q,-) = \hom(P,-) \oplus \hom(Q,-)$
		
		$1 \iff 5$ To show that $0\to A \to B \xrightarrow{\varphi} P$ splits we need to show that there exists a $\psi: P \to B$ such that $\varphi \circ \psi = 1_P$. But this is just obtained by the definition of $P$ being projective.
		\[\begin{tikzcd}
			&& M \\
			\\
			P && P
			\arrow["\varphi", from=1-3, to=3-3]
			\arrow["\psi", dashed, from=3-1, to=1-3]
			\arrow["{=}", from=3-1, to=3-3]
		\end{tikzcd}\]
		
	\end{proof}
	
	\begin{theorem}\label{a2}Proj. fin. generated modules over local rings are free
	\end{theorem}
	\begin{proof}
		Pick a minimal set of generators and see its residue classes in $M/\mathfrak{m}M$ as the basis of it as a vector space over $R/\mathfrak{m}$.
		
		Now as for some free module $F, F=\varphi(M)\oplus K$ for some $K$ and some homomorphism $\varphi: M \to F$, (by defn of projective module), 	we get \[ M/\mathfrak{m}M \cong 	F/\mathfrak{m}F = (R/\mathfrak{m})^n\cong R^n\otimes R/\mathfrak{m} \cong F \otimes R/\mathfrak{m} \cong (\varphi(M)\oplus K) \otimes R/\mathfrak{m}\]
		
		Finally we get $M/\mathfrak{m}M \cong M/\mathfrak{m}M \oplus K/\mathfrak{m}K\implies K=\mathfrak{m}K \implies K=0$ by Nakayama
	\end{proof}
	This holds for not necessarily f.g. modules too refer to \cite[Th.~2.5]{matsumura_1987}	.
	
		Using the convention of \cite{lam1999lectures} we define the rank of a projective module as such.
	\begin{definition}[Rank of a f.g. projective module]\label{def:rankproj}
		For any f.g. projective module $P$ over commutative ring $A$ the localization $P_\mathfrak{p} =P \otimes_A A_\mathfrak{p}$ is also a f.g. $A_\mathfrak{p}$ module. But $P_\mathfrak{p}$ being local is free by Th. \ref{a2}. So the local rank of $P$ is defined as the rank of the free $P_\mathfrak{p} $ module.
		
		This induces a map $\phi: \mathrm{Spec}(A) \to \Z $ sending each $\mathfrak{p}$ to the local rank of $P$. If $\phi $ is constant and the rank of $P$ is the same for all localizations then we refer to that as the rank of $P$.
	\end{definition}
	
%	\begin{proposition} If $M$ is a finitely presented module over a Noetherian ring $R$ (prime ideals fin gen) then TFAE
%		
%		
%		\begin{enumerate}
%			\item $M$ is projective.
%			\item $M$ localized at maximal ideals is free.
%			\item A finite set of elements $\{x_i\}^n$ in $R$ generate $R$ such that $M[x_i^{-1}]$ is free over $R[x_i^{-1}]$.
%		\end{enumerate}		
%	\end{proposition}
%	This proceeds just from the previous result.
%	\begin{lemma}\label{suboffgisfgnoet}
%		$A$ is Noetherian iff all submodules of f.g. $A$ modules are f.g..
%	\end{lemma}
	\begin{proposition}\label{submodoffreemodisfreepid}
		For a PID $A$ a submodule $M$ of a free module of finite rank say $A^n $ is free, and the submodule has rank $\leq n$.
	\end{proposition}
	\begin{proof}
		We prove this by induction on $n$. When $n=0$ there is nothing to prove. For $n=1$ due to the fact that $A$ is a PID the submodules of $A$ (ideals) are one generated i.e. they are rank 1 free modules of $A$.
		
		Proceed via induction. Now consider the case when $n=k$. 
		
		Let $M \subset A^k$ be non zero. Consider the componentwise projection maps $p_i: A^{k} \to A$ for each $i$. Then $\pi_i(M) \neq \{0\}$ for some $i$. Therefore $p_i(M)$ is a non-zero ideal in $A$, i.e. free with rank 1. Also, $\ker p_i \cap M$ is a submodule of $\ker p_i$ which is itself free of rank $n-1$. Therefore rank of $\ker p_i \cap M$ is $\leq n - 1$. Let $a$ be a generator for $p_i(M)$ consider some preimage of it as $a_p$.
		
		Now $M = \ker p_i \cap M \oplus \langle a_p \rangle$. If $\{a_1, a_2, \cdots a_m\}$ is a basis of $\ker p_i \cap M$, then $\{a_1, a_2, \cdots a_m, a_p \}$ is a basis of $M$. Hence rank of $M$ equals $m + 1 \leq n$. 
		
	\end{proof}
	
	\begin{proposition}\label{projfgpidfree}
		Projective f.g. modules over PIDs are free
	\end{proposition}
	\begin{proof}
		Every f.g. projective module $P$ is a direct summand of a free module $F$ meaning it is a submodule of $F$ and by Prop. \ref{submodoffreemodisfreepid} it is free.
	\end{proof}

	%		Note If $R$ is local and $M$ is fin-gen projective module then $M$ is free, this is a consequence of Nakayama. As $M \oplus Q = R$ so if $R$ has maximal ideal $\mathfrak{m}$ then $M/\mathfrak{m}M$ is a vector space	over the field $R/\mathfrak{m}R$ and its basis lifts to minimal set of generators of $M$, consider $N=M/\sum R m_i$ and so $ N/ IN=M/(IM+\sum_i R m_i)=M/M=0\implies N=IN$ then apply typical Nakayama to get $N=0
	%		\implies M= \sum_i R m_i$, for $I$ an ideal inside the Jacobson radical of $R$
	%		
	%		So now to prove $1 \iff 2 $ consider a finitely presented module localized over 
	%		
	%		If $M,N$ finitely presented over $R$ and their localizations are isomorphic then theres some element of $f\in R-P$ such that $M[f^{-1}] \cong N[f^{-1}]$
	
	
	\subsection{Long exact sequence of homologies, Snake and 5-lemma}

	Consider $(A,\varphi),(B,\psi),(C,\chi)$ to be chain complexes we can define a short exact sequence of complexes as \[ 0 \to A \xrightarrow{\alpha} B \xrightarrow{\beta} C \to 0 \]
	For $\alpha, \beta $ maps of complexes as discussed above, and $\beta \alpha=0$, if for all $i$ the underlying sequence of modules is exact\[ 0 \to A_i \xrightarrow{\alpha_i } B_i \xrightarrow{\beta_i } C_i \to 0\]
	
	These maps also induce maps on the homologies $\alpha_i: H_i A \to H_i B, \beta_i: H_i B \to H_i C$. Furthermore there is a natural map \[ 	\delta_i : H_i C \to H_{i-1}A	 \] which is called the \textbf{connecting homomorphism}
	
	Before seeing how to construct this $\delta $ it is useful to have a complete picture of the data in front of us. This can be seen below,
	\[\begin{tikzcd}
		& \vdots & \vdots & \vdots \\
		0 & {A_i} & {B_i} & {C_i} & 0 \\
		0 & {A_{i-1}} & {B_{i-1}} & {C_{i-1}} & 0 \\
		0 & {A_{i-2}} & {B_{i-2}} & {C_{i-2}} & 0 \\
		& \vdots & \vdots & \vdots
		\arrow[from=2-1, to=2-2]
		\arrow["{\alpha_i}", from=2-2, to=2-3]
		\arrow["{\beta_i}", from=2-3, to=2-4]
		\arrow[from=2-4, to=2-5]
		\arrow[from=3-1, to=3-2]
		\arrow[from=4-1, to=4-2]
		\arrow["{\alpha_{i-1}}", from=3-2, to=3-3]
		\arrow["{\beta_{i-1}}", from=3-3, to=3-4]
		\arrow[from=3-4, to=3-5]
		\arrow["{\alpha_{i-2}}", from=4-2, to=4-3]
		\arrow["{\beta_{i-2}}", from=4-3, to=4-4]
		\arrow[from=4-4, to=4-5]
		\arrow["{\varphi_i}"', from=2-2, to=3-2]
		\arrow["{\varphi_{i-1}}"', from=3-2, to=4-2]
		\arrow[from=4-2, to=5-2]
		\arrow[from=1-2, to=2-2]
		\arrow[from=1-3, to=2-3]
		\arrow[from=1-4, to=2-4]
		\arrow["{\psi_i}"', from=2-3, to=3-3]
		\arrow["{\chi_i}"', from=2-4, to=3-4]
		\arrow["{\psi_{i-1}}"', from=3-3, to=4-3]
		\arrow["{\chi_{i-1}}"', from=3-4, to=4-4]
		\arrow[from=4-3, to=5-3]
		\arrow[from=4-4, to=5-4]
	\end{tikzcd}\]
	We construct via a diagram chase. Suppose $h \in H_i C= \ker \chi_i / \image \chi_{i+1} $ pick a cycle $x\in \ker \chi_i$. As $\beta_i $ is surjective we know there exists $y \in B_i$ s.t. $\beta_i(y)=x $. Now also by the fact that $x\in \ker \chi_i$ and that we have maps between chain complexes so the squares commute. We have that $\beta_{i-1}(\psi_{i}(y))=\chi_i(\beta_i(y))=\chi_i(x)=0$.
	
	Now there is some $z \in A_{i-1}$ such that $\alpha_{i-1}(z)=\psi_i(y)$ (this is due to exactness of $i-1$ sequence hence the quotient isomorphism and the above condition).
	
	As $\alpha_{i-2}$ is a monomorphism $\alpha_{i-2} \varphi_{i-1}(z)=\psi_{i-1}\alpha_{i-1}(z)=\psi_{i-1}\psi_{i}(y)=0$ so $z\in \ker \alpha_{i-1}$. Just define $\delta_i(h) $ to be the image of $z$ in $H_{i-1}A$.
	
	The above definition is well defined as it is independent of the choice of lift $x$. Pick any other lift say $x'$ now $\beta_i(x-x')=x-x=0$. So it has a preimage in $A_i$ and can be given as an embedding from $A_i \to B_i$ so $x-x' \in A_i$. $\phi_i(x-x')=\psi_i x - \psi_i x'$ which implies their images in $H_{i-1}A$ are homotopic.
	
	The fact that $\delta_i $ is a group homomorphism is simply via linearity.
	
	\begin{proposition}[Induced long exact sequence of homology]
		For a given short exact sequence 
		\[ 0 \to A \xrightarrow{\alpha } B \xrightarrow{\beta } C \to 0\]
		of chain complexes $(A, \varphi), (B, \psi), (C, \chi)$, then the connecting homomorphism $\delta_i: H_iC \to H_{i-1}A$ induces the following long exact sequence of homologies
		\[\begin{tikzcd}
			& \cdots & {H_iC} \\
			{H_{i-1}A} & {H_{i-1}B} & {H_{i-1}C} \\
			{H_{i-2}A} & \cdots
			\arrow[from=1-2, to=1-3]
			\arrow[from=2-1, to=2-2]
			\arrow[from=2-2, to=2-3]
			\arrow["{\delta_i}"{description}, from=1-3, to=2-1]
			\arrow["{\delta_{i-1}}"{description}, from=2-3, to=3-1]
			\arrow[from=3-1, to=3-2]
		\end{tikzcd}\]
		
		Furthermore if the chain complexes are differential modules the following triangle commutes,
		\[\begin{tikzcd}
			HA && HB \\
			& HC
			\arrow["\alpha", from=1-1, to=1-3]
			\arrow["\beta", from=1-3, to=2-2]
			\arrow["\delta", from=2-2, to=1-1]
		\end{tikzcd}\]
		
	\end{proposition}
	
		\begin{lemma}[Snake lemma]
		\[\begin{tikzcd}
			& A & B & C & 0 \\
			0 & {A'} & {B'} & {C'}
			\arrow[from=1-2, to=1-3]
			\arrow[from=1-3, to=1-4]
			\arrow[from=1-4, to=1-5]
			\arrow[from=2-1, to=2-2]
			\arrow[from=2-2, to=2-3]
			\arrow[from=2-3, to=2-4]
			\arrow["\alpha", from=1-2, to=2-2]
			\arrow["\beta", from=1-3, to=2-3]
			\arrow["\gamma", from=1-4, to=2-4]
		\end{tikzcd}\]
		The above commutative diagram induces a exact sequence \[ \ker \alpha \to \ker \beta \to \ker \gamma \to \mathrm{coker}\alpha \to \mathrm{coker}\beta \to \mathrm{coker}\gamma \]
	\end{lemma}
	\begin{proof}
		The map $\ker \gamma \to \mathrm{coker} \alpha $ is given by the connecting homomorphism.
	\end{proof}
	
	\begin{lemma}[5-lemma]
		If we have a commutative diagram as such,
		\[\begin{tikzcd}
			A & B & C & D & E \\
			{A'} & {B'} & {C'} & {D'} & {E'}
			\arrow[from=1-1, to=1-2]
			\arrow["\alpha"', from=1-1, to=2-1]
			\arrow[from=1-2, to=1-3]
			\arrow["\beta"', from=1-2, to=2-2]
			\arrow[from=1-3, to=1-4]
			\arrow["\gamma"', from=1-3, to=2-3]
			\arrow[from=1-4, to=1-5]
			\arrow["\delta"', from=1-4, to=2-4]
			\arrow["\epsilon"', from=1-5, to=2-5]
			\arrow[from=2-1, to=2-2]
			\arrow[from=2-2, to=2-3]
			\arrow[from=2-3, to=2-4]
			\arrow[from=2-4, to=2-5]
		\end{tikzcd}\]
		and if $\beta, \delta $ are isomorphisms with $\alpha $ epimorphism and $\epsilon $ a monomorphism implies that $\gamma $ is an isomorphism.
	\end{lemma}
	
	\subsection{Resolutions}
	Given a module $M$ its \textbf{left resolution} is given by the data of a exact sequence $(A_\bullet, \varphi_\bullet)$ into $M$ as such,
	\[ 	\dots \to A_1	\to A_0 \xrightarrow{\epsilon} M \to 0 \]
	where $\epsilon $ is called the \textbf{augmentation map}, if the exact sequence is free its a free resolution and such for projective. 
	
	If we have a cochain complex instead it forms a \textbf{right resolution} and if its elements are injective we call them injective resolutions.
	
	\begin{proposition}[Horseshoe lemma]
		If there is a short exact sequence of modules,
		\[ 0 \to M \to N \to P \to 0 \]
		and both $M,P$ have a projective resolutions $A, C$ 
		\[\begin{tikzcd}
			&&& 0 \\
			\cdots & {A_1} & {A_0} & M & 0 \\
			&&& N \\
			\cdots & {C_1} & {C_0} & P & 0 \\
			&&& 0
			\arrow[from=2-4, to=2-5]
			\arrow[from=1-4, to=2-4]
			\arrow[from=2-4, to=3-4]
			\arrow[from=3-4, to=4-4]
			\arrow[from=4-4, to=4-5]
			\arrow[from=4-4, to=5-4]
			\arrow[ from=4-3, to=4-4]
			\arrow[ from=2-3, to=2-4]
			\arrow[from=2-1, to=2-2]
			\arrow[from=2-2, to=2-3]
			\arrow[from=4-1, to=4-2]
			\arrow[from=4-2, to=4-3]
		\end{tikzcd}\]
		as below then $N$ also has a projective resolution $B$ which forms a short exact sequence. Also the sequence splits due to $C_i$ being projective so $B_i=A_i \oplus C_i$.
	\end{proposition}
	\begin{proof}
		First note $\epsilon_P: C_0 \to P$ lifts due to projectivity to $C_0 \to N$ also $A_0\to N$ via composition so simply define $B_0 = A_0 \oplus C_0$. This is an epi evidently via diagram chase. Also is projective as direct sum of projectives is projective. Now consider direct sum of kernel of $A_0 \to M, B_0 \to N, C_0 \to P$ and construct the direct sum again to get $F_1$.	Now we get a $3\times 3$. Exactness is due to the Snake lemma
	\end{proof}
	\subsection{Puppe/Homotopy cofiber sequence}
	The discussion in this section follows \cite{weibel_1994}.
	
%	\textbf{TO DO: KOSZKUL COMPLEX AND HILBERT SYZYGY}
%	We previously saw the definition of a bilinear map when discussing tensor products. Now consider $n$- linear maps for some map between $R$-Modules $M,P$. Repeated application of the tensor product still provides us with universal such module, $M^n \to \otimes_{i=1}^n M$.
%	
%	Also a map is called $n$-alternating if it vanishes when two of the arguments are the same. This also implies that sign changes when the arguments are interchanged. Also for a permutation the sign change changes to the sign of the permutation. Now when we require a notion of a universal $n$-linear alternating map we arrive to the definition of a wedge product.
%	
%	In particular for a specific $n$. There is a universal alternating $n$-linear map sending $M \to \Lambda^n M$. If $M$ is f.g. by $r$ elements then $\Lambda M^n$ is a free module of rank $\binom{r}{n}$.
%	
%	\begin{definition}[Tensor algebra]
%		For a $R$-Module $M$ and $T^n M = \otimes^n M$ the tensor algebra is defined to be \[ T(M)=\oplus_{n=0}^\infty T^n M \]
%	\end{definition}
%	
%	
%	
%	\begin{definition}[Exterior algebra and wedge product]
%		For an $R$-Module $M$. Consider the Tensor algebra $T(M)=\oplus_n \otimes^n M	$. Consider the ideal $I$ spanned by elements $v \otimes v$ for $v \in T(M)$.
%		
%		The quotient of $T(V)/I := \Lambda(M) $ is called the exterior algebra and its product the wedge product.	It is universal with respect to multilinear alternating maps.
%		
%		For $v \Lambda^nM, w \in \Lambda^m M$ multiplication is defined as such,
%		\[ v \Lambda w = (-1)^{nm} w \Lambda v\]
%	\end{definition}
%	
%	
%	\begin{definition}[Koszkul complex]
%		For a $R$-module $M$ there is an associated chain complex of $n^\textbf{th}$ exterior algebras
%		\[ \Lambda^n M \to \Lambda^{n-1} M \to \dots \to \Lambda^0 M \cong M \]
%	\end{definition}
%	
%	
%	\begin{definition}[Regular sequence]
%		A sequence of elements $r_1,\dots,r_n$ is said to be a regular sequence in $R$ if $r_1$ is not a zero divisor of $R$, $r_2$ is not a zero divisor of $R/\langle r_1\rangle $, and so on
%	\end{definition}
%	\begin{proposition}
%		For a finite regular sequence $\{r_i\}_{i=1}^n$ of a ring $R$ the Koszkul complex forms the canonical free resolution of $R/\langle r_1,\dots,r_n\rangle$ of the form
%		\[ 0 \to R^{\binom{n}{n}} \to \dots \to R^{\binom{n}{1}} \to R \to R/\langle r_1,\dots, r_n \rangle \to 0\]
%	\end{proposition}
%	\begin{proof}
%		TO DO
%	\end{proof}
	
	
	\section{Vector bundles}
	More detailed exposition can be found in \cite{milnor1974characteristic}. We define the basics as needed for Swam's theorem. We understand all maps as continuous functions.
	\begin{definition}[Vector bundle]
		A real $n$ dimensional vector bundle is a triple $(E,p, B)$. Which consists of a continuous map $p:E \to B$ from the total space $E$ to the base space $B$. Such that for all $b \in B$, $F_b=p^{-1}(b)$ the fibre of $b$ has a real/complex vector space structure. Along with the following property of local trivialization
		\begin{enumerate}
			 \item For any $b \in B$ there exists a open open $U \subset B$ along with a homeomorphism \[ h: U \times \R^n	\to p^{-1}(U) \] such that for all $c \in U$ the map through $h$ defines an isomorphism between $F_c$ and $\R^n$.
		\end{enumerate}
	\end{definition}
	
	A trivial vector bundle is one in which the total space $E=B \times \R^n$ with $p$ just the trivial projection mapping.
	
	
	\begin{definition}[Vector bundle isomorphisms]
		Two vector bundles $(E_1,p, B)$ and $(E_2,p_2, B) $ are considered isomorphic if there exists a homeomorphism between their total spaces $h$ such that the below diagram commutes
		\[\begin{tikzcd}
			{E_1} && {E_2} \\
			& B
			\arrow["{p_1}"', from=1-1, to=2-2]
			\arrow["{p_2}", from=1-3, to=2-2]
			\arrow["h", from=1-1, to=1-3]
		\end{tikzcd}\]
		
		and also if $h$ induces a vector space isomorphism for each fibre.
	\end{definition}
	
	\begin{definition}[Sections of a vector bundle]
		For a topological vector bundle $(E,p,B)$ a section refers to a map	$s: B \to E$ such that $p \circ s= 1_B$ where $1_B$ denotes the identity map on $B$.
		
		These sections equivalently are a homomorphism of vector bundles from the trivial line bundle $(B \times \R, \pi_B, B) \to (E,p,B)$
	\end{definition}
%	
%	\begin{definition}[Pullbacks of bundles]
%		content...
%	\end{definition}
%	
%	\begin{definition}[Whitney sums]
%		content...
%	\end{definition}
%	
%	\begin{definition}[Steifel Whitney Class]
%		content...
%	\end{definition}
	\section{Categories}
	\subsection{Abelian Categories}
	Abelian categories are essential to the understanding of homological algebra. It is motivated by the fact that it allows for using homological methods in a wide variety of applications and helps unify various (co)homology theories. They were first introduced by Grothendieck in his seminal Tohuku paper \cite{grothendieck1957quelques}.
	
	There is a chain of conditions regarding `abelian'-ness of categories which is roughly understood as follows,
	\[ \textbf{Abelian} \subseteq \textbf{Pre-Abelian} \subseteq \textbf{Additive} \subseteq \textbf{Ab-Enriched}\]
	The motivation behind them is to have categories which resemble algebras.
	
	Ab-Enriched categories are categories such that for objects $A,B \in \mathbf{C}$ the external hom set $\Hom(A,B)$ has the structure of an abelian group, furthermore it has a well defined notion of composition (which is bilinear due to the monoidal product in Ab), $\Hom(A,B)\otimes \Hom(B,C) =\Hom(A,C)$. 
	
	We have chosen to omit the precise definitions of monoidal and monoidally enriched categories to make this section easier to read. Since we refrain from explicitly using them for computations anywhere, the basic background described above will suffice. For a more detailed overview of the definitions for monoidal and monoidally enriched categories refer to \cite{lane1998categories} for a classical treatment or \cite{riehl2017category} for an excellent modern exposition. 
	
	We cover a few basic results.
	
	\begin{proposition}
		In Ab-Enriched categories intial and terminal objects coincide (it is often called the zero object)
	\end{proposition}
	\begin{proof}
		Let $\mathbf{C}$ be an Ab-Enriched category. Note that the Hom-sets between objects have `zero morphisms', i.e. arrows in the Hom-set which behave like the additive identity in the Ab group induced by it. In particular for $0_{A,B}\in \Hom(A,B)$ we have the property that if $f:B \to C$ then $f\circ 0_{A,B}=0_{A,C}$ and $g: A \to D$ then $0_{A,B}\circ g=0_{D,B}$.
		
		Now suppose $0 \in \mathbf{C}$ is initial so there is a unique morphism $0\to 0$ so in its Hom-set its both the additive inverse and the identity. So for any $f:X \to 0$ we can say that by the zero morphism property $f=0$ so also $0$ is terminal.
	\end{proof}
	\begin{proposition}
		In Ab-Enriched categories finite coproducts coincide with finite products (i.e. biproducts) \footnote{This also holds over categories enriched over commutative monoids.}
	\end{proposition}
	\begin{proof}	
		Let $\mathbf{C}$ be an Ab-enriched category and $A,B\in \mathbf{C}$ consider the product $A\times B$, which is determined by the following UMP,
		\[\begin{tikzcd}
			& X \\
			A & A\times B & B
			\arrow["{p_1}"', from=2-2, to=2-1]
			\arrow["{p_2}", from=2-2, to=2-3]
			\arrow["u", dashed, from=1-2, to=2-2]
			\arrow["{x_1}"', from=1-2, to=2-1]
			\arrow["{x_2}", from=1-2, to=2-3]
		\end{tikzcd}\]
		Consider $A$ and $B$ in place of $X $ in the diagram. By the UMP we have $q_1: A \to A\times B, q_2: B \to A\times B$
		\[\begin{tikzcd}
			A && B \\
			& {A\times B} \\
			A && B
			\arrow["{p_1}"', from=2-2, to=3-1]
			\arrow["{p_2}", from=2-2, to=3-3]
			\arrow["{q_2}"', from=1-3, to=2-2]
			\arrow["{q_1}"', from=1-1, to=2-2]
			\arrow["{1_A}"', from=1-1, to=3-1]
			\arrow["{1_B}", from=1-3, to=3-3]
		\end{tikzcd}\]
		So $p_1q_1=1_A$ and $p_2q_2=1_B$ also $p_1q_2=p_2q_1=0$.
		
		Now note that $q_1p_1+q_2p_2=1_{A\times B}$ as $p_1(q_1p_1+q_2p_2)=p_1$ and $p_2(q_1p_1+q_2p_2)=p_2$. Claim this $q_1,q_2$ determine a coproduct $A +B$.
		
		We wish to show the following UMP holds for some arbitrary $C \in \mathbf{C}$
		\[\begin{tikzcd}
			A & C & B \\
			& {A\times B} \\
			A && B
			\arrow["{q_1}"', from=1-1, to=2-2]
			\arrow["{q_2}", from=1-3, to=2-2]
			\arrow["{p_1}"', from=2-2, to=3-1]
			\arrow["{p_2}", from=2-2, to=3-3]
			\arrow["{1_B}"', from=1-3, to=3-3]
			\arrow["{1_A}"', from=1-1, to=3-1]
			\arrow["{r_1}", from=1-1, to=1-2]
			\arrow["{r_2}"', from=1-3, to=1-2]
			\arrow["{f}"',dashed, from=2-2, to=1-2]
		\end{tikzcd}\]
		Define $f: A\times B \to C$ as $f=r_1p_1+r_2p_2$. Now $fq_1=r_1$ and $fq_2=r_2$ if we show uniqueness of $f$ we are done.
		
		Say $f'$ then $(f-f')1_{A \times B}=(f-f')(q_1p_1+q_2p_2)=0$. So $f=f'$.
		
		
	\end{proof}
	
	
	\begin{definition}[Additive category]
		An Ab-Enriched category which has all finite coproducts.
	\end{definition}
	
	Functors between additive categories are called \textit{additive functors}. And can be realized as functors which preserve additivity of homomorphisms between modules, $F(f+g)=F(f)+F(g).$
	
	Before proceeding further it is important to think about kernels and cokernels in the categorical sense.
	\begin{definition}[Kernel]
		A kernel is a pullback of a morphism $f:A \to B$ and the unique morphism from $0 \to B$. Provided initials and pullbacks exist.
		
		\[\begin{tikzcd}
			{\ker f} && 0 \\
			\\
			A && B
			\arrow["f", from=3-1, to=3-3]
			\arrow[from=1-3, to=3-3]
			\arrow[from=1-1, to=1-3]
			\arrow[from=1-1, to=3-1]
		\end{tikzcd}\]
	\end{definition}
	The intuition behind this definition is that alternatively it is seen as an equalizer of a function $f:A \to B$ and the unique zero morphism $0_{A,B}$. The kernel object is the part of the domain that is 'going to zero'. \footnote{A minor point to note is that in the case of Ab-Enrichments the `zero' in the Hom-sets isn't a terminal, its Hom-set specific. When you assume a Ab-Enriched category has a initial 0 however this matches up with our intuition.}
	
	
	\begin{definition}[Pre-abelian categories]
		An additive category with all morphism having kernels and cokernels.
	\end{definition}
	The above definition is equivalent to saying a pre-abelian category is a Ab-Enriched category with all finite limits and colimits. This is a consequence to the fact that categories have finite limits iff it has finite products and equalizers \cite[Prop.~5.21]{Awodey}. And we know equalizers exist because equalizers of two morphisms is just the kernel of $f-g$.
	
	
	
	
	\begin{definition}[Abelian category]
		Pre-abelian categories for which each mono is a kernel and each epic is a cokernel.
	\end{definition}
	
	With this definition in mind we will now define a few important constructions we will use often. These are not restricted to abelian categories but we will use them very often in the case of abelian categories, so it is good to see it in action directly with the notion of an abelian category at hand.
	\begin{definition}[Subobject]
			A subobject for some $X \in \mathcal{C}$ is a monomorphisms into $X$. 
	\end{definition}
	
	
	With slight abuse of notation we refer to $Y \leq X$ as a subobject of $X$ where $Y$ is just a representative of the codomain of a isomorphism class of monomorphisms into $X$. In particular for$X, Z \rightrightarrows X$ monics $Z, X$ belong to the same subobject class if the morphisms are isomorphic, i.e. there exists an isomorphism between $Y \to Z$ making the triangle commute. 
	
	This is clearer when seen through the lens of a slice category. Note that arrows between subobjects of the same $X$ are arrows in the slice category of $X$. So collection of subobjects form a category with a preorder (with inclusion). The reasoning behind such an odd definition for subobjects is motivated by the fact that we think of generalized elements in $\mathcal{C} $ as being not $X \in \mathrm{Ob}(\mathcal{C}) $ but rather $\hom_\mathcal{C}(-,X)$.
	
	\begin{definition}[Quotients in abelian categories]
		For $Y \leq X$ in an abelian category we can define $X/Y $ as the cokernel of the monomorphism $Y \to X$. 
	\end{definition}
	
	\begin{definition}[Extension/short exact sequences in abelian categories]
		For $ A, B \in \mathcal{A}$ an extension by $A$ of $B$ refers to some $E \in \mathcal{A}$ such that $0 \to A \to E \to B \to 0$ is a short exact sequence.
	\end{definition}
	
	\subsubsection{Examples}
	Some examples of abelian categories are as follows,
	\begin{enumerate}
		\item \textbf{The category of modules.}
		\item\textbf{Category of representations of a group}
		\item \textbf{Category of sheaves of abelian groups on some topological space.}
		
		\begin{definition}[Presheaf]
			For a category $C$ a presheaf is any functor $F: \mathbf{C}^{\mathrm{op}}\to \mathbf{Sets}$.
		\end{definition}
		In particular in the case for a topological space $X$ a presheaf of groups (or any algebraic object) on $X$ (in truth the set of the lattice of open sets of $X$ ordered by inclusion) is a some contravariant functor $F$ which sends open sets $U \subseteq X$ to some $F(U)$, it respects inclusions (i.e. there for open sets $V \subseteq V $ is a natural transformation $\rho_{UV}: F(U)\to F(V)$ in the form of a restriction). Furthermore, function composition, unitals and empty sets going to empty sets hold (to make it a category). Note that all these notions of presheaves are really just a special case of the categorical definition where the sheaf of groups is really just a group object in the categorical presheaf.
		\begin{definition}[Sheaf of sets on a topology]\label{def:scheaf}
			A sheaf of a topology $X$ is a presheaf which satisfies two additional properties, for open sets $U \in X$ and open covers ${U_i}$ of $U$
			\begin{enumerate}
				\item (Locality)  \textbf{A section}, i.e. an element $s \in F(U)$ goes to zero restricted at $U_i$ for all $i$ implies $s=0$.
				\item (Gluing) If there is a collection of sections $s_i \in F(U_i)$ such that $s_i|_{U_i \cap U_j}=s_j|_{U_i \cap U_j}$ for all $i,j$ then there is some $s \in F(U)$ such that $s|_{U_i}=s_i$ for all $i$.
			\end{enumerate}
			
			These two conditions can be written is short as just saying we require $F(U)$ to be the equalizer for the following diagram
			\[\begin{tikzcd}
				{\prod_{i \in I} F(U_i)} && {\prod_{i,j}F(U_i \cap U_j)}
				\arrow[shift right=2, from=1-1, to=1-3]
				\arrow[shift left=2, from=1-1, to=1-3]
			\end{tikzcd}\]
		\end{definition}
		
		The category of sheaves of abelian groups on a topological space form a abelian category. Additivity is natural due to the functorial nature of $F$. A quick proof is due to `sheafification', i.e. the left adjoint to the inclusion functor from sheaves into presheaves. Presheves of abelian groups can be understood to have all the required properties to be an Abelian category due the functorial representation. Now due to the following result \cite[Sec. 6.17]{stacks1} we can extend this notion to the sheaves via sheafification.
	\end{enumerate}
	\subsubsection{Serre subcategory, localization}
	For an abelian category $\mathcal{A}$ a Serre subcategory () of $\mathcal{A}$ is a specific kind of subcateogry which allows us to create a `quotient' which we call a Serre quotient. In reality this is more akin to a localization than a quotient proper. 
	
	\begin{definition}[Serre subcategory]
		Let $\mathcal{A}$ be an abelian category, a full subcategory $\mathcal{B} \subset \mathcal{A}$ is called a Serre subcategory of $\mathcal{A}$ if \begin{itemize}
			\item For exact sequence $0 \to A \to B \to C $ in $\mathcal{A}$, $B \in \mathcal{B} \iff A,C \in \mathcal{B}$
			\item Equivalently this means that $\mathcal{B}$ is closed under quotients, subobjects and extensions.
		\end{itemize}
	\end{definition}
	
	\begin{definition}[Serre quotient]
		Given $\mathcal{B} \subset \mathcal{A}$ a locally small Serre subcategory of an abelian category we can define its Serre question $\mathcal{A}/\mathcal{B}$ with the following construction. \begin{itemize}
			\item $\mathrm{Ob}(\mathcal{A}/\mathcal{B})$ consists of objects from $\mathcal{A}$
			\item Morphisms between $A\to B$ as $\hom_{\mathcal{A}/\mathcal{B}} (A,B) =  \lim_\to \hom_\mathcal{A} (\tilde A, Y/\tilde Y)$ where $\tilde A \leq A, \tilde Y \leq Y$ are subobjects.
		\end{itemize}
	\end{definition}
	When $\mathcal{A}$ is small we can treat morphisms $A \to B $ as equivalence classes of diagrams of the form \[ A \xleftarrow{f} \bullet \xrightarrow{g} B \]
	Where $\ker, \mathrm{coker}$ of $f$ are in $\mathcal{B}$. Equivalence with another diagram $A \leftarrow \circ \rightarrow B$ is defined with the existence of the below commuting diagram
	\[\begin{tikzcd}
		& \bullet \\
		A & X & B \\
		& \bullet
		\arrow[from=1-2, to=2-1]
		\arrow[from=1-2, to=2-3]
		\arrow[from=2-2, to=1-2]
		\arrow[from=2-2, to=2-1]
		\arrow[from=2-2, to=2-3]
		\arrow[from=2-2, to=3-2]
		\arrow[from=3-2, to=2-1]
		\arrow[from=3-2, to=2-3]
	\end{tikzcd}\]
	Where for $\bullet \leftarrow X \rightarrow \circ $ we have $\ker,\mathrm{coker}$ of both the arrows in $\mathcal{B}$, making the below diagram commute.
	
	
	A more pedagogically relevant definition is that $S$ the collection of morphisms whose kernels and cokernels belong to $\mathcal{B}$ can be considered as a multiplicative system (in the sense of Gabriel-Zisman) and $\mathcal{A/B}$ is precisely $\mathcal{A}[S^{-1}]$ a localization of categories in terms of Gabriel-Zisman. \textbf{(TO DO)} \cite{gabriel1967calculus}.
	\begin{theorem}
		$\mathcal{A/B}$ is abelian and the inclusion functor $L:\mathcal{A} \to \mathcal{A/B}$ is exact
	\end{theorem}
	\begin{proposition}
		The Serre quotient $\mathcal{A/B}$ universal in the following sense. Any exact functor $U: \mathcal{A} \to \mathcal{C}$ such that $U(B)\cong 0$ for $B \in \mathcal{B}$ will factor through $L$. i.e. the below diagram commutes	
		\[\begin{tikzcd}
			&& {\mathcal{A/B}} \\
			\\
			{\mathcal{A}} && {\mathcal{C}}
			\arrow[dashed, from=1-3, to=3-3]
			\arrow["L", from=3-1, to=1-3]
			\arrow["U", from=3-1, to=3-3]
		\end{tikzcd}\]
	\end{proposition}
	
	This result is the reason why the Serre subcategory is defined the way it is. The conditions required in the definitions are precisely those such that the above proposition may hold.
%	\subsubsection{Important results}
%	There are a few concepts and definitions relevant in the conversation of abelian categories which we will list out here for completeness. Firstly is the notion of \textbf{exact functors} the typical notion of a functor carrying forward exact sequences. With the prefix of left/right added to determine it carrying forward only left or right sides of the exact sequence.
	
	
%	\begin{proposition}\label{adjointinjective}
%		Given a pair of adjoint functors $F \dashv U$ between abelian categories $F:\mathbf{C} \rightleftarrows \mathbf{D}:U$ if the left adjoint $F$ is exact, faithful and if $ \mathbf{D}$ has enough injectives also $\mathbf{C}$ has enough injectives.
%	\end{proposition}
%	\begin{proof}
%		content...
%	\end{proof}
	\subsection{Derived categories}
	\subsection{Exact categories}
	An exact category (sometimes referred to as a Quillen exact category) is a pair $(C,E)$ for $C$ an additive category which is a full subcategory of some abelian category $\mathcal{A}$. Along with a family of sequences $E$ of the form \[ 0 \to X \to Y \to Z \to 0 \] which are short exact sequences in $\mathcal{A}$ and if in a sequence of the above form $X, Z \in C$ then $Y \cong Z \in \mathrm{Ob}(C)$
	\begin{example}
		Every abelian category is trivially exact over itself.
	\end{example}
	\begin{example}
		The vector bundles on a scheme $X$ form a exact category.
	\end{example}
	\subsection{Factorization systems, Model categories}
	\subsection{Triangulated categories}
	Add examples from Puppe sequence discussion from homological alg notes they form the triangulation in the case of the stable homotopy category.
	
	Also include quillen model cats somewhere in between.
	
	\subsection{Waldhausen categories}
	Every exact category has a Waldhausen structure.
	\section{Stable homotopy and Spectra (relevant or not? in top k yes in alg k ?) }
	The definitions in this section are mainly using the convention in Adam's blue book \cite{adams1974stable}.
	\begin{definition}[CW-Spectrum]
		A sequence of based CW-complexes $\{E_n\}_{n \in \mathbb{Z}}$ with structure maps $\sum E_n \to E_{n+1}$
	\end{definition}
	The suggestive notation is pointing in the direction of the canonical spectrum known as the suspension spectrum when the structure maps are indeed suspensions.
	\end{appendices}

	A natural question to ask is why can we not simply define the morphism as an obvious map translating between spectra (up to a degree shift) that respects the suspension functors through a obvious commuting square. Such a construction would fail due to the existence of nontrivial maps such as the Hopf fibration.
	
	Consider the suspension spectra of spheres denoted as $\mathbf{S}$ the sphere spectrum.
	
	\begin{theorem}[Brown representability]
		Some nice contravariant functors on homotopy category are representable.
	\end{theorem}
	\begin{theorem}
		Extraordinary (co)homology theories are representable by a spectrum.
	\end{theorem}
	K theory spectrum
	\appendix
	
	
	
	
	\bibliographystyle{alpha}
	\bibliography{references}
\end{document}